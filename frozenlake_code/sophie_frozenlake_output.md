# 4x4 frozen lake map PPO - is_slippery off
```
Output 1: Average over 100 episodes - Reward: 0.0
-----------------------------
| time/              |      |
|    fps             | 581  |
|    iterations      | 1    |
|    time_elapsed    | 3    |
|    total_timesteps | 2048 |
-----------------------------
Output 2: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 491         |
|    iterations           | 2           |
|    time_elapsed         | 8           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.009321687 |
|    clip_fraction        | 0.0233      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -4.46       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00896     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00466    |
|    value_loss           | 0.0146      |
-----------------------------------------
Output 3: Average over 100 episodes - Reward: 0.13
-----------------------------------------
| time/                   |             |
|    fps                  | 510         |
|    iterations           | 3           |
|    time_elapsed         | 12          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012359478 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.0994      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0199     |
|    value_loss           | 0.0199      |
-----------------------------------------
Output 4: Average over 100 episodes - Reward: 0.2
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 4           |
|    time_elapsed         | 15          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.018152526 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0148     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0423     |
|    value_loss           | 0.0595      |
-----------------------------------------
Output 5: Average over 100 episodes - Reward: 0.38
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 5           |
|    time_elapsed         | 19          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.017712172 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.25        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00747    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.0997      |
-----------------------------------------
Output 6: Average over 100 episodes - Reward: 0.67
----------------------------------------
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 6          |
|    time_elapsed         | 23         |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.02646886 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0203    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.126      |
----------------------------------------
Output 7: Average over 100 episodes - Reward: 0.85
-----------------------------------------
| time/                   |             |
|    fps                  | 538         |
|    iterations           | 7           |
|    time_elapsed         | 26          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.030173749 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.884      |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00837     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0383     |
|    value_loss           | 0.0914      |
-----------------------------------------
Output 8: Average over 100 episodes - Reward: 0.92
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 8           |
|    time_elapsed         | 30          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.016236085 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.751      |
|    explained_variance   | -0.0577     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0125     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.0487      |
-----------------------------------------
Output 9: Average over 100 episodes - Reward: 0.91
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 9           |
|    time_elapsed         | 33          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.012887418 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0.075       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00145    |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0218     |
|    value_loss           | 0.0418      |
-----------------------------------------
Output 10: Average over 100 episodes - Reward: 0.93
----------------------------------------
| time/                   |            |
|    fps                  | 542        |
|    iterations           | 10         |
|    time_elapsed         | 37         |
|    total_timesteps      | 20480      |
| train/                  |            |
|    approx_kl            | 0.01151163 |
|    clip_fraction        | 0.0963     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.549     |
|    explained_variance   | 0.0444     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0119     |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0158    |
|    value_loss           | 0.0418     |
----------------------------------------
Output 11: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 11          |
|    time_elapsed         | 41          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.011159407 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.451      |
|    explained_variance   | 0.0262      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00837     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.0166      |
-----------------------------------------
Output 12: Average over 100 episodes - Reward: 0.95
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 12          |
|    time_elapsed         | 45          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.024604848 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.338      |
|    explained_variance   | 0.0399      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0208     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.0109      |
-----------------------------------------
Output 13: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 13          |
|    time_elapsed         | 48          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.011726507 |
|    clip_fraction        | 0.0877      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.287      |
|    explained_variance   | 0.0269      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0233     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00942    |
|    value_loss           | 0.0197      |
-----------------------------------------
Output 14: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 548         |
|    iterations           | 14          |
|    time_elapsed         | 52          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014662791 |
|    clip_fraction        | 0.0902      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.251      |
|    explained_variance   | 0.0219      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0229      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00647    |
|    value_loss           | 0.00194     |
-----------------------------------------
Output 15: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 15           |
|    time_elapsed         | 55           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0078750625 |
|    clip_fraction        | 0.0819       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.233       |
|    explained_variance   | 0.14         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00718     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0136      |
|    value_loss           | 0.00194      |
------------------------------------------
Output 16: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 16           |
|    time_elapsed         | 59           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0025280765 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.21        |
|    explained_variance   | 0.879        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0176      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00855     |
|    value_loss           | 1.36e-05     |
------------------------------------------
Output 17: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 551         |
|    iterations           | 17          |
|    time_elapsed         | 63          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.009340372 |
|    clip_fraction        | 0.0279      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.171      |
|    explained_variance   | 0.102       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00509     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.00319     |
-----------------------------------------
Output 18: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 18          |
|    time_elapsed         | 67          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.003326573 |
|    clip_fraction        | 0.00791     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.013      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 9.63e-06    |
-----------------------------------------
Output 19: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 19           |
|    time_elapsed         | 71           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0065471856 |
|    clip_fraction        | 0.0449       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.148       |
|    explained_variance   | 0.138        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0143      |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.0104      |
|    value_loss           | 0.00195      |
------------------------------------------
Output 20: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 20           |
|    time_elapsed         | 74           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0022320712 |
|    clip_fraction        | 0.00762      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.812        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00381     |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00182     |
|    value_loss           | 4.99e-06     |
------------------------------------------
Output 21: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 21           |
|    time_elapsed         | 78           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0010030152 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00476     |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00248     |
|    value_loss           | 3.66e-07     |
------------------------------------------
Output 22: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 22           |
|    time_elapsed         | 82           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0014223877 |
|    clip_fraction        | 0.00986      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.989        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00171      |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.003       |
|    value_loss           | 3.23e-06     |
------------------------------------------
Output 23: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 544           |
|    iterations           | 23            |
|    time_elapsed         | 86            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 0.00095772103 |
|    clip_fraction        | 0.00654       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.11         |
|    explained_variance   | 0.996         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.000899     |
|    n_updates            | 220           |
|    policy_gradient_loss | -0.0024       |
|    value_loss           | 1.25e-06      |
-------------------------------------------
Output 24: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 24          |
|    time_elapsed         | 90          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.008844548 |
|    clip_fraction        | 0.0506      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0921     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0236     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00179    |
|    value_loss           | 2.9e-09     |
-----------------------------------------
Output 25: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 542           |
|    iterations           | 25            |
|    time_elapsed         | 94            |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00085654494 |
|    clip_fraction        | 0.00825       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0848       |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | -7.94e-05     |
|    n_updates            | 240           |
|    policy_gradient_loss | -0.00298      |
|    value_loss           | 7.66e-07      |
-------------------------------------------
Output 26: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 26          |
|    time_elapsed         | 98          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.016539123 |
|    clip_fraction        | 0.0735      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.993       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0016     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00869    |
|    value_loss           | 1.97e-06    |
-----------------------------------------
Output 27: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 27           |
|    time_elapsed         | 101          |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0016396644 |
|    clip_fraction        | 0.0365       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00597     |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 3.46e-07     |
------------------------------------------
Output 28: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 28           |
|    time_elapsed         | 105          |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0045873467 |
|    clip_fraction        | 0.0555       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.114       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0315      |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00187     |
|    value_loss           | 9.29e-08     |
------------------------------------------
Output 29: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 29           |
|    time_elapsed         | 109          |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0010067772 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000663     |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00289     |
|    value_loss           | 1.16e-06     |
------------------------------------------
Output 30: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 30           |
|    time_elapsed         | 113          |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 0.0017343315 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.121       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000611    |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00251     |
|    value_loss           | 1.26e-06     |
------------------------------------------
Output 31: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 31          |
|    time_elapsed         | 117         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.005733989 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.115      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0144     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.000258   |
|    value_loss           | 2.68e-07    |
-----------------------------------------
Output 32: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 32          |
|    time_elapsed         | 121         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.009974135 |
|    clip_fraction        | 0.0561      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00219     |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00226    |
|    value_loss           | 1.07e-06    |
-----------------------------------------
Output 33: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 33           |
|    time_elapsed         | 125          |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0006366095 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.142       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00198     |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00204     |
|    value_loss           | 5.18e-07     |
------------------------------------------
Output 34: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 34           |
|    time_elapsed         | 128          |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0040280893 |
|    clip_fraction        | 0.0763       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.142       |
|    explained_variance   | 0.545        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00438     |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.0113      |
|    value_loss           | 0.000672     |
------------------------------------------
Output 35: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 35          |
|    time_elapsed         | 132         |
|    total_timesteps      | 71680       |
| train/                  |             |
|    approx_kl            | 0.008923295 |
|    clip_fraction        | 0.0153      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.108      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0113      |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00371    |
|    value_loss           | 2.71e-06    |
-----------------------------------------
Output 36: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 36           |
|    time_elapsed         | 135          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0057754107 |
|    clip_fraction        | 0.065        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.121       |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000785     |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.0025      |
|    value_loss           | 2.13e-06     |
------------------------------------------
Output 37: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 37           |
|    time_elapsed         | 139          |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0042172717 |
|    clip_fraction        | 0.0571       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00533     |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.000842    |
|    value_loss           | 1.76e-08     |
------------------------------------------
Output 38: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 38          |
|    time_elapsed         | 143         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.014924299 |
|    clip_fraction        | 0.0202      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.995       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0227     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0083     |
|    value_loss           | 1.95e-06    |
-----------------------------------------
Output 39: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 39          |
|    time_elapsed         | 147         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.000541655 |
|    clip_fraction        | 0.00693     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0757     |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000895   |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.000469   |
|    value_loss           | 2.34e-08    |
-----------------------------------------
Output 40: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 40           |
|    time_elapsed         | 150          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0007697933 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0815      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000982    |
|    n_updates            | 390          |
|    policy_gradient_loss | 0.000521     |
|    value_loss           | 3.08e-11     |
------------------------------------------
Output 41: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 41           |
|    time_elapsed         | 154          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0004983704 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0767      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00109     |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00158     |
|    value_loss           | 2.3e-07      |
------------------------------------------
Output 42: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 42          |
|    time_elapsed         | 158         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.009262267 |
|    clip_fraction        | 0.0223      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0564     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000162   |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.000384   |
|    value_loss           | 1.65e-09    |
-----------------------------------------
Output 43: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 545           |
|    iterations           | 43            |
|    time_elapsed         | 161           |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00062545587 |
|    clip_fraction        | 0.00605       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0469       |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00162      |
|    n_updates            | 420           |
|    policy_gradient_loss | -0.0021       |
|    value_loss           | 1.16e-06      |
-------------------------------------------
Output 44: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 44          |
|    time_elapsed         | 165         |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.007503272 |
|    clip_fraction        | 0.0404      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0863     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00953    |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.000134   |
|    value_loss           | 6e-09       |
-----------------------------------------
Output 45: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 45          |
|    time_elapsed         | 168         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.023681324 |
|    clip_fraction        | 0.0417      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0427     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0583     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00452    |
|    value_loss           | 1.33e-11    |
-----------------------------------------
Output 46: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 547        |
|    iterations           | 46         |
|    time_elapsed         | 172        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.00057453 |
|    clip_fraction        | 0.00273    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0404    |
|    explained_variance   | 0.135      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.000146  |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.00196   |
|    value_loss           | 0.00208    |
----------------------------------------
Output 47: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 548         |
|    iterations           | 47          |
|    time_elapsed         | 175         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.019220963 |
|    clip_fraction        | 0.0439      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.082      |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0133      |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.000163   |
|    value_loss           | 3.79e-06    |
-----------------------------------------
Output 48: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 48          |
|    time_elapsed         | 180         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.040310755 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0634     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0417     |
|    value_loss           | 1.75e-08    |
-----------------------------------------
Output 49: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 49          |
|    time_elapsed         | 184         |
|    total_timesteps      | 100352      |
| train/                  |             |
|    approx_kl            | 0.004138008 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00137    |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00586    |
|    value_loss           | 0.00167     |
-----------------------------------------
Output 50: Average over 100 episodes - Reward: 0.8
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 50          |
|    time_elapsed         | 188         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.018567778 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0248     |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 2.42e-06    |
-----------------------------------------
Output 51: Average over 100 episodes - Reward: 0.96
---------------------------------------
| time/                   |           |
|    fps                  | 542       |
|    iterations           | 51        |
|    time_elapsed         | 192       |
|    total_timesteps      | 104448    |
| train/                  |           |
|    approx_kl            | 0.0466288 |
|    clip_fraction        | 0.22      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.179    |
|    explained_variance   | 0.00963   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0216    |
|    n_updates            | 500       |
|    policy_gradient_loss | -0.0407   |
|    value_loss           | 0.109     |
---------------------------------------
Output 52: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 543        |
|    iterations           | 52         |
|    time_elapsed         | 196        |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.05229365 |
|    clip_fraction        | 0.124      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0978    |
|    explained_variance   | -0.157     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00666   |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.0276    |
|    value_loss           | 0.0365     |
----------------------------------------
Output 53: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 543        |
|    iterations           | 53         |
|    time_elapsed         | 199        |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.27187753 |
|    clip_fraction        | 0.0982     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0708    |
|    explained_variance   | -2.47      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0838    |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0265    |
|    value_loss           | 0.000113   |
----------------------------------------
Output 54: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 54          |
|    time_elapsed         | 203         |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.025883295 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.445      |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0629     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0565     |
|    value_loss           | 0.000805    |
-----------------------------------------
Output 55: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 55          |
|    time_elapsed         | 207         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.020221418 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.394      |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0505     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0553     |
|    value_loss           | 0.00048     |
-----------------------------------------
Output 56: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 56          |
|    time_elapsed         | 211         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.015575903 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.329      |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0417     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0582     |
|    value_loss           | 0.00024     |
-----------------------------------------
Output 57: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 538        |
|    iterations           | 57         |
|    time_elapsed         | 216        |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.01814416 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.257     |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.033     |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0543    |
|    value_loss           | 0.000134   |
----------------------------------------
Output 58: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 538         |
|    iterations           | 58          |
|    time_elapsed         | 220         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.017703665 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0498     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0377     |
|    value_loss           | 0.00252     |
-----------------------------------------
Output 59: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 59           |
|    time_elapsed         | 225          |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 0.0018399425 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.155       |
|    explained_variance   | 0.826        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000734     |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.0158      |
|    value_loss           | 2.65e-05     |
------------------------------------------
Output 60: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 60          |
|    time_elapsed         | 229         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.072003245 |
|    clip_fraction        | 0.0529      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0666     |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0122     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0264     |
|    value_loss           | 2.89e-05    |
-----------------------------------------
Output 61: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 61          |
|    time_elapsed         | 235         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.035436414 |
|    clip_fraction        | 0.0773      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0856     |
|    explained_variance   | 0.984       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0396     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 3.73e-06    |
-----------------------------------------
Output 62: Average over 100 episodes - Reward: 0.92
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 62          |
|    time_elapsed         | 241         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.005337301 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.011      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00936    |
|    value_loss           | 4.77e-07    |
-----------------------------------------
Output 63: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 523        |
|    iterations           | 63         |
|    time_elapsed         | 246        |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.03359917 |
|    clip_fraction        | 0.0811     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0762    |
|    explained_variance   | 0.014      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00914   |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.0221    |
|    value_loss           | 0.0437     |
----------------------------------------
Output 64: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 521         |
|    iterations           | 64          |
|    time_elapsed         | 251         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.015275711 |
|    clip_fraction        | 0.0121      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0281     |
|    explained_variance   | -0.257      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00462    |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00845    |
|    value_loss           | 0.00392     |
-----------------------------------------
Output 65: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 522           |
|    iterations           | 65            |
|    time_elapsed         | 254           |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 0.00014866202 |
|    clip_fraction        | 0.00151       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0161       |
|    explained_variance   | 0.879         |
|    learning_rate        | 0.0003        |
|    loss                 | 7.41e-05      |
|    n_updates            | 640           |
|    policy_gradient_loss | -0.000585     |
|    value_loss           | 8.52e-06      |
-------------------------------------------
Output 66: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 522           |
|    iterations           | 66            |
|    time_elapsed         | 258           |
|    total_timesteps      | 135168        |
| train/                  |               |
|    approx_kl            | 0.00047223264 |
|    clip_fraction        | 0.00273       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0111       |
|    explained_variance   | 0.665         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000337      |
|    n_updates            | 650           |
|    policy_gradient_loss | -0.00342      |
|    value_loss           | 5.87e-05      |
-------------------------------------------
Output 67: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 523           |
|    iterations           | 67            |
|    time_elapsed         | 262           |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 9.2193455e-05 |
|    clip_fraction        | 0.000537      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00885      |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000274      |
|    n_updates            | 660           |
|    policy_gradient_loss | -0.000559     |
|    value_loss           | 3.91e-07      |
-------------------------------------------
Output 68: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 68            |
|    time_elapsed         | 265           |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00015750702 |
|    clip_fraction        | 0.00132       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00575      |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | -3.38e-05     |
|    n_updates            | 670           |
|    policy_gradient_loss | -0.00203      |
|    value_loss           | 6.47e-07      |
-------------------------------------------
Output 69: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 69            |
|    time_elapsed         | 269           |
|    total_timesteps      | 141312        |
| train/                  |               |
|    approx_kl            | 2.2470776e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00585      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00144      |
|    n_updates            | 680           |
|    policy_gradient_loss | -0.000336     |
|    value_loss           | 8.55e-10      |
-------------------------------------------
Output 70: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 70           |
|    time_elapsed         | 272          |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0017848094 |
|    clip_fraction        | 0.00142      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00687     |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00179     |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00251     |
|    value_loss           | 1.03e-07     |
------------------------------------------
Output 71: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 71           |
|    time_elapsed         | 276          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0003652146 |
|    clip_fraction        | 0.00171      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0063      |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000331     |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00219     |
|    value_loss           | 8.19e-07     |
------------------------------------------
Output 72: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 526           |
|    iterations           | 72            |
|    time_elapsed         | 279           |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00021480443 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00405      |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | -7.82e-05     |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000795     |
|    value_loss           | 2.35e-07      |
-------------------------------------------
Output 73: Average over 53 episodes - Reward: 0.9622641509433962
----------------------------------------
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 73         |
|    time_elapsed         | 283        |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.45978245 |
|    clip_fraction        | 0.149      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0698    |
|    explained_variance   | 1          |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0772    |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 7.4e-10    |
----------------------------------------
Output 74: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 527        |
|    iterations           | 74         |
|    time_elapsed         | 287        |
|    total_timesteps      | 151552     |
| train/                  |            |
|    approx_kl            | 0.12862726 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.461     |
|    explained_variance   | 0.00231    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0174    |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.0242    |
|    value_loss           | 0.00268    |
----------------------------------------
Output 75: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 75          |
|    time_elapsed         | 291         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.008243544 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.366      |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.031      |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0308     |
|    value_loss           | 0.00153     |
-----------------------------------------
Output 76: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 76          |
|    time_elapsed         | 294         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.026573837 |
|    clip_fraction        | 0.438       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.366      |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0709     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0619     |
|    value_loss           | 0.000553    |
-----------------------------------------
Output 77: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 77         |
|    time_elapsed         | 298        |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.06549874 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.256     |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0561    |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0581    |
|    value_loss           | 0.000283   |
----------------------------------------
Output 78: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 78          |
|    time_elapsed         | 302         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.016886093 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.157      |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0546     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 8.15e-05    |
-----------------------------------------
Output 79: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 527        |
|    iterations           | 79         |
|    time_elapsed         | 306        |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 0.03433241 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0718    |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0251    |
|    n_updates            | 780        |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 3.78e-05   |
----------------------------------------
Output 80: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 80          |
|    time_elapsed         | 311         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.027212624 |
|    clip_fraction        | 0.0183      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0219     |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00841    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 9.51e-06    |
-----------------------------------------
Output 81: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 81            |
|    time_elapsed         | 315           |
|    total_timesteps      | 165888        |
| train/                  |               |
|    approx_kl            | 0.00033224118 |
|    clip_fraction        | 0.000586      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0119       |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00351      |
|    n_updates            | 800           |
|    policy_gradient_loss | -0.000264     |
|    value_loss           | 4.6e-07       |
-------------------------------------------
Output 82: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 82            |
|    time_elapsed         | 319           |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 0.00073159643 |
|    clip_fraction        | 0.00425       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0137       |
|    explained_variance   | 0.993         |
|    learning_rate        | 0.0003        |
|    loss                 | -4.28e-05     |
|    n_updates            | 810           |
|    policy_gradient_loss | -0.00504      |
|    value_loss           | 2.08e-06      |
-------------------------------------------
Output 83: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 83           |
|    time_elapsed         | 324          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0005519813 |
|    clip_fraction        | 0.00229      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00854     |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000134    |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.003       |
|    value_loss           | 1.5e-06      |
------------------------------------------
Output 84: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 84            |
|    time_elapsed         | 327           |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 0.00032585693 |
|    clip_fraction        | 0.00127       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00666      |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.000166     |
|    n_updates            | 830           |
|    policy_gradient_loss | -0.00131      |
|    value_loss           | 4.74e-07      |
-------------------------------------------
Output 85: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 85            |
|    time_elapsed         | 331           |
|    total_timesteps      | 174080        |
| train/                  |               |
|    approx_kl            | 0.00023629851 |
|    clip_fraction        | 0.00142       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00902      |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0003        |
|    n_updates            | 840           |
|    policy_gradient_loss | -0.00201      |
|    value_loss           | 7.63e-07      |
-------------------------------------------
Output 86: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 86            |
|    time_elapsed         | 335           |
|    total_timesteps      | 176128        |
| train/                  |               |
|    approx_kl            | 0.00044725052 |
|    clip_fraction        | 0.00352       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0128       |
|    explained_variance   | 0.356         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000177      |
|    n_updates            | 850           |
|    policy_gradient_loss | -0.00354      |
|    value_loss           | 9.83e-06      |
-------------------------------------------
Output 87: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 87          |
|    time_elapsed         | 339         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.006098825 |
|    clip_fraction        | 0.00332     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0047     |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0167     |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00344    |
|    value_loss           | 3.06e-07    |
-----------------------------------------
Output 88: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 88            |
|    time_elapsed         | 343           |
|    total_timesteps      | 180224        |
| train/                  |               |
|    approx_kl            | 1.7523416e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00401      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.000321     |
|    n_updates            | 870           |
|    policy_gradient_loss | -0.000201     |
|    value_loss           | 1.69e-09      |
-------------------------------------------
Output 89: Average over 100 episodes - Reward: 0.98
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 89          |
|    time_elapsed         | 347         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.030337682 |
|    clip_fraction        | 0.00693     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0092     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0372     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00334    |
|    value_loss           | 4.46e-07    |
-----------------------------------------
Output 90: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 90          |
|    time_elapsed         | 351         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.005886345 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.0322      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0191      |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00507    |
|    value_loss           | 0.0117      |
-----------------------------------------
Output 91: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 91          |
|    time_elapsed         | 355         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.002097738 |
|    clip_fraction        | 0.016       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.0942      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00513     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.001      |
|    value_loss           | 0.00195     |
-----------------------------------------
Output 92: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 92           |
|    time_elapsed         | 359          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0021182909 |
|    clip_fraction        | 0.0585       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.893        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00482     |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00169     |
|    value_loss           | 1.88e-06     |
------------------------------------------
Output 93: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 93          |
|    time_elapsed         | 363         |
|    total_timesteps      | 190464      |
| train/                  |             |
|    approx_kl            | 0.003432044 |
|    clip_fraction        | 0.0963      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000398    |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00599    |
|    value_loss           | 4.88e-08    |
-----------------------------------------
Output 94: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 94           |
|    time_elapsed         | 367          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0034878012 |
|    clip_fraction        | 0.0455       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.126       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0206       |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.00143     |
|    value_loss           | 3.32e-11     |
------------------------------------------
Output 95: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 95           |
|    time_elapsed         | 370          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0014720141 |
|    clip_fraction        | 0.028        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000471    |
|    n_updates            | 940          |
|    policy_gradient_loss | -3.38e-05    |
|    value_loss           | 2.08e-13     |
------------------------------------------
Output 96: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 96           |
|    time_elapsed         | 374          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 9.533175e-05 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 2.55e-06     |
|    n_updates            | 950          |
|    policy_gradient_loss | 0.000951     |
|    value_loss           | 2.55e-15     |
------------------------------------------
Output 97: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 97           |
|    time_elapsed         | 378          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0028868674 |
|    clip_fraction        | 0.0379       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0.135        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0119      |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00179     |
|    value_loss           | 0.00198      |
------------------------------------------
Output 98: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 98          |
|    time_elapsed         | 381         |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 0.001927211 |
|    clip_fraction        | 0.077       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00321    |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00225    |
|    value_loss           | 3.13e-06    |
-----------------------------------------
Output 99: Average over 100 episodes - Reward: 0.48
----------------------------------------
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 99         |
|    time_elapsed         | 385        |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.06015517 |
|    clip_fraction        | 0.0983     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.17      |
|    explained_variance   | 0.998      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0265    |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.0168    |
|    value_loss           | 2.94e-07   |
----------------------------------------
Output 100: Average over 100 episodes - Reward: 0.81
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 100         |
|    time_elapsed         | 389         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.073347434 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.255      |
|    explained_variance   | 0.00716     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0509      |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.169       |
-----------------------------------------
Output 101: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 526       |
|    iterations           | 101       |
|    time_elapsed         | 392       |
|    total_timesteps      | 206848    |
| train/                  |           |
|    approx_kl            | 0.1024346 |
|    clip_fraction        | 0.173     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.179    |
|    explained_variance   | -0.053    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0124   |
|    n_updates            | 1000      |
|    policy_gradient_loss | -0.0421   |
|    value_loss           | 0.0873    |
---------------------------------------
Output 102: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 102          |
|    time_elapsed         | 396          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0075094206 |
|    clip_fraction        | 0.12         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.163       |
|    explained_variance   | -8.49        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00595     |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.00718     |
|    value_loss           | 0.000764     |
------------------------------------------
Output 103: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 103         |
|    time_elapsed         | 400         |
|    total_timesteps      | 210944      |
| train/                  |             |
|    approx_kl            | 0.057779532 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.205      |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0665     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0296     |
|    value_loss           | 7.45e-06    |
-----------------------------------------
Output 104: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 525        |
|    iterations           | 104        |
|    time_elapsed         | 405        |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.02890331 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.282     |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0271    |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.0484    |
|    value_loss           | 0.000123   |
----------------------------------------
Output 105: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 105         |
|    time_elapsed         | 409         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.053700514 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.205      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0331     |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0423     |
|    value_loss           | 5.52e-05    |
-----------------------------------------
Output 106: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 525       |
|    iterations           | 106       |
|    time_elapsed         | 413       |
|    total_timesteps      | 217088    |
| train/                  |           |
|    approx_kl            | 0.0726821 |
|    clip_fraction        | 0.0688    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.155    |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0315   |
|    n_updates            | 1050      |
|    policy_gradient_loss | -0.0214   |
|    value_loss           | 1.19e-05  |
---------------------------------------
Output 107: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 107         |
|    time_elapsed         | 417         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.015470378 |
|    clip_fraction        | 0.0302      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.138      |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0259     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00353    |
|    value_loss           | 1.05e-06    |
-----------------------------------------
Output 108: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 108          |
|    time_elapsed         | 421          |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0043997588 |
|    clip_fraction        | 0.0753       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.139       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000754    |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00362     |
|    value_loss           | 2.27e-07     |
------------------------------------------
Output 109: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 109          |
|    time_elapsed         | 425          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0031100498 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0126      |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00171     |
|    value_loss           | 2.26e-07     |
------------------------------------------
Output 110: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 110         |
|    time_elapsed         | 428         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.001311864 |
|    clip_fraction        | 0.0128      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.0763      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00542     |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0023     |
|    value_loss           | 0.00387     |
-----------------------------------------
Output 111: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 111          |
|    time_elapsed         | 432          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0069368607 |
|    clip_fraction        | 0.0932       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.127       |
|    explained_variance   | 0.0436       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0184      |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00788     |
|    value_loss           | 0.00772      |
------------------------------------------
Output 112: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 112          |
|    time_elapsed         | 436          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0014606285 |
|    clip_fraction        | 0.00688      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0.367        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.86e-05     |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.000102    |
|    value_loss           | 5.26e-06     |
------------------------------------------
Output 113: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 113          |
|    time_elapsed         | 440          |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 0.0011450573 |
|    clip_fraction        | 0.0386       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0.135        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0108      |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 0.00194      |
------------------------------------------
Output 114: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 114        |
|    time_elapsed         | 443        |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.02139366 |
|    clip_fraction        | 0.122      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.151     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00143   |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 1.98e-06   |
----------------------------------------
Output 115: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 115          |
|    time_elapsed         | 447          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0016451557 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.172       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0208      |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00273     |
|    value_loss           | 1.14e-08     |
------------------------------------------
Output 116: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 116         |
|    time_elapsed         | 451         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.002748047 |
|    clip_fraction        | 0.0107      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00692     |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.000257    |
|    value_loss           | 4.73e-11    |
-----------------------------------------
Output 117: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 117          |
|    time_elapsed         | 455          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0036054915 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.169       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00424     |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00329     |
|    value_loss           | 2.33e-07     |
------------------------------------------
Output 118: Average over 100 episodes - Reward: 0.66
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 118         |
|    time_elapsed         | 459         |
|    total_timesteps      | 241664      |
| train/                  |             |
|    approx_kl            | 0.017215833 |
|    clip_fraction        | 0.081       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.203      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0421     |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 3.28e-10    |
-----------------------------------------
Output 119: Average over 100 episodes - Reward: 0.93
---------------------------------------
| time/                   |           |
|    fps                  | 524       |
|    iterations           | 119       |
|    time_elapsed         | 464       |
|    total_timesteps      | 243712    |
| train/                  |           |
|    approx_kl            | 0.0496531 |
|    clip_fraction        | 0.239     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.215    |
|    explained_variance   | 0.0162    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0419    |
|    n_updates            | 1180      |
|    policy_gradient_loss | -0.0423   |
|    value_loss           | 0.144     |
---------------------------------------
Output 120: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 120         |
|    time_elapsed         | 468         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.051617544 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.158      |
|    explained_variance   | -0.149      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00259    |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.0439      |
-----------------------------------------
Output 121: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 524        |
|    iterations           | 121        |
|    time_elapsed         | 472        |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.07296798 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.183     |
|    explained_variance   | -0.573     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0727    |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.00209    |
----------------------------------------
Output 122: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 122         |
|    time_elapsed         | 476         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.022237718 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.461      |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0574     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0595     |
|    value_loss           | 0.000293    |
-----------------------------------------
Output 123: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 515        |
|    iterations           | 123        |
|    time_elapsed         | 488        |
|    total_timesteps      | 251904     |
| train/                  |            |
|    approx_kl            | 0.03452906 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.365     |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0958    |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0605    |
|    value_loss           | 0.00014    |
----------------------------------------
Output 124: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 124         |
|    time_elapsed         | 494         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.032406606 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.27       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.038      |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 7.32e-05    |
-----------------------------------------
Output 125: Average over 100 episodes - Reward: 0.96
-----------------------------------------
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 125         |
|    time_elapsed         | 498         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.012753302 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.203      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0326     |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0376     |
|    value_loss           | 2.01e-05    |
-----------------------------------------
Output 126: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 512       |
|    iterations           | 126       |
|    time_elapsed         | 503       |
|    total_timesteps      | 258048    |
| train/                  |           |
|    approx_kl            | 0.0116098 |
|    clip_fraction        | 0.0742    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.19     |
|    explained_variance   | 0.0191    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00943   |
|    n_updates            | 1250      |
|    policy_gradient_loss | -0.00966  |
|    value_loss           | 0.0257    |
---------------------------------------
Output 127: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 127          |
|    time_elapsed         | 507          |
|    total_timesteps      | 260096       |
| train/                  |              |
|    approx_kl            | 0.0072780615 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.187       |
|    explained_variance   | 0.0251       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00247      |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.0053      |
|    value_loss           | 0.00383      |
------------------------------------------
Output 128: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 512        |
|    iterations           | 128        |
|    time_elapsed         | 511        |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.00440746 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.209     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00153   |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.00609   |
|    value_loss           | 1.56e-05   |
----------------------------------------
Output 129: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 129         |
|    time_elapsed         | 515         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.005655849 |
|    clip_fraction        | 0.0837      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.172      |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0328      |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.00546    |
|    value_loss           | 0.00193     |
-----------------------------------------
Output 130: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 130         |
|    time_elapsed         | 519         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.007954779 |
|    clip_fraction        | 0.0916      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.152      |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00475    |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00455    |
|    value_loss           | 2.76e-06    |
-----------------------------------------
Output 131: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 131          |
|    time_elapsed         | 523          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0011284873 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.165       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000561    |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00195     |
|    value_loss           | 8.29e-07     |
------------------------------------------
Output 132: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 132          |
|    time_elapsed         | 527          |
|    total_timesteps      | 270336       |
| train/                  |              |
|    approx_kl            | 0.0077514625 |
|    clip_fraction        | 0.0508       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0.0763       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00126      |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00516     |
|    value_loss           | 0.00387      |
------------------------------------------
Output 133: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 133         |
|    time_elapsed         | 531         |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.023631785 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.174      |
|    explained_variance   | 0.0988      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0283      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0119     |
|    value_loss           | 0.00195     |
-----------------------------------------
Output 134: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 513        |
|    iterations           | 134        |
|    time_elapsed         | 534        |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.00442267 |
|    clip_fraction        | 0.0668     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.271     |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0275    |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.0206    |
|    value_loss           | 5.2e-05    |
----------------------------------------
Output 135: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 135         |
|    time_elapsed         | 538         |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.028299801 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.199      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0485     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0438     |
|    value_loss           | 4.2e-05     |
-----------------------------------------
Output 136: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 136         |
|    time_elapsed         | 542         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.051473666 |
|    clip_fraction        | 0.0789      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.209      |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0161     |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0349     |
|    value_loss           | 0.00264     |
-----------------------------------------
Output 137: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 137          |
|    time_elapsed         | 545          |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 0.0061823674 |
|    clip_fraction        | 0.0994       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.172       |
|    explained_variance   | 0.777        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00237      |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00552     |
|    value_loss           | 2.68e-06     |
------------------------------------------
Output 138: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 513         |
|    iterations           | 138         |
|    time_elapsed         | 549         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.015359763 |
|    clip_fraction        | 0.0928      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0248     |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 6.79e-07    |
-----------------------------------------
Output 139: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 139         |
|    time_elapsed         | 553         |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.016176555 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.252      |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.058      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 4.25e-05    |
-----------------------------------------
Output 140: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 513        |
|    iterations           | 140        |
|    time_elapsed         | 557        |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.07156935 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.171     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0642    |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.0546    |
|    value_loss           | 3.86e-05   |
----------------------------------------
Output 141: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 513          |
|    iterations           | 141          |
|    time_elapsed         | 561          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0057819746 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.132       |
|    explained_variance   | 0.981        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.016       |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00899     |
|    value_loss           | 8.88e-07     |
------------------------------------------
Output 142: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 142         |
|    time_elapsed         | 565         |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 0.010374842 |
|    clip_fraction        | 0.0575      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0204     |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00387    |
|    value_loss           | 4.74e-07    |
-----------------------------------------
Output 143: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 143          |
|    time_elapsed         | 569          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0010524376 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0822      |
|    explained_variance   | 0.135        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00543      |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.0022      |
|    value_loss           | 0.00199      |
------------------------------------------
Output 144: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 144         |
|    time_elapsed         | 573         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.013367552 |
|    clip_fraction        | 0.0482      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0128      |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.002      |
|    value_loss           | 3.74e-06    |
-----------------------------------------
Output 145: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 514          |
|    iterations           | 145          |
|    time_elapsed         | 576          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0098536955 |
|    clip_fraction        | 0.0721       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0352       |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.00132     |
|    value_loss           | 1.75e-08     |
------------------------------------------
Output 146: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 146         |
|    time_elapsed         | 580         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.023273146 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0684     |
|    explained_variance   | 0.135       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00533     |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00132    |
|    value_loss           | 0.00197     |
-----------------------------------------
Output 147: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 147         |
|    time_elapsed         | 584         |
|    total_timesteps      | 301056      |
| train/                  |             |
|    approx_kl            | 0.058688648 |
|    clip_fraction        | 0.0753      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00273     |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.0235      |
|    value_loss           | 0.00189     |
-----------------------------------------
Output 148: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 148         |
|    time_elapsed         | 588         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.005878003 |
|    clip_fraction        | 0.0605      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.187      |
|    explained_variance   | -1.84       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0129     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00794    |
|    value_loss           | 7.43e-05    |
-----------------------------------------
Output 149: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 515       |
|    iterations           | 149       |
|    time_elapsed         | 592       |
|    total_timesteps      | 305152    |
| train/                  |           |
|    approx_kl            | 0.0434833 |
|    clip_fraction        | 0.0756    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.109    |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.018    |
|    n_updates            | 1480      |
|    policy_gradient_loss | -0.0207   |
|    value_loss           | 3.05e-05  |
---------------------------------------
Output 150: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 150         |
|    time_elapsed         | 595         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.038209245 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0455     |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0173     |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0127     |
|    value_loss           | 4.33e-06    |
-----------------------------------------
Output 151: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 515         |
|    iterations           | 151         |
|    time_elapsed         | 599         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.012694922 |
|    clip_fraction        | 0.0478      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0579     |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0441     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.00196     |
-----------------------------------------
Output 152: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 515          |
|    iterations           | 152          |
|    time_elapsed         | 603          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0024129115 |
|    clip_fraction        | 0.0479       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.673        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0251      |
|    n_updates            | 1510         |
|    policy_gradient_loss | -0.0125      |
|    value_loss           | 3.33e-05     |
------------------------------------------
Output 153: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 515       |
|    iterations           | 153       |
|    time_elapsed         | 607       |
|    total_timesteps      | 313344    |
| train/                  |           |
|    approx_kl            | 0.0536049 |
|    clip_fraction        | 0.198     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0344   |
|    explained_variance   | 0.914     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0364   |
|    n_updates            | 1520      |
|    policy_gradient_loss | -0.0328   |
|    value_loss           | 2.87e-05  |
---------------------------------------
Output 154: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 516         |
|    iterations           | 154         |
|    time_elapsed         | 610         |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.011702733 |
|    clip_fraction        | 0.00786     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00945    |
|    explained_variance   | 0.986       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00619    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00987    |
|    value_loss           | 3.33e-06    |
-----------------------------------------
Output 155: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 155          |
|    time_elapsed         | 614          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0011227893 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00828     |
|    explained_variance   | 0.319        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000112    |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.0123      |
|    value_loss           | 0.00095      |
------------------------------------------
Output 156: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 156         |
|    time_elapsed         | 617         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.012612118 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0818     |
|    explained_variance   | 0.0606      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.083      |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.00549     |
-----------------------------------------
Output 157: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 157         |
|    time_elapsed         | 621         |
|    total_timesteps      | 321536      |
| train/                  |             |
|    approx_kl            | 0.030372893 |
|    clip_fraction        | 0.0425      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.142      |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000454   |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00346    |
|    value_loss           | 2.68e-05    |
-----------------------------------------
Output 158: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 158         |
|    time_elapsed         | 625         |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.039923433 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0472     |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00669    |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.000433    |
-----------------------------------------
Output 159: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 159          |
|    time_elapsed         | 629          |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 0.0033517224 |
|    clip_fraction        | 0.00601      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0248      |
|    explained_variance   | 0.963        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00273     |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00351     |
|    value_loss           | 2.86e-06     |
------------------------------------------
Output 160: Average over 100 episodes - Reward: 0.45
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 160         |
|    time_elapsed         | 632         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.067208424 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0376     |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0247     |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0085     |
|    value_loss           | 1.16e-06    |
-----------------------------------------
Output 161: Average over 100 episodes - Reward: 0.82
----------------------------------------
| time/                   |            |
|    fps                  | 517        |
|    iterations           | 161        |
|    time_elapsed         | 636        |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.08026756 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.102     |
|    explained_variance   | 0.00569    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0441     |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0406    |
|    value_loss           | 0.174      |
----------------------------------------
Output 162: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 517        |
|    iterations           | 162        |
|    time_elapsed         | 640        |
|    total_timesteps      | 331776     |
| train/                  |            |
|    approx_kl            | 0.20818406 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | -0.102     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00212    |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0621    |
|    value_loss           | 0.106      |
----------------------------------------
Output 163: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 163          |
|    time_elapsed         | 644          |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 0.0045146616 |
|    clip_fraction        | 0.0719       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.262       |
|    explained_variance   | -11.9        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00199     |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.000936    |
|    value_loss           | 0.00113      |
------------------------------------------
Output 164: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 164         |
|    time_elapsed         | 648         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.018600766 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.224      |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0233      |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 8e-05       |
-----------------------------------------
Output 165: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 165        |
|    time_elapsed         | 651        |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.06472302 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0767    |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0532    |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0428    |
|    value_loss           | 4.71e-05   |
----------------------------------------
Output 166: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 166         |
|    time_elapsed         | 655         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.008217967 |
|    clip_fraction        | 0.0129      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0377     |
|    explained_variance   | 0.99        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0287     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 2.86e-06    |
-----------------------------------------
Output 167: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 167          |
|    time_elapsed         | 659          |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 0.0057613505 |
|    clip_fraction        | 0.0083       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0186      |
|    explained_variance   | 0.0765       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00673     |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00304     |
|    value_loss           | 0.00381      |
------------------------------------------
Output 168: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 168         |
|    time_elapsed         | 663         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.031996954 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0917     |
|    explained_variance   | 0.979       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0551     |
|    n_updates            | 1670        |
|    policy_gradient_loss | 0.0921      |
|    value_loss           | 1.16e-06    |
-----------------------------------------
Output 169: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 169         |
|    time_elapsed         | 666         |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.056223758 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0553     |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0337     |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0344     |
|    value_loss           | 4.42e-05    |
-----------------------------------------
Output 170: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 170        |
|    time_elapsed         | 671        |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.01946678 |
|    clip_fraction        | 0.00762    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00927   |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0296    |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0135    |
|    value_loss           | 3.95e-06   |
----------------------------------------
Output 171: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 171         |
|    time_elapsed         | 675         |
|    total_timesteps      | 350208      |
| train/                  |             |
|    approx_kl            | 0.007025689 |
|    clip_fraction        | 0.0516      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.041      |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0134     |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.00193     |
-----------------------------------------
Output 172: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 172         |
|    time_elapsed         | 678         |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.093694836 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0139     |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0354     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0372     |
|    value_loss           | 2.37e-05    |
-----------------------------------------
Output 173: Average over 47 episodes - Reward: 0.9574468085106383
----------------------------------------
| time/                   |            |
|    fps                  | 519        |
|    iterations           | 173        |
|    time_elapsed         | 682        |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.50095356 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.999      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0874    |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0696    |
|    value_loss           | 1.04e-07   |
----------------------------------------
Output 174: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 174         |
|    time_elapsed         | 685         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.119256936 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.46       |
|    explained_variance   | 0.0173      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0119      |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.00254     |
-----------------------------------------
Output 175: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 175         |
|    time_elapsed         | 689         |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.014967771 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.44       |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0341     |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0369     |
|    value_loss           | 0.00258     |
-----------------------------------------
Output 176: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 520        |
|    iterations           | 176        |
|    time_elapsed         | 692        |
|    total_timesteps      | 360448     |
| train/                  |            |
|    approx_kl            | 0.02341931 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.405     |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0637    |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0617    |
|    value_loss           | 0.000743   |
----------------------------------------
Output 177: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 177         |
|    time_elapsed         | 696         |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.018157467 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.327      |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0803     |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0584     |
|    value_loss           | 0.000246    |
-----------------------------------------
Output 178: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 520        |
|    iterations           | 178        |
|    time_elapsed         | 700        |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.04281885 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.224     |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0611    |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0498    |
|    value_loss           | 0.00013    |
----------------------------------------
Output 179: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 179         |
|    time_elapsed         | 703         |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.040553372 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0546     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0428     |
|    value_loss           | 3.24e-05    |
-----------------------------------------
Output 180: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 180          |
|    time_elapsed         | 707          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0037690555 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0741      |
|    explained_variance   | 0.986        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.028       |
|    n_updates            | 1790         |
|    policy_gradient_loss | -0.0107      |
|    value_loss           | 3.42e-06     |
------------------------------------------
Output 181: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 521         |
|    iterations           | 181         |
|    time_elapsed         | 711         |
|    total_timesteps      | 370688      |
| train/                  |             |
|    approx_kl            | 0.024535496 |
|    clip_fraction        | 0.0172      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0248     |
|    explained_variance   | 0.989       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00238    |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 3.27e-06    |
-----------------------------------------
Output 182: Average over 100 episodes - Reward: 0.3
----------------------------------------
| time/                   |            |
|    fps                  | 521        |
|    iterations           | 182        |
|    time_elapsed         | 714        |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.12737618 |
|    clip_fraction        | 0.0549     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0406    |
|    explained_variance   | 0.998      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0159    |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0175    |
|    value_loss           | 4.64e-07   |
----------------------------------------
Output 183: Average over 88 episodes - Reward: 0.6477272727272727
----------------------------------------
| time/                   |            |
|    fps                  | 521        |
|    iterations           | 183        |
|    time_elapsed         | 718        |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.12885761 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.159     |
|    explained_variance   | 0.0166     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0194     |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0454    |
|    value_loss           | 0.134      |
----------------------------------------
Output 184: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 521        |
|    iterations           | 184        |
|    time_elapsed         | 722        |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.31469417 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.149     |
|    explained_variance   | 0.0598     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.112     |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0365    |
|    value_loss           | 0.0252     |
----------------------------------------
Output 185: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 521        |
|    iterations           | 185        |
|    time_elapsed         | 726        |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.06563662 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.127     |
|    explained_variance   | 0.156      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0479    |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.00599    |
----------------------------------------
Output 186: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 186          |
|    time_elapsed         | 730          |
|    total_timesteps      | 380928       |
| train/                  |              |
|    approx_kl            | 0.0072224806 |
|    clip_fraction        | 0.213        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.206       |
|    explained_variance   | -0.178       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.022       |
|    n_updates            | 1850         |
|    policy_gradient_loss | -0.0243      |
|    value_loss           | 0.00018      |
------------------------------------------
Output 187: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 521         |
|    iterations           | 187         |
|    time_elapsed         | 734         |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.009987278 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.155      |
|    explained_variance   | 0.175       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0548     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0399     |
|    value_loss           | 0.00167     |
-----------------------------------------
Output 188: Average over 100 episodes - Reward: 0.99
----------------------------------------
| time/                   |            |
|    fps                  | 520        |
|    iterations           | 188        |
|    time_elapsed         | 739        |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.03174333 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0662    |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0514    |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.026     |
|    value_loss           | 3.35e-05   |
----------------------------------------
Output 189: Average over 100 episodes - Reward: 0.99
----------------------------------------
| time/                   |            |
|    fps                  | 520        |
|    iterations           | 189        |
|    time_elapsed         | 743        |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.03383645 |
|    clip_fraction        | 0.0181     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0169    |
|    explained_variance   | 0.171      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0045    |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.014     |
|    value_loss           | 0.0016     |
----------------------------------------
Output 190: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 520           |
|    iterations           | 190           |
|    time_elapsed         | 748           |
|    total_timesteps      | 389120        |
| train/                  |               |
|    approx_kl            | 0.00065978325 |
|    clip_fraction        | 0.00244       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00635      |
|    explained_variance   | -0.0257       |
|    learning_rate        | 0.0003        |
|    loss                 | -0.000548     |
|    n_updates            | 1890          |
|    policy_gradient_loss | -0.0036       |
|    value_loss           | 0.00341       |
-------------------------------------------
Output 191: Average over 38 episodes - Reward: 0.6842105263157895
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 191         |
|    time_elapsed         | 752         |
|    total_timesteps      | 391168      |
| train/                  |             |
|    approx_kl            | 0.113623604 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0147     |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00522    |
|    value_loss           | 2e-06       |
-----------------------------------------
Output 192: Average over 84 episodes - Reward: 0.9880952380952381
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 192         |
|    time_elapsed         | 757         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.021599311 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.789      |
|    explained_variance   | -0.351      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0433     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0232     |
|    value_loss           | 0.0151      |
-----------------------------------------
Output 193: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 193         |
|    time_elapsed         | 761         |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.011709952 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.668      |
|    explained_variance   | 0.325       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0568     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0303     |
|    value_loss           | 0.015       |
-----------------------------------------
Output 194: Average over 100 episodes - Reward: 0.38
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 194         |
|    time_elapsed         | 766         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.030335478 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0489     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 0.0114      |
-----------------------------------------
Output 195: Average over 100 episodes - Reward: 0.84
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 195        |
|    time_elapsed         | 770        |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.05961606 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | -0.0407    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0263     |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.13       |
----------------------------------------
Output 196: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 196         |
|    time_elapsed         | 773         |
|    total_timesteps      | 401408      |
| train/                  |             |
|    approx_kl            | 0.052203607 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | -0.0343     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0252     |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.0616      |
-----------------------------------------
Output 197: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 197         |
|    time_elapsed         | 777         |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.009525564 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.43       |
|    explained_variance   | 0.0852      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0538     |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.0343     |
|    value_loss           | 0.00929     |
-----------------------------------------
Output 198: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 198         |
|    time_elapsed         | 781         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.012403684 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.248      |
|    explained_variance   | -0.0377     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0432     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.00117     |
-----------------------------------------
Output 199: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 199         |
|    time_elapsed         | 786         |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.092901215 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.201       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0548     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0422     |
|    value_loss           | 0.00258     |
-----------------------------------------
Output 200: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 200         |
|    time_elapsed         | 790         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.002041428 |
|    clip_fraction        | 0.0405      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0261     |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 4.05e-05    |
-----------------------------------------
Output 201: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 201         |
|    time_elapsed         | 795         |
|    total_timesteps      | 411648      |
| train/                  |             |
|    approx_kl            | 0.036064602 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.046      |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0435     |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0237     |
|    value_loss           | 0.00195     |
-----------------------------------------
Output 202: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 202           |
|    time_elapsed         | 799           |
|    total_timesteps      | 413696        |
| train/                  |               |
|    approx_kl            | 0.00060761574 |
|    clip_fraction        | 0.00503       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0309       |
|    explained_variance   | 0.945         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.0089       |
|    n_updates            | 2010          |
|    policy_gradient_loss | -0.00274      |
|    value_loss           | 5.92e-06      |
-------------------------------------------
Output 203: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 203           |
|    time_elapsed         | 803           |
|    total_timesteps      | 415744        |
| train/                  |               |
|    approx_kl            | 0.00027976814 |
|    clip_fraction        | 0.0064        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0191       |
|    explained_variance   | 0.986         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.0296       |
|    n_updates            | 2020          |
|    policy_gradient_loss | -0.00634      |
|    value_loss           | 3.84e-06      |
-------------------------------------------
Output 204: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 204           |
|    time_elapsed         | 807           |
|    total_timesteps      | 417792        |
| train/                  |               |
|    approx_kl            | 0.00028694046 |
|    clip_fraction        | 0.00337       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0172       |
|    explained_variance   | 0.994         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00135       |
|    n_updates            | 2030          |
|    policy_gradient_loss | -0.00402      |
|    value_loss           | 1.78e-06      |
-------------------------------------------
Output 205: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 205          |
|    time_elapsed         | 811          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0050301924 |
|    clip_fraction        | 0.00288      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00727     |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000892    |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.00544     |
|    value_loss           | 1.34e-06     |
------------------------------------------
Output 206: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 206           |
|    time_elapsed         | 814           |
|    total_timesteps      | 421888        |
| train/                  |               |
|    approx_kl            | 0.00019012712 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00494      |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.000116     |
|    n_updates            | 2050          |
|    policy_gradient_loss | -0.00125      |
|    value_loss           | 7.7e-07       |
-------------------------------------------
Output 207: Average over 100 episodes - Reward: 0.15
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 207        |
|    time_elapsed         | 818        |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.17273842 |
|    clip_fraction        | 0.0612     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0322    |
|    explained_variance   | 1          |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0339    |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0115    |
|    value_loss           | 6.98e-10   |
----------------------------------------
Output 208: Average over 100 episodes - Reward: 0.72
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 208        |
|    time_elapsed         | 821        |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.22339553 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.0149     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0114     |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0417    |
|    value_loss           | 0.114      |
----------------------------------------
Output 209: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 518       |
|    iterations           | 209       |
|    time_elapsed         | 825       |
|    total_timesteps      | 428032    |
| train/                  |           |
|    approx_kl            | 0.3540065 |
|    clip_fraction        | 0.252     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0543   |
|    explained_variance   | -0.253    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.016    |
|    n_updates            | 2080      |
|    policy_gradient_loss | -0.0562   |
|    value_loss           | 0.112     |
---------------------------------------
Output 210: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 518         |
|    iterations           | 210         |
|    time_elapsed         | 829         |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.013122258 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.273      |
|    explained_variance   | -12.7       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00932    |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0038     |
|    value_loss           | 0.002       |
-----------------------------------------
Output 211: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 518        |
|    iterations           | 211        |
|    time_elapsed         | 832        |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.07171131 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.174     |
|    explained_variance   | 0.459      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0409    |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.0002     |
----------------------------------------
Output 212: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 212         |
|    time_elapsed         | 836         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.046704784 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0409     |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.036      |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0306     |
|    value_loss           | 3.47e-05    |
-----------------------------------------
Output 213: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 213          |
|    time_elapsed         | 840          |
|    total_timesteps      | 436224       |
| train/                  |              |
|    approx_kl            | 0.0017617152 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0236      |
|    explained_variance   | 0.983        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000457     |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.00879     |
|    value_loss           | 4.9e-06      |
------------------------------------------
Output 214: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 214          |
|    time_elapsed         | 844          |
|    total_timesteps      | 438272       |
| train/                  |              |
|    approx_kl            | 0.0011949928 |
|    clip_fraction        | 0.00552      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0202      |
|    explained_variance   | 0.167        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00015     |
|    n_updates            | 2130         |
|    policy_gradient_loss | -0.005       |
|    value_loss           | 0.00159      |
------------------------------------------
Output 215: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 215           |
|    time_elapsed         | 848           |
|    total_timesteps      | 440320        |
| train/                  |               |
|    approx_kl            | 0.00027694518 |
|    clip_fraction        | 0.00186       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0133       |
|    explained_variance   | 0.166         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000321      |
|    n_updates            | 2140          |
|    policy_gradient_loss | -0.00154      |
|    value_loss           | 0.00159       |
-------------------------------------------
Output 216: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 519        |
|    iterations           | 216        |
|    time_elapsed         | 851        |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.11412075 |
|    clip_fraction        | 0.0736     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0561    |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0231    |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0103    |
|    value_loss           | 1.46e-06   |
----------------------------------------
Output 217: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 519        |
|    iterations           | 217        |
|    time_elapsed         | 855        |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.05501329 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.391     |
|    explained_variance   | 0.0711     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0583    |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0611    |
|    value_loss           | 0.00124    |
----------------------------------------
Output 218: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 218         |
|    time_elapsed         | 859         |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.018322106 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.305      |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0367     |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0437     |
|    value_loss           | 0.000443    |
-----------------------------------------
Output 219: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 519        |
|    iterations           | 219        |
|    time_elapsed         | 862        |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.00960817 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.581      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0364    |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0491    |
|    value_loss           | 0.00022    |
----------------------------------------
Output 220: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 220         |
|    time_elapsed         | 866         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.008419463 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.195      |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0294     |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 7.7e-05     |
-----------------------------------------
Output 221: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 221         |
|    time_elapsed         | 869         |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.031732537 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.054      |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0441     |
|    value_loss           | 3.79e-05    |
-----------------------------------------
Output 222: Average over 100 episodes - Reward: 0.76
----------------------------------------
| time/                   |            |
|    fps                  | 520        |
|    iterations           | 222        |
|    time_elapsed         | 873        |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.09576306 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0693    |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0575    |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.033     |
|    value_loss           | 0.00161    |
----------------------------------------
Output 223: Average over 100 episodes - Reward: 0.98
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 223         |
|    time_elapsed         | 876         |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.083250135 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0174     |
|    explained_variance   | 0.0119      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0143      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0292     |
|    value_loss           | 0.114       |
-----------------------------------------
Output 224: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 224          |
|    time_elapsed         | 880          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0048896396 |
|    clip_fraction        | 0.00381      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00953     |
|    explained_variance   | -0.367       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00142     |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.0035      |
|    value_loss           | 0.00811      |
------------------------------------------
Output 225: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 225          |
|    time_elapsed         | 884          |
|    total_timesteps      | 460800       |
| train/                  |              |
|    approx_kl            | 4.186353e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00664     |
|    explained_variance   | 0.548        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000967    |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 1.22e-05     |
------------------------------------------
Output 226: Average over 100 episodes - Reward: 0.98
-------------------------------------------
| time/                   |               |
|    fps                  | 521           |
|    iterations           | 226           |
|    time_elapsed         | 887           |
|    total_timesteps      | 462848        |
| train/                  |               |
|    approx_kl            | 0.00072316977 |
|    clip_fraction        | 0.00132       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00782      |
|    explained_variance   | 0.135         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00481       |
|    n_updates            | 2250          |
|    policy_gradient_loss | 0.00131       |
|    value_loss           | 0.00191       |
-------------------------------------------
Output 227: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 521           |
|    iterations           | 227           |
|    time_elapsed         | 891           |
|    total_timesteps      | 464896        |
| train/                  |               |
|    approx_kl            | 0.00010110959 |
|    clip_fraction        | 0.000977      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00986      |
|    explained_variance   | 0.057         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.012         |
|    n_updates            | 2260          |
|    policy_gradient_loss | -0.00156      |
|    value_loss           | 0.00569       |
-------------------------------------------
Output 228: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 521        |
|    iterations           | 228        |
|    time_elapsed         | 894        |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.13767052 |
|    clip_fraction        | 0.0966     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.132     |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0617    |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 1.46e-06   |
----------------------------------------
Output 229: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 229         |
|    time_elapsed         | 898         |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.023256809 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.538      |
|    explained_variance   | 0.052       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0482     |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0383     |
|    value_loss           | 0.00164     |
-----------------------------------------
Output 230: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 230         |
|    time_elapsed         | 901         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.009908862 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.399      |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0578     |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0399     |
|    value_loss           | 0.00108     |
-----------------------------------------
Output 231: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 231         |
|    time_elapsed         | 905         |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.014651705 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.277      |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0534     |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0419     |
|    value_loss           | 0.000547    |
-----------------------------------------
Output 232: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 232         |
|    time_elapsed         | 909         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.014023146 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0406     |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0428     |
|    value_loss           | 0.000143    |
-----------------------------------------
Output 233: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 522         |
|    iterations           | 233         |
|    time_elapsed         | 912         |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.024725547 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0865     |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0215     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0214     |
|    value_loss           | 0.00199     |
-----------------------------------------
Output 234: Average over 100 episodes - Reward: 1.0
---------------------------------------
| time/                   |           |
|    fps                  | 523       |
|    iterations           | 234       |
|    time_elapsed         | 916       |
|    total_timesteps      | 479232    |
| train/                  |           |
|    approx_kl            | 0.0339495 |
|    clip_fraction        | 0.0158    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0164   |
|    explained_variance   | 0.921     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0261   |
|    n_updates            | 2330      |
|    policy_gradient_loss | -0.0169   |
|    value_loss           | 2.29e-05  |
---------------------------------------
Output 235: Average over 82 episodes - Reward: 0.1951219512195122
----------------------------------------
| time/                   |            |
|    fps                  | 523        |
|    iterations           | 235        |
|    time_elapsed         | 919        |
|    total_timesteps      | 481280     |
| train/                  |            |
|    approx_kl            | 0.34094393 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.135     |
|    explained_variance   | 0.994      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0128    |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0172    |
|    value_loss           | 1.19e-06   |
----------------------------------------
Output 236: Average over 59 episodes - Reward: 0.5084745762711864
-----------------------------------------
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 236         |
|    time_elapsed         | 923         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.014196388 |
|    clip_fraction        | 0.0676      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | -0.0953     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0257      |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0174     |
|    value_loss           | 0.0715      |
-----------------------------------------
Output 237: Average over 49 episodes - Reward: 0.7755102040816326
-----------------------------------------
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 237         |
|    time_elapsed         | 926         |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.008490555 |
|    clip_fraction        | 0.0693      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.189      |
|    explained_variance   | -0.0491     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0241      |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.0515      |
-----------------------------------------
Output 238: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 238         |
|    time_elapsed         | 929         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.040982686 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.292      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00383    |
|    value_loss           | 0.0351      |
-----------------------------------------
Output 239: Average over 100 episodes - Reward: 0.43
----------------------------------------
| time/                   |            |
|    fps                  | 524        |
|    iterations           | 239        |
|    time_elapsed         | 932        |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.03552676 |
|    clip_fraction        | 0.124      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.284     |
|    explained_variance   | 0.0269     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0121    |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0282    |
|    value_loss           | 0.0188     |
----------------------------------------
Output 240: Average over 100 episodes - Reward: 0.61
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 240          |
|    time_elapsed         | 936          |
|    total_timesteps      | 491520       |
| train/                  |              |
|    approx_kl            | 0.0068540196 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.304       |
|    explained_variance   | -0.0318      |
|    learning_rate        | 0.0003       |
|    loss                 | 0.049        |
|    n_updates            | 2390         |
|    policy_gradient_loss | -0.0271      |
|    value_loss           | 0.138        |
------------------------------------------
Output 241: Average over 100 episodes - Reward: 0.86
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 241         |
|    time_elapsed         | 939         |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.015234603 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.284      |
|    explained_variance   | 0.0708      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0507      |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.028      |
|    value_loss           | 0.132       |
-----------------------------------------
Output 242: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 242         |
|    time_elapsed         | 942         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.059879962 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.308      |
|    explained_variance   | 0.0305      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00366     |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0364     |
|    value_loss           | 0.0673      |
-----------------------------------------
Output 243: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 243         |
|    time_elapsed         | 946         |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.035169095 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.389      |
|    explained_variance   | -0.29       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0387     |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0236     |
|    value_loss           | 0.00454     |
-----------------------------------------
Output 244: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 526        |
|    iterations           | 244        |
|    time_elapsed         | 949        |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.01202821 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.4       |
|    explained_variance   | 0.0801     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0181    |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.00285    |
----------------------------------------
Output 245: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 245         |
|    time_elapsed         | 953         |
|    total_timesteps      | 501760      |
| train/                  |             |
|    approx_kl            | 0.023337647 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.314      |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0695     |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.00186     |
-----------------------------------------
Overall: Average Reward: 0.9463636363636364
```
# 4x4 frozen lake map PPO - is_slippery on
```
Using cpu device
Logging to ./PPOtensorboard/PPO_2
Output 1: Average over 100 episodes - Reward: 0.02
-----------------------------
| time/              |      |
|    fps             | 910  |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
Output 2: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 637         |
|    iterations           | 2           |
|    time_elapsed         | 6           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011759092 |
|    clip_fraction        | 0.0239      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -1.43       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0204      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00675    |
|    value_loss           | 0.0152      |
-----------------------------------------
Output 3: Average over 100 episodes - Reward: 0.01
-----------------------------------------
| time/                   |             |
|    fps                  | 604         |
|    iterations           | 3           |
|    time_elapsed         | 10          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.018131863 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0244     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 0.022       |
-----------------------------------------
Output 4: Average over 100 episodes - Reward: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 589         |
|    iterations           | 4           |
|    time_elapsed         | 13          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.013373062 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0201     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0081     |
|    value_loss           | 0.0177      |
-----------------------------------------
Output 5: Average over 100 episodes - Reward: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 584         |
|    iterations           | 5           |
|    time_elapsed         | 17          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.014359696 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.29       |
|    explained_variance   | 0.109       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00103    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.0189      |
-----------------------------------------
Output 6: Average over 100 episodes - Reward: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 567         |
|    iterations           | 6           |
|    time_elapsed         | 21          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.008946655 |
|    clip_fraction        | 0.0532      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00817    |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00636    |
|    value_loss           | 0.0218      |
-----------------------------------------
Output 7: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 560         |
|    iterations           | 7           |
|    time_elapsed         | 25          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.009846981 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00539    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.0366      |
-----------------------------------------
Output 8: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 8           |
|    time_elapsed         | 30          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013054941 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.13       |
|    explained_variance   | 0.0709      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0324     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.0176      |
-----------------------------------------
Output 9: Average over 100 episodes - Reward: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 9           |
|    time_elapsed         | 33          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.007603651 |
|    clip_fraction        | 0.0999      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0104     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00985    |
|    value_loss           | 0.0203      |
-----------------------------------------
Output 10: Average over 100 episodes - Reward: 0.13
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 10          |
|    time_elapsed         | 37          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.008516686 |
|    clip_fraction        | 0.0708      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.016       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00811    |
|    value_loss           | 0.0378      |
-----------------------------------------
Output 11: Average over 100 episodes - Reward: 0.08
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 11          |
|    time_elapsed         | 41          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.013390456 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.942      |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00452    |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.0655      |
-----------------------------------------
Output 12: Average over 100 episodes - Reward: 0.16
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 12          |
|    time_elapsed         | 45          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.006245424 |
|    clip_fraction        | 0.0802      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.855      |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0111      |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00883    |
|    value_loss           | 0.0393      |
-----------------------------------------
Output 13: Average over 100 episodes - Reward: 0.13
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 13          |
|    time_elapsed         | 49          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.009041596 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.787      |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0235      |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00892    |
|    value_loss           | 0.0541      |
-----------------------------------------
Output 14: Average over 100 episodes - Reward: 0.13
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 14          |
|    time_elapsed         | 52          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.008766474 |
|    clip_fraction        | 0.086       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.705      |
|    explained_variance   | -0.0146     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.058       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00669    |
|    value_loss           | 0.0599      |
-----------------------------------------
Output 15: Average over 100 episodes - Reward: 0.15
------------------------------------------
| time/                   |              |
|    fps                  | 544          |
|    iterations           | 15           |
|    time_elapsed         | 56           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0044650272 |
|    clip_fraction        | 0.0604       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.637       |
|    explained_variance   | 0.0925       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0254       |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00673     |
|    value_loss           | 0.0458       |
------------------------------------------
Output 16: Average over 100 episodes - Reward: 0.19
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 16           |
|    time_elapsed         | 60           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0065571903 |
|    clip_fraction        | 0.064        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.612       |
|    explained_variance   | 0.11         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0187       |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0065      |
|    value_loss           | 0.0544       |
------------------------------------------
Output 17: Average over 96 episodes - Reward: 0.2916666666666667
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 17          |
|    time_elapsed         | 63          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.003240789 |
|    clip_fraction        | 0.0479      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.548      |
|    explained_variance   | 0.0775      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0235      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00512    |
|    value_loss           | 0.0571      |
-----------------------------------------
Output 18: Average over 98 episodes - Reward: 0.15306122448979592
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 18          |
|    time_elapsed         | 67          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.002738592 |
|    clip_fraction        | 0.0301      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.502      |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0158      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0035     |
|    value_loss           | 0.0643      |
-----------------------------------------
Output 19: Average over 86 episodes - Reward: 0.23255813953488372
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 19          |
|    time_elapsed         | 70          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.013955073 |
|    clip_fraction        | 0.0884      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.411      |
|    explained_variance   | 0.09        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000393    |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00822    |
|    value_loss           | 0.0478      |
-----------------------------------------
Output 20: Average over 81 episodes - Reward: 0.32098765432098764
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 20          |
|    time_elapsed         | 73          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.002251668 |
|    clip_fraction        | 0.0406      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.351      |
|    explained_variance   | 0.124       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0185      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00393    |
|    value_loss           | 0.054       |
-----------------------------------------
Output 21: Average over 77 episodes - Reward: 0.4155844155844156
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 21           |
|    time_elapsed         | 77           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0032955778 |
|    clip_fraction        | 0.0442       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.324       |
|    explained_variance   | 0.0584       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0231       |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00482     |
|    value_loss           | 0.0676       |
------------------------------------------
Output 22: Average over 77 episodes - Reward: 0.45454545454545453
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 22           |
|    time_elapsed         | 81           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0017685595 |
|    clip_fraction        | 0.0308       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.298       |
|    explained_variance   | 0.0995       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0294       |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00348     |
|    value_loss           | 0.0685       |
------------------------------------------
Output 23: Average over 69 episodes - Reward: 0.42028985507246375
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 23           |
|    time_elapsed         | 85           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0019462605 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.262       |
|    explained_variance   | 0.113        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0146       |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00391     |
|    value_loss           | 0.0703       |
------------------------------------------
Output 24: Average over 59 episodes - Reward: 0.3220338983050847
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 24          |
|    time_elapsed         | 88          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.001574968 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.252      |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0292      |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00284    |
|    value_loss           | 0.0605      |
-----------------------------------------
Output 25: Average over 67 episodes - Reward: 0.3582089552238806
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 25           |
|    time_elapsed         | 92           |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 0.0015776232 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.222       |
|    explained_variance   | 0.0778       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0427       |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 0.0477       |
------------------------------------------
Output 26: Average over 53 episodes - Reward: 0.5471698113207547
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 26           |
|    time_elapsed         | 96           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0019995533 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.222       |
|    explained_variance   | 0.0581       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00982      |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.0054      |
|    value_loss           | 0.0589       |
------------------------------------------
Output 27: Average over 73 episodes - Reward: 0.3698630136986301
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 27           |
|    time_elapsed         | 100          |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0014885871 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.196       |
|    explained_variance   | 0.129        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0165       |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 0.0535       |
------------------------------------------
Output 28: Average over 59 episodes - Reward: 0.5254237288135594
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 28           |
|    time_elapsed         | 104          |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0025128606 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.203       |
|    explained_variance   | 0.124        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0103       |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00444     |
|    value_loss           | 0.0602       |
------------------------------------------
Output 29: Average over 62 episodes - Reward: 0.45161290322580644
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 29           |
|    time_elapsed         | 107          |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0017638915 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.195       |
|    explained_variance   | 0.1          |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0138       |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00296     |
|    value_loss           | 0.0612       |
------------------------------------------
Output 30: Average over 58 episodes - Reward: 0.46551724137931033
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 30           |
|    time_elapsed         | 111          |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 0.0018271065 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.181       |
|    explained_variance   | 0.0961       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0187       |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00361     |
|    value_loss           | 0.0579       |
------------------------------------------
Output 31: Average over 58 episodes - Reward: 0.5689655172413793
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 31           |
|    time_elapsed         | 115          |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0017547107 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.169       |
|    explained_variance   | 0.07         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0136       |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0027      |
|    value_loss           | 0.0558       |
------------------------------------------
Output 32: Average over 55 episodes - Reward: 0.43636363636363634
------------------------------------------
| time/                   |              |
|    fps                  | 544          |
|    iterations           | 32           |
|    time_elapsed         | 120          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0011948969 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.158       |
|    explained_variance   | 0.122        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0316       |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00311     |
|    value_loss           | 0.056        |
------------------------------------------
Output 33: Average over 55 episodes - Reward: 0.5636363636363636
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 33           |
|    time_elapsed         | 125          |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0018023378 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0.0757       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0327       |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00263     |
|    value_loss           | 0.0509       |
------------------------------------------
Output 34: Average over 54 episodes - Reward: 0.5555555555555556
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 34           |
|    time_elapsed         | 129          |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0016387149 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.169       |
|    explained_variance   | 0.132        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0402       |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.0015      |
|    value_loss           | 0.0509       |
------------------------------------------
Output 35: Average over 50 episodes - Reward: 0.44
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 35           |
|    time_elapsed         | 133          |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 0.0015316681 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.154       |
|    explained_variance   | 0.0855       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0182       |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00338     |
|    value_loss           | 0.0544       |
------------------------------------------
Output 36: Average over 55 episodes - Reward: 0.41818181818181815
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 36           |
|    time_elapsed         | 137          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0012915332 |
|    clip_fraction        | 0.015        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0.142        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00763      |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.002       |
|    value_loss           | 0.0442       |
------------------------------------------
Output 37: Average over 52 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 37           |
|    time_elapsed         | 141          |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0021371394 |
|    clip_fraction        | 0.0282       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.125       |
|    explained_variance   | 0.114        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0238       |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00388     |
|    value_loss           | 0.0479       |
------------------------------------------
Output 38: Average over 67 episodes - Reward: 0.5074626865671642
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 38           |
|    time_elapsed         | 145          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0010672399 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.126        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0157       |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00243     |
|    value_loss           | 0.0495       |
------------------------------------------
Output 39: Average over 61 episodes - Reward: 0.6557377049180327
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 39           |
|    time_elapsed         | 148          |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0016045854 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.128       |
|    explained_variance   | 0.0971       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0259       |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 0.0633       |
------------------------------------------
Output 40: Average over 54 episodes - Reward: 0.6296296296296297
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 40           |
|    time_elapsed         | 152          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0012650255 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0.15         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0222       |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 0.0558       |
------------------------------------------
Output 41: Average over 56 episodes - Reward: 0.6785714285714286
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 41           |
|    time_elapsed         | 155          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0014877559 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0867      |
|    explained_variance   | 0.184        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00302      |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00293     |
|    value_loss           | 0.0474       |
------------------------------------------
Output 42: Average over 61 episodes - Reward: 0.6229508196721312
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 42            |
|    time_elapsed         | 159           |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 0.00095942966 |
|    clip_fraction        | 0.0132        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0869       |
|    explained_variance   | 0.179         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0157        |
|    n_updates            | 410           |
|    policy_gradient_loss | -0.00209      |
|    value_loss           | 0.0483        |
-------------------------------------------
Output 43: Average over 59 episodes - Reward: 0.6779661016949152
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 43           |
|    time_elapsed         | 163          |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0011996623 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0747      |
|    explained_variance   | 0.162        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0234       |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00306     |
|    value_loss           | 0.0531       |
------------------------------------------
Output 44: Average over 47 episodes - Reward: 0.723404255319149
------------------------------------------
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 44           |
|    time_elapsed         | 168          |
|    total_timesteps      | 90112        |
| train/                  |              |
|    approx_kl            | 0.0007060744 |
|    clip_fraction        | 0.00977      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0757      |
|    explained_variance   | 0.149        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0216       |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 0.052        |
------------------------------------------
Output 45: Average over 48 episodes - Reward: 0.5625
------------------------------------------
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 45           |
|    time_elapsed         | 172          |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0006596346 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0701      |
|    explained_variance   | 0.216        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00791      |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 0.0361       |
------------------------------------------
Output 46: Average over 48 episodes - Reward: 0.625
------------------------------------------
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 46           |
|    time_elapsed         | 176          |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0007465207 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0548      |
|    explained_variance   | 0.183        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0205       |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00266     |
|    value_loss           | 0.0437       |
------------------------------------------
Output 47: Average over 53 episodes - Reward: 0.7735849056603774
-------------------------------------------
| time/                   |               |
|    fps                  | 532           |
|    iterations           | 47            |
|    time_elapsed         | 180           |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 0.00047021804 |
|    clip_fraction        | 0.00962       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0578       |
|    explained_variance   | 0.115         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0201        |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.00227      |
|    value_loss           | 0.0471        |
-------------------------------------------
Output 48: Average over 47 episodes - Reward: 0.5957446808510638
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 48          |
|    time_elapsed         | 185         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.009291668 |
|    clip_fraction        | 0.00659     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.08       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0116      |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00109    |
|    value_loss           | 0.0407      |
-----------------------------------------
Output 49: Average over 55 episodes - Reward: 0.6
-------------------------------------------
| time/                   |               |
|    fps                  | 528           |
|    iterations           | 49            |
|    time_elapsed         | 189           |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 0.00090887287 |
|    clip_fraction        | 0.0209        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.112        |
|    explained_variance   | 0.179         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0129        |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.00234      |
|    value_loss           | 0.0418        |
-------------------------------------------
Output 50: Average over 56 episodes - Reward: 0.6428571428571429
------------------------------------------
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 50           |
|    time_elapsed         | 194          |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0017146834 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0964      |
|    explained_variance   | 0.143        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0251       |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00295     |
|    value_loss           | 0.0467       |
------------------------------------------
Output 51: Average over 45 episodes - Reward: 0.5111111111111111
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 51           |
|    time_elapsed         | 198          |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0006749025 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0925      |
|    explained_variance   | 0.198        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0203       |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.000885    |
|    value_loss           | 0.0459       |
------------------------------------------
Output 52: Average over 54 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 52           |
|    time_elapsed         | 202          |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0013776425 |
|    clip_fraction        | 0.00981      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0766      |
|    explained_variance   | 0.141        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00834      |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.000412    |
|    value_loss           | 0.0382       |
------------------------------------------
Output 53: Average over 52 episodes - Reward: 0.8461538461538461
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 53            |
|    time_elapsed         | 206           |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 0.00094938243 |
|    clip_fraction        | 0.0151        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0683       |
|    explained_variance   | 0.222         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00788       |
|    n_updates            | 520           |
|    policy_gradient_loss | -0.0025       |
|    value_loss           | 0.0486        |
-------------------------------------------
Output 54: Average over 57 episodes - Reward: 0.6666666666666666
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 54            |
|    time_elapsed         | 210           |
|    total_timesteps      | 110592        |
| train/                  |               |
|    approx_kl            | 0.00096126297 |
|    clip_fraction        | 0.00737       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0688       |
|    explained_variance   | 0.294         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0183        |
|    n_updates            | 530           |
|    policy_gradient_loss | -0.00117      |
|    value_loss           | 0.0343        |
-------------------------------------------
Output 55: Average over 43 episodes - Reward: 0.6511627906976745
-------------------------------------------
| time/                   |               |
|    fps                  | 527           |
|    iterations           | 55            |
|    time_elapsed         | 213           |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 0.00060952315 |
|    clip_fraction        | 0.00669       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0564       |
|    explained_variance   | 0.164         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0342        |
|    n_updates            | 540           |
|    policy_gradient_loss | -0.000583     |
|    value_loss           | 0.0459        |
-------------------------------------------
Output 56: Average over 54 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 56           |
|    time_elapsed         | 217          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0005073134 |
|    clip_fraction        | 0.00879      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0539      |
|    explained_variance   | 0.171        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0205       |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 0.0349       |
------------------------------------------
Output 57: Average over 49 episodes - Reward: 0.7142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 57           |
|    time_elapsed         | 221          |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0011366992 |
|    clip_fraction        | 0.0118       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0484      |
|    explained_variance   | 0.125        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0157       |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000555    |
|    value_loss           | 0.0431       |
------------------------------------------
Output 58: Average over 55 episodes - Reward: 0.5636363636363636
-------------------------------------------
| time/                   |               |
|    fps                  | 527           |
|    iterations           | 58            |
|    time_elapsed         | 225           |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 0.00042007098 |
|    clip_fraction        | 0.00552       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0498       |
|    explained_variance   | 0.185         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0291        |
|    n_updates            | 570           |
|    policy_gradient_loss | -0.000387     |
|    value_loss           | 0.0359        |
-------------------------------------------
Output 59: Average over 57 episodes - Reward: 0.6491228070175439
------------------------------------------
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 59           |
|    time_elapsed         | 229          |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 0.0013147304 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0527      |
|    explained_variance   | 0.188        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0342       |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00165     |
|    value_loss           | 0.0453       |
------------------------------------------
Output 60: Average over 55 episodes - Reward: 0.7272727272727273
------------------------------------------
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 60           |
|    time_elapsed         | 232          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0005868763 |
|    clip_fraction        | 0.00688      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0491      |
|    explained_variance   | 0.194        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0292       |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.000837    |
|    value_loss           | 0.048        |
------------------------------------------
Output 61: Average over 57 episodes - Reward: 0.6491228070175439
-------------------------------------------
| time/                   |               |
|    fps                  | 528           |
|    iterations           | 61            |
|    time_elapsed         | 236           |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 0.00049428607 |
|    clip_fraction        | 0.00962       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0452       |
|    explained_variance   | 0.166         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0231        |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.0009       |
|    value_loss           | 0.0458        |
-------------------------------------------
Output 62: Average over 50 episodes - Reward: 0.72
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 62           |
|    time_elapsed         | 240          |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0013355683 |
|    clip_fraction        | 0.00684      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0449      |
|    explained_variance   | 0.12         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0184       |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00118     |
|    value_loss           | 0.0509       |
------------------------------------------
Output 63: Average over 49 episodes - Reward: 0.673469387755102
-------------------------------------------
| time/                   |               |
|    fps                  | 528           |
|    iterations           | 63            |
|    time_elapsed         | 244           |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 0.00043953225 |
|    clip_fraction        | 0.00703       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.031        |
|    explained_variance   | 0.153         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0261        |
|    n_updates            | 620           |
|    policy_gradient_loss | -0.000694     |
|    value_loss           | 0.0399        |
-------------------------------------------
Output 64: Average over 49 episodes - Reward: 0.6530612244897959
------------------------------------------
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 64           |
|    time_elapsed         | 247          |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0003621345 |
|    clip_fraction        | 0.00449      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0245      |
|    explained_variance   | 0.142        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0231       |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.000921    |
|    value_loss           | 0.0442       |
------------------------------------------
Output 65: Average over 54 episodes - Reward: 0.7407407407407407
-------------------------------------------
| time/                   |               |
|    fps                  | 529           |
|    iterations           | 65            |
|    time_elapsed         | 251           |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 0.00037078318 |
|    clip_fraction        | 0.00596       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0282       |
|    explained_variance   | 0.138         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0206        |
|    n_updates            | 640           |
|    policy_gradient_loss | -0.0011       |
|    value_loss           | 0.0427        |
-------------------------------------------
Output 66: Average over 56 episodes - Reward: 0.6071428571428571
-------------------------------------------
| time/                   |               |
|    fps                  | 527           |
|    iterations           | 66            |
|    time_elapsed         | 256           |
|    total_timesteps      | 135168        |
| train/                  |               |
|    approx_kl            | 0.00046620186 |
|    clip_fraction        | 0.00405       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0255       |
|    explained_variance   | 0.229         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.017         |
|    n_updates            | 650           |
|    policy_gradient_loss | -0.000294     |
|    value_loss           | 0.039         |
-------------------------------------------
Output 67: Average over 48 episodes - Reward: 0.7916666666666666
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 67            |
|    time_elapsed         | 264           |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 0.00029627225 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0206       |
|    explained_variance   | 0.138         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0248        |
|    n_updates            | 660           |
|    policy_gradient_loss | -0.00163      |
|    value_loss           | 0.0497        |
-------------------------------------------
Output 68: Average over 55 episodes - Reward: 0.7636363636363637
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 68            |
|    time_elapsed         | 268           |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00083030347 |
|    clip_fraction        | 0.00181       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0165       |
|    explained_variance   | 0.15          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0143        |
|    n_updates            | 670           |
|    policy_gradient_loss | -0.000876     |
|    value_loss           | 0.0328        |
-------------------------------------------
Output 69: Average over 45 episodes - Reward: 0.7777777777777778
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 69           |
|    time_elapsed         | 272          |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 0.0008672685 |
|    clip_fraction        | 0.00503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0164      |
|    explained_variance   | 0.197        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0175       |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 0.038        |
------------------------------------------
Output 70: Average over 57 episodes - Reward: 0.7894736842105263
-------------------------------------------
| time/                   |               |
|    fps                  | 518           |
|    iterations           | 70            |
|    time_elapsed         | 276           |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 0.00029841604 |
|    clip_fraction        | 0.0042        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0165       |
|    explained_variance   | 0.187         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0142        |
|    n_updates            | 690           |
|    policy_gradient_loss | -0.00058      |
|    value_loss           | 0.0277        |
-------------------------------------------
Output 71: Average over 58 episodes - Reward: 0.6896551724137931
------------------------------------------
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 71           |
|    time_elapsed         | 279          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 4.988801e-05 |
|    clip_fraction        | 0.000781     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0178      |
|    explained_variance   | 0.149        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0197       |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.000142    |
|    value_loss           | 0.0361       |
------------------------------------------
Output 72: Average over 47 episodes - Reward: 0.7446808510638298
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 72            |
|    time_elapsed         | 283           |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00042893848 |
|    clip_fraction        | 0.00371       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0209       |
|    explained_variance   | 0.162         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0297        |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000144     |
|    value_loss           | 0.0443        |
-------------------------------------------
Output 73: Average over 48 episodes - Reward: 0.7083333333333334
------------------------------------------
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 73           |
|    time_elapsed         | 287          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0006143631 |
|    clip_fraction        | 0.00347      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0196      |
|    explained_variance   | 0.207        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0133       |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.000778    |
|    value_loss           | 0.0329       |
------------------------------------------
Output 74: Average over 51 episodes - Reward: 0.7450980392156863
-------------------------------------------
| time/                   |               |
|    fps                  | 521           |
|    iterations           | 74            |
|    time_elapsed         | 290           |
|    total_timesteps      | 151552        |
| train/                  |               |
|    approx_kl            | 0.00058600644 |
|    clip_fraction        | 0.0042        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0157       |
|    explained_variance   | 0.135         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.019         |
|    n_updates            | 730           |
|    policy_gradient_loss | -0.00138      |
|    value_loss           | 0.034         |
-------------------------------------------
Output 75: Average over 52 episodes - Reward: 0.7692307692307693
-------------------------------------------
| time/                   |               |
|    fps                  | 520           |
|    iterations           | 75            |
|    time_elapsed         | 294           |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 0.00094482215 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.014        |
|    explained_variance   | 0.186         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0191        |
|    n_updates            | 740           |
|    policy_gradient_loss | -0.00132      |
|    value_loss           | 0.0353        |
-------------------------------------------
Output 76: Average over 52 episodes - Reward: 0.7307692307692307
-----------------------------------------
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 76          |
|    time_elapsed         | 299         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.000200846 |
|    clip_fraction        | 0.00288     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0115     |
|    explained_variance   | 0.241       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0166      |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.000585   |
|    value_loss           | 0.0363      |
-----------------------------------------
Output 77: Average over 44 episodes - Reward: 0.6590909090909091
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 77            |
|    time_elapsed         | 303           |
|    total_timesteps      | 157696        |
| train/                  |               |
|    approx_kl            | 0.00062166963 |
|    clip_fraction        | 0.00205       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0164       |
|    explained_variance   | 0.21          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0293        |
|    n_updates            | 760           |
|    policy_gradient_loss | -0.000409     |
|    value_loss           | 0.0407        |
-------------------------------------------
Output 78: Average over 44 episodes - Reward: 0.7727272727272727
------------------------------------------
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 78           |
|    time_elapsed         | 307          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0003419726 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0123      |
|    explained_variance   | 0.145        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0221       |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00161     |
|    value_loss           | 0.033        |
------------------------------------------
Output 79: Average over 59 episodes - Reward: 0.7457627118644068
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 79           |
|    time_elapsed         | 311          |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 0.0006669709 |
|    clip_fraction        | 0.00518      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0184      |
|    explained_variance   | 0.239        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0126       |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00116     |
|    value_loss           | 0.0269       |
------------------------------------------
Output 80: Average over 56 episodes - Reward: 0.6607142857142857
-------------------------------------------
| time/                   |               |
|    fps                  | 518           |
|    iterations           | 80            |
|    time_elapsed         | 316           |
|    total_timesteps      | 163840        |
| train/                  |               |
|    approx_kl            | 0.00013641248 |
|    clip_fraction        | 0.00269       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0241       |
|    explained_variance   | 0.183         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.017         |
|    n_updates            | 790           |
|    policy_gradient_loss | -0.00023      |
|    value_loss           | 0.0402        |
-------------------------------------------
Output 81: Average over 51 episodes - Reward: 0.7450980392156863
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 81           |
|    time_elapsed         | 319          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0007337489 |
|    clip_fraction        | 0.00459      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0212      |
|    explained_variance   | 0.193        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0141       |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.000878    |
|    value_loss           | 0.0426       |
------------------------------------------
Output 82: Average over 54 episodes - Reward: 0.7962962962962963
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 82            |
|    time_elapsed         | 323           |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 0.00048018238 |
|    clip_fraction        | 0.00332       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0137       |
|    explained_variance   | 0.225         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0174        |
|    n_updates            | 810           |
|    policy_gradient_loss | -0.00105      |
|    value_loss           | 0.0379        |
-------------------------------------------
Output 83: Average over 54 episodes - Reward: 0.7592592592592593
-------------------------------------------
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 83            |
|    time_elapsed         | 326           |
|    total_timesteps      | 169984        |
| train/                  |               |
|    approx_kl            | 0.00050552265 |
|    clip_fraction        | 0.00479       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0129       |
|    explained_variance   | 0.227         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0148        |
|    n_updates            | 820           |
|    policy_gradient_loss | -0.000914     |
|    value_loss           | 0.0363        |
-------------------------------------------
Output 84: Average over 47 episodes - Reward: 0.6382978723404256
------------------------------------------
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 84           |
|    time_elapsed         | 330          |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 0.0011615122 |
|    clip_fraction        | 0.00293      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0195      |
|    explained_variance   | 0.168        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0216       |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.000703    |
|    value_loss           | 0.0355       |
------------------------------------------
Output 85: Average over 47 episodes - Reward: 0.574468085106383
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 85           |
|    time_elapsed         | 333          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0007271331 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.036       |
|    explained_variance   | 0.142        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0157       |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00163     |
|    value_loss           | 0.0346       |
------------------------------------------
Output 86: Average over 53 episodes - Reward: 0.7358490566037735
------------------------------------------
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 86           |
|    time_elapsed         | 337          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0018951688 |
|    clip_fraction        | 0.0137       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0378      |
|    explained_variance   | 0.21         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0223       |
|    n_updates            | 850          |
|    policy_gradient_loss | -0.00129     |
|    value_loss           | 0.0373       |
------------------------------------------
Output 87: Average over 52 episodes - Reward: 0.5961538461538461
-------------------------------------------
| time/                   |               |
|    fps                  | 523           |
|    iterations           | 87            |
|    time_elapsed         | 340           |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 0.00074766786 |
|    clip_fraction        | 0.011         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0359       |
|    explained_variance   | 0.205         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0316        |
|    n_updates            | 860           |
|    policy_gradient_loss | -0.00186      |
|    value_loss           | 0.0394        |
-------------------------------------------
Output 88: Average over 41 episodes - Reward: 0.6341463414634146
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 88           |
|    time_elapsed         | 344          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0010426112 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0283      |
|    explained_variance   | 0.198        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0142       |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 0.0405       |
------------------------------------------
Output 89: Average over 55 episodes - Reward: 0.6545454545454545
-------------------------------------------
| time/                   |               |
|    fps                  | 523           |
|    iterations           | 89            |
|    time_elapsed         | 348           |
|    total_timesteps      | 182272        |
| train/                  |               |
|    approx_kl            | 0.00027150224 |
|    clip_fraction        | 0.00684       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0212       |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0192        |
|    n_updates            | 880           |
|    policy_gradient_loss | -0.00101      |
|    value_loss           | 0.0368        |
-------------------------------------------
Output 90: Average over 54 episodes - Reward: 0.6851851851851852
-------------------------------------------
| time/                   |               |
|    fps                  | 522           |
|    iterations           | 90            |
|    time_elapsed         | 352           |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 0.00037707883 |
|    clip_fraction        | 0.00361       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0219       |
|    explained_variance   | 0.114         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0195        |
|    n_updates            | 890           |
|    policy_gradient_loss | -0.000687     |
|    value_loss           | 0.0472        |
-------------------------------------------
Output 91: Average over 56 episodes - Reward: 0.7857142857142857
-------------------------------------------
| time/                   |               |
|    fps                  | 522           |
|    iterations           | 91            |
|    time_elapsed         | 356           |
|    total_timesteps      | 186368        |
| train/                  |               |
|    approx_kl            | 0.00044050053 |
|    clip_fraction        | 0.00376       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0184       |
|    explained_variance   | 0.139         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0248        |
|    n_updates            | 900           |
|    policy_gradient_loss | -0.000422     |
|    value_loss           | 0.0429        |
-------------------------------------------
Output 92: Average over 48 episodes - Reward: 0.75
------------------------------------------
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 92           |
|    time_elapsed         | 361          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0004714257 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0136      |
|    explained_variance   | 0.236        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0131       |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.000834    |
|    value_loss           | 0.0379       |
------------------------------------------
Output 93: Average over 53 episodes - Reward: 0.8301886792452831
-------------------------------------------
| time/                   |               |
|    fps                  | 520           |
|    iterations           | 93            |
|    time_elapsed         | 366           |
|    total_timesteps      | 190464        |
| train/                  |               |
|    approx_kl            | 0.00016294586 |
|    clip_fraction        | 0.00195       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0109       |
|    explained_variance   | 0.129         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0244        |
|    n_updates            | 920           |
|    policy_gradient_loss | -0.000628     |
|    value_loss           | 0.0348        |
-------------------------------------------
Output 94: Average over 48 episodes - Reward: 0.7708333333333334
------------------------------------------
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 94           |
|    time_elapsed         | 370          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0014486826 |
|    clip_fraction        | 0.00273      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0117      |
|    explained_variance   | 0.162        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0134       |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.000683    |
|    value_loss           | 0.0324       |
------------------------------------------
Output 95: Average over 46 episodes - Reward: 0.6086956521739131
-------------------------------------------
| time/                   |               |
|    fps                  | 518           |
|    iterations           | 95            |
|    time_elapsed         | 375           |
|    total_timesteps      | 194560        |
| train/                  |               |
|    approx_kl            | 0.00082427054 |
|    clip_fraction        | 0.00723       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.016        |
|    explained_variance   | 0.207         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0103        |
|    n_updates            | 940           |
|    policy_gradient_loss | -0.00164      |
|    value_loss           | 0.0273        |
-------------------------------------------
Output 96: Average over 50 episodes - Reward: 0.72
-------------------------------------------
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 96            |
|    time_elapsed         | 379           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00036438246 |
|    clip_fraction        | 0.00508       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0203       |
|    explained_variance   | 0.222         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0116        |
|    n_updates            | 950           |
|    policy_gradient_loss | -0.0012       |
|    value_loss           | 0.0317        |
-------------------------------------------
Output 97: Average over 44 episodes - Reward: 0.6818181818181818
-----------------------------------------
| time/                   |             |
|    fps                  | 517         |
|    iterations           | 97          |
|    time_elapsed         | 384         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.001066285 |
|    clip_fraction        | 0.00435     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0315     |
|    explained_variance   | 0.126       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0276      |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.000478   |
|    value_loss           | 0.0383      |
-----------------------------------------
Output 98: Average over 53 episodes - Reward: 0.6792452830188679
------------------------------------------
| time/                   |              |
|    fps                  | 516          |
|    iterations           | 98           |
|    time_elapsed         | 388          |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 0.0035966039 |
|    clip_fraction        | 0.0278       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.176       |
|    explained_variance   | 0.161        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0341       |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.000656    |
|    value_loss           | 0.036        |
------------------------------------------
Output 99: Average over 51 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 99           |
|    time_elapsed         | 392          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0015414003 |
|    clip_fraction        | 0.0257       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.156       |
|    explained_variance   | 0.216        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0136       |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 0.0409       |
------------------------------------------
Output 100: Average over 60 episodes - Reward: 0.6166666666666667
------------------------------------------
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 100          |
|    time_elapsed         | 395          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0017694521 |
|    clip_fraction        | 0.0295       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 0.243        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0247       |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00168     |
|    value_loss           | 0.0391       |
------------------------------------------
Output 101: Average over 55 episodes - Reward: 0.5818181818181818
------------------------------------------
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 101          |
|    time_elapsed         | 399          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0015224796 |
|    clip_fraction        | 0.0243       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.132       |
|    explained_variance   | 0.214        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0235       |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 0.0484       |
------------------------------------------
Output 102: Average over 43 episodes - Reward: 0.7209302325581395
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 102          |
|    time_elapsed         | 402          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0011223515 |
|    clip_fraction        | 0.017        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.134       |
|    explained_variance   | 0.142        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0281       |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.000351    |
|    value_loss           | 0.0512       |
------------------------------------------
Output 103: Average over 45 episodes - Reward: 0.5777777777777777
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 103          |
|    time_elapsed         | 406          |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 0.0012929495 |
|    clip_fraction        | 0.0137       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0.267        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0184       |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00127     |
|    value_loss           | 0.0327       |
------------------------------------------
Output 104: Average over 56 episodes - Reward: 0.5892857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 518          |
|    iterations           | 104          |
|    time_elapsed         | 410          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0010659052 |
|    clip_fraction        | 0.0213       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0997      |
|    explained_variance   | 0.156        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0138       |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 0.0405       |
------------------------------------------
Output 105: Average over 47 episodes - Reward: 0.723404255319149
-----------------------------------------
| time/                   |             |
|    fps                  | 519         |
|    iterations           | 105         |
|    time_elapsed         | 414         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.001032447 |
|    clip_fraction        | 0.0111      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0737     |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.024       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.000829   |
|    value_loss           | 0.0474      |
-----------------------------------------
Output 106: Average over 49 episodes - Reward: 0.8367346938775511
-------------------------------------------
| time/                   |               |
|    fps                  | 520           |
|    iterations           | 106           |
|    time_elapsed         | 417           |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 0.00080464885 |
|    clip_fraction        | 0.0125        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0786       |
|    explained_variance   | 0.199         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0197        |
|    n_updates            | 1050          |
|    policy_gradient_loss | -0.000739     |
|    value_loss           | 0.0424        |
-------------------------------------------
Output 107: Average over 47 episodes - Reward: 0.7446808510638298
------------------------------------------
| time/                   |              |
|    fps                  | 520          |
|    iterations           | 107          |
|    time_elapsed         | 421          |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 0.0005384034 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0822      |
|    explained_variance   | 0.224        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0138       |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.000231    |
|    value_loss           | 0.0344       |
------------------------------------------
Output 108: Average over 53 episodes - Reward: 0.7169811320754716
-------------------------------------------
| time/                   |               |
|    fps                  | 521           |
|    iterations           | 108           |
|    time_elapsed         | 424           |
|    total_timesteps      | 221184        |
| train/                  |               |
|    approx_kl            | 0.00064939505 |
|    clip_fraction        | 0.0129        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0768       |
|    explained_variance   | 0.183         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0201        |
|    n_updates            | 1070          |
|    policy_gradient_loss | -0.000441     |
|    value_loss           | 0.0339        |
-------------------------------------------
Output 109: Average over 54 episodes - Reward: 0.7222222222222222
------------------------------------------
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 109          |
|    time_elapsed         | 427          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0011657047 |
|    clip_fraction        | 0.00986      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0736      |
|    explained_variance   | 0.182        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0215       |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.000555    |
|    value_loss           | 0.0389       |
------------------------------------------
Output 110: Average over 47 episodes - Reward: 0.6808510638297872
------------------------------------------
| time/                   |              |
|    fps                  | 522          |
|    iterations           | 110          |
|    time_elapsed         | 430          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0007767617 |
|    clip_fraction        | 0.00396      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.077       |
|    explained_variance   | 0.211        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0177       |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00028     |
|    value_loss           | 0.0384       |
------------------------------------------
Output 111: Average over 44 episodes - Reward: 0.7727272727272727
-------------------------------------------
| time/                   |               |
|    fps                  | 523           |
|    iterations           | 111           |
|    time_elapsed         | 434           |
|    total_timesteps      | 227328        |
| train/                  |               |
|    approx_kl            | 0.00073735346 |
|    clip_fraction        | 0.012         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.072        |
|    explained_variance   | 0.218         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0194        |
|    n_updates            | 1100          |
|    policy_gradient_loss | -0.00102      |
|    value_loss           | 0.0352        |
-------------------------------------------
Output 112: Average over 41 episodes - Reward: 0.7073170731707317
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 112          |
|    time_elapsed         | 437          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0012590206 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0613      |
|    explained_variance   | 0.228        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.014        |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.000101    |
|    value_loss           | 0.035        |
------------------------------------------
Output 113: Average over 49 episodes - Reward: 0.7142857142857143
-------------------------------------------
| time/                   |               |
|    fps                  | 523           |
|    iterations           | 113           |
|    time_elapsed         | 441           |
|    total_timesteps      | 231424        |
| train/                  |               |
|    approx_kl            | 0.00025560035 |
|    clip_fraction        | 0.00937       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0524       |
|    explained_variance   | 0.203         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.016         |
|    n_updates            | 1120          |
|    policy_gradient_loss | -0.000508     |
|    value_loss           | 0.029         |
-------------------------------------------
Output 114: Average over 44 episodes - Reward: 0.7045454545454546
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 114          |
|    time_elapsed         | 445          |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 0.0008532315 |
|    clip_fraction        | 0.00957      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0728      |
|    explained_variance   | 0.177        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0222       |
|    n_updates            | 1130         |
|    policy_gradient_loss | -8.19e-06    |
|    value_loss           | 0.0384       |
------------------------------------------
Output 115: Average over 52 episodes - Reward: 0.7692307692307693
-------------------------------------------
| time/                   |               |
|    fps                  | 524           |
|    iterations           | 115           |
|    time_elapsed         | 449           |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 0.00076471304 |
|    clip_fraction        | 0.0138        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0533       |
|    explained_variance   | 0.226         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0102        |
|    n_updates            | 1140          |
|    policy_gradient_loss | -0.0021       |
|    value_loss           | 0.0302        |
-------------------------------------------
Output 116: Average over 50 episodes - Reward: 0.72
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 116         |
|    time_elapsed         | 452         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.000412018 |
|    clip_fraction        | 0.00864     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0546     |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0167      |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.000353   |
|    value_loss           | 0.0367      |
-----------------------------------------
Output 117: Average over 57 episodes - Reward: 0.7368421052631579
------------------------------------------
| time/                   |              |
|    fps                  | 525          |
|    iterations           | 117          |
|    time_elapsed         | 456          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0018078504 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0567      |
|    explained_variance   | 0.106        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.017        |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.001       |
|    value_loss           | 0.0348       |
------------------------------------------
Output 118: Average over 47 episodes - Reward: 0.6595744680851063
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 118           |
|    time_elapsed         | 460           |
|    total_timesteps      | 241664        |
| train/                  |               |
|    approx_kl            | 0.00080604455 |
|    clip_fraction        | 0.0141        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0526       |
|    explained_variance   | 0.24          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00945       |
|    n_updates            | 1170          |
|    policy_gradient_loss | -0.00204      |
|    value_loss           | 0.0391        |
-------------------------------------------
Output 119: Average over 48 episodes - Reward: 0.6041666666666666
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 119           |
|    time_elapsed         | 463           |
|    total_timesteps      | 243712        |
| train/                  |               |
|    approx_kl            | 0.00055907236 |
|    clip_fraction        | 0.0114        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0481       |
|    explained_variance   | 0.157         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0303        |
|    n_updates            | 1180          |
|    policy_gradient_loss | -0.000787     |
|    value_loss           | 0.0376        |
-------------------------------------------
Output 120: Average over 45 episodes - Reward: 0.6222222222222222
-------------------------------------------
| time/                   |               |
|    fps                  | 525           |
|    iterations           | 120           |
|    time_elapsed         | 467           |
|    total_timesteps      | 245760        |
| train/                  |               |
|    approx_kl            | 0.00075352733 |
|    clip_fraction        | 0.00396       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.043        |
|    explained_variance   | 0.18          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0245        |
|    n_updates            | 1190          |
|    policy_gradient_loss | -0.000286     |
|    value_loss           | 0.0324        |
-------------------------------------------
Output 121: Average over 49 episodes - Reward: 0.7346938775510204
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 121         |
|    time_elapsed         | 470         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.001028092 |
|    clip_fraction        | 0.00591     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0269     |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0166      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.000957   |
|    value_loss           | 0.0386      |
-----------------------------------------
Output 122: Average over 51 episodes - Reward: 0.7058823529411765
------------------------------------------
| time/                   |              |
|    fps                  | 526          |
|    iterations           | 122          |
|    time_elapsed         | 474          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0010415434 |
|    clip_fraction        | 0.00518      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0249      |
|    explained_variance   | 0.107        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.017        |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.000675    |
|    value_loss           | 0.0369       |
------------------------------------------
Output 123: Average over 50 episodes - Reward: 0.78
-------------------------------------------
| time/                   |               |
|    fps                  | 527           |
|    iterations           | 123           |
|    time_elapsed         | 477           |
|    total_timesteps      | 251904        |
| train/                  |               |
|    approx_kl            | 0.00021762634 |
|    clip_fraction        | 0.0043        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.028        |
|    explained_variance   | 0.234         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0146        |
|    n_updates            | 1220          |
|    policy_gradient_loss | -0.000592     |
|    value_loss           | 0.035         |
-------------------------------------------
Output 124: Average over 48 episodes - Reward: 0.75
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 124          |
|    time_elapsed         | 480          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0004869751 |
|    clip_fraction        | 0.00615      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | 0.226        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0169       |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.000867    |
|    value_loss           | 0.0355       |
------------------------------------------
Output 125: Average over 46 episodes - Reward: 0.6739130434782609
-------------------------------------------
| time/                   |               |
|    fps                  | 528           |
|    iterations           | 125           |
|    time_elapsed         | 484           |
|    total_timesteps      | 256000        |
| train/                  |               |
|    approx_kl            | 0.00050307385 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0303       |
|    explained_variance   | 0.306         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0156        |
|    n_updates            | 1240          |
|    policy_gradient_loss | -0.000294     |
|    value_loss           | 0.0291        |
-------------------------------------------
Output 126: Average over 49 episodes - Reward: 0.7959183673469388
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 126         |
|    time_elapsed         | 487         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.000199075 |
|    clip_fraction        | 0.00518     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0268     |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0172      |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.000356   |
|    value_loss           | 0.0306      |
-----------------------------------------
Output 127: Average over 44 episodes - Reward: 0.6818181818181818
-------------------------------------------
| time/                   |               |
|    fps                  | 530           |
|    iterations           | 127           |
|    time_elapsed         | 490           |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 0.00043362164 |
|    clip_fraction        | 0.00435       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0198       |
|    explained_variance   | 0.209         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0143        |
|    n_updates            | 1260          |
|    policy_gradient_loss | -0.000473     |
|    value_loss           | 0.0313        |
-------------------------------------------
Output 128: Average over 40 episodes - Reward: 0.725
------------------------------------------
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 128          |
|    time_elapsed         | 494          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0003113775 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0145      |
|    explained_variance   | 0.196        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0132       |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.000458    |
|    value_loss           | 0.0287       |
------------------------------------------
Output 129: Average over 50 episodes - Reward: 0.8
------------------------------------------
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 129          |
|    time_elapsed         | 497          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 1.649381e-05 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0104      |
|    explained_variance   | 0.21         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0144       |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.000214    |
|    value_loss           | 0.0259       |
------------------------------------------
Output 130: Average over 44 episodes - Reward: 0.5909090909090909
-------------------------------------------
| time/                   |               |
|    fps                  | 531           |
|    iterations           | 130           |
|    time_elapsed         | 501           |
|    total_timesteps      | 266240        |
| train/                  |               |
|    approx_kl            | 0.00010183646 |
|    clip_fraction        | 0.000586      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0105       |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.018         |
|    n_updates            | 1290          |
|    policy_gradient_loss | -0.00024      |
|    value_loss           | 0.0335        |
-------------------------------------------
Output 131: Average over 52 episodes - Reward: 0.5576923076923077
------------------------------------------
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 131          |
|    time_elapsed         | 504          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0013630812 |
|    clip_fraction        | 0.0061       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0183      |
|    explained_variance   | 0.0546       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0162       |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00132     |
|    value_loss           | 0.0359       |
------------------------------------------
Output 132: Average over 47 episodes - Reward: 0.6808510638297872
------------------------------------------
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 132          |
|    time_elapsed         | 508          |
|    total_timesteps      | 270336       |
| train/                  |              |
|    approx_kl            | 0.0012748379 |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0385      |
|    explained_variance   | 0.0643       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.027        |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.000176    |
|    value_loss           | 0.0474       |
------------------------------------------
Output 133: Average over 47 episodes - Reward: 0.7446808510638298
------------------------------------------
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 133          |
|    time_elapsed         | 512          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0012594792 |
|    clip_fraction        | 0.00771      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0384      |
|    explained_variance   | 0.0853       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0182       |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000782    |
|    value_loss           | 0.0369       |
------------------------------------------
Output 134: Average over 48 episodes - Reward: 0.6041666666666666
-------------------------------------------
| time/                   |               |
|    fps                  | 532           |
|    iterations           | 134           |
|    time_elapsed         | 515           |
|    total_timesteps      | 274432        |
| train/                  |               |
|    approx_kl            | 0.00020157848 |
|    clip_fraction        | 0.0043        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0249       |
|    explained_variance   | 0.134         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0217        |
|    n_updates            | 1330          |
|    policy_gradient_loss | -0.000986     |
|    value_loss           | 0.036         |
-------------------------------------------
Output 135: Average over 47 episodes - Reward: 0.6808510638297872
-------------------------------------------
| time/                   |               |
|    fps                  | 532           |
|    iterations           | 135           |
|    time_elapsed         | 519           |
|    total_timesteps      | 276480        |
| train/                  |               |
|    approx_kl            | 0.00045650871 |
|    clip_fraction        | 0.00508       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0209       |
|    explained_variance   | 0.136         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.014         |
|    n_updates            | 1340          |
|    policy_gradient_loss | -0.00163      |
|    value_loss           | 0.0371        |
-------------------------------------------
Output 136: Average over 53 episodes - Reward: 0.7735849056603774
------------------------------------------
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 136          |
|    time_elapsed         | 522          |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0002786898 |
|    clip_fraction        | 0.00386      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0208      |
|    explained_variance   | 0.132        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0221       |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.000814    |
|    value_loss           | 0.0414       |
------------------------------------------
Output 137: Average over 46 episodes - Reward: 0.6956521739130435
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 137         |
|    time_elapsed         | 525         |
|    total_timesteps      | 280576      |
| train/                  |             |
|    approx_kl            | 0.001043569 |
|    clip_fraction        | 0.00322     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0171     |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0196      |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.000834   |
|    value_loss           | 0.0383      |
-----------------------------------------
Output 138: Average over 50 episodes - Reward: 0.78
------------------------------------------
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 138          |
|    time_elapsed         | 529          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0027076157 |
|    clip_fraction        | 0.00225      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0259      |
|    explained_variance   | 0.192        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0252       |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.000817    |
|    value_loss           | 0.0352       |
------------------------------------------
Output 139: Average over 48 episodes - Reward: 0.5833333333333334
-------------------------------------------
| time/                   |               |
|    fps                  | 534           |
|    iterations           | 139           |
|    time_elapsed         | 532           |
|    total_timesteps      | 284672        |
| train/                  |               |
|    approx_kl            | 0.00033137255 |
|    clip_fraction        | 0.00654       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0348       |
|    explained_variance   | 0.0825        |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0239        |
|    n_updates            | 1380          |
|    policy_gradient_loss | -0.00162      |
|    value_loss           | 0.036         |
-------------------------------------------
Output 140: Average over 45 episodes - Reward: 0.6444444444444445
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 140          |
|    time_elapsed         | 536          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0008266675 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0285      |
|    explained_variance   | 0.104        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0155       |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 0.0373       |
------------------------------------------
Output 141: Average over 46 episodes - Reward: 0.6304347826086957
-------------------------------------------
| time/                   |               |
|    fps                  | 534           |
|    iterations           | 141           |
|    time_elapsed         | 540           |
|    total_timesteps      | 288768        |
| train/                  |               |
|    approx_kl            | 0.00026158654 |
|    clip_fraction        | 0.00459       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0237       |
|    explained_variance   | 0.161         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0122        |
|    n_updates            | 1400          |
|    policy_gradient_loss | -0.000628     |
|    value_loss           | 0.0305        |
-------------------------------------------
Output 142: Average over 45 episodes - Reward: 0.7333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 142          |
|    time_elapsed         | 544          |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 0.0005640375 |
|    clip_fraction        | 0.00698      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0282      |
|    explained_variance   | 0.138        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0101       |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00192     |
|    value_loss           | 0.0382       |
------------------------------------------
Output 143: Average over 47 episodes - Reward: 0.7446808510638298
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 143          |
|    time_elapsed         | 547          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0006376859 |
|    clip_fraction        | 0.00366      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.028       |
|    explained_variance   | 0.139        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0293       |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000876    |
|    value_loss           | 0.036        |
------------------------------------------
Output 144: Average over 57 episodes - Reward: 0.7017543859649122
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 144          |
|    time_elapsed         | 551          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0041336566 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0787      |
|    explained_variance   | 0.22         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0181       |
|    n_updates            | 1430         |
|    policy_gradient_loss | -0.000906    |
|    value_loss           | 0.0331       |
------------------------------------------
Output 145: Average over 51 episodes - Reward: 0.6274509803921569
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 145          |
|    time_elapsed         | 555          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0019773329 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0789      |
|    explained_variance   | 0.216        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.018        |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.00262     |
|    value_loss           | 0.0447       |
------------------------------------------
Output 146: Average over 55 episodes - Reward: 0.6
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 146         |
|    time_elapsed         | 559         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.012421638 |
|    clip_fraction        | 0.0181      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0746     |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0289      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00227    |
|    value_loss           | 0.0426      |
-----------------------------------------
Output 147: Average over 55 episodes - Reward: 0.6363636363636364
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 147         |
|    time_elapsed         | 563         |
|    total_timesteps      | 301056      |
| train/                  |             |
|    approx_kl            | 0.001832657 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0942     |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0318      |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00152    |
|    value_loss           | 0.046       |
-----------------------------------------
Output 148: Average over 53 episodes - Reward: 0.6037735849056604
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 148          |
|    time_elapsed         | 567          |
|    total_timesteps      | 303104       |
| train/                  |              |
|    approx_kl            | 0.0019422355 |
|    clip_fraction        | 0.0218       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0801      |
|    explained_variance   | 0.174        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0315       |
|    n_updates            | 1470         |
|    policy_gradient_loss | -0.00319     |
|    value_loss           | 0.0448       |
------------------------------------------
Output 149: Average over 50 episodes - Reward: 0.76
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 149          |
|    time_elapsed         | 571          |
|    total_timesteps      | 305152       |
| train/                  |              |
|    approx_kl            | 0.0012006414 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0704      |
|    explained_variance   | 0.137        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0138       |
|    n_updates            | 1480         |
|    policy_gradient_loss | -0.00188     |
|    value_loss           | 0.0457       |
------------------------------------------
Output 150: Average over 49 episodes - Reward: 0.7142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 150          |
|    time_elapsed         | 574          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0023245295 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0684      |
|    explained_variance   | 0.153        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0149       |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.002       |
|    value_loss           | 0.0367       |
------------------------------------------
Output 151: Average over 52 episodes - Reward: 0.7115384615384616
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 151         |
|    time_elapsed         | 577         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.002283651 |
|    clip_fraction        | 0.0219      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0629     |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0152      |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00316    |
|    value_loss           | 0.0409      |
-----------------------------------------
Output 152: Average over 40 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 152          |
|    time_elapsed         | 581          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0011112196 |
|    clip_fraction        | 0.00825      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0702      |
|    explained_variance   | 0.143        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0142       |
|    n_updates            | 1510         |
|    policy_gradient_loss | 6.5e-05      |
|    value_loss           | 0.0391       |
------------------------------------------
Output 153: Average over 50 episodes - Reward: 0.7
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 153         |
|    time_elapsed         | 585         |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.003165348 |
|    clip_fraction        | 0.0197      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0555     |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0192      |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00381    |
|    value_loss           | 0.035       |
-----------------------------------------
Output 154: Average over 48 episodes - Reward: 0.5833333333333334
-------------------------------------------
| time/                   |               |
|    fps                  | 535           |
|    iterations           | 154           |
|    time_elapsed         | 588           |
|    total_timesteps      | 315392        |
| train/                  |               |
|    approx_kl            | 0.00041085985 |
|    clip_fraction        | 0.00518       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0531       |
|    explained_variance   | 0.171         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0154        |
|    n_updates            | 1530          |
|    policy_gradient_loss | -0.000321     |
|    value_loss           | 0.0401        |
-------------------------------------------
Output 155: Average over 49 episodes - Reward: 0.8163265306122449
-------------------------------------------
| time/                   |               |
|    fps                  | 536           |
|    iterations           | 155           |
|    time_elapsed         | 591           |
|    total_timesteps      | 317440        |
| train/                  |               |
|    approx_kl            | 0.00016049398 |
|    clip_fraction        | 0.00522       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0458       |
|    explained_variance   | 0.102         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0228        |
|    n_updates            | 1540          |
|    policy_gradient_loss | 0.000102      |
|    value_loss           | 0.0436        |
-------------------------------------------
Output 156: Average over 51 episodes - Reward: 0.7843137254901961
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 156         |
|    time_elapsed         | 595         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.008505339 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0337     |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0109      |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00372    |
|    value_loss           | 0.0381      |
-----------------------------------------
Output 157: Average over 43 episodes - Reward: 0.6511627906976745
-------------------------------------------
| time/                   |               |
|    fps                  | 536           |
|    iterations           | 157           |
|    time_elapsed         | 599           |
|    total_timesteps      | 321536        |
| train/                  |               |
|    approx_kl            | 0.00035108117 |
|    clip_fraction        | 0.00513       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0296       |
|    explained_variance   | 0.241         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00911       |
|    n_updates            | 1560          |
|    policy_gradient_loss | -0.00134      |
|    value_loss           | 0.0339        |
-------------------------------------------
Output 158: Average over 43 episodes - Reward: 0.7441860465116279
-------------------------------------------
| time/                   |               |
|    fps                  | 536           |
|    iterations           | 158           |
|    time_elapsed         | 602           |
|    total_timesteps      | 323584        |
| train/                  |               |
|    approx_kl            | 0.00082811154 |
|    clip_fraction        | 0.00605       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0296       |
|    explained_variance   | 0.156         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0141        |
|    n_updates            | 1570          |
|    policy_gradient_loss | -0.000573     |
|    value_loss           | 0.0354        |
-------------------------------------------
Output 159: Average over 51 episodes - Reward: 0.7450980392156863
-------------------------------------------
| time/                   |               |
|    fps                  | 536           |
|    iterations           | 159           |
|    time_elapsed         | 606           |
|    total_timesteps      | 325632        |
| train/                  |               |
|    approx_kl            | 0.00019311346 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0354       |
|    explained_variance   | 0.272         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0118        |
|    n_updates            | 1580          |
|    policy_gradient_loss | -0.000345     |
|    value_loss           | 0.0277        |
-------------------------------------------
Output 160: Average over 52 episodes - Reward: 0.6346153846153846
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 160          |
|    time_elapsed         | 610          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0030940636 |
|    clip_fraction        | 0.00308      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0387      |
|    explained_variance   | 0.147        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0146       |
|    n_updates            | 1590         |
|    policy_gradient_loss | -0.000659    |
|    value_loss           | 0.0382       |
------------------------------------------
Output 161: Average over 49 episodes - Reward: 0.6326530612244898
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 161          |
|    time_elapsed         | 613          |
|    total_timesteps      | 329728       |
| train/                  |              |
|    approx_kl            | 0.0016645489 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0555      |
|    explained_variance   | 0.122        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0254       |
|    n_updates            | 1600         |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 0.0387       |
------------------------------------------
Output 162: Average over 42 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 162          |
|    time_elapsed         | 617          |
|    total_timesteps      | 331776       |
| train/                  |              |
|    approx_kl            | 0.0018693088 |
|    clip_fraction        | 0.00762      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0427      |
|    explained_variance   | 0.169        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0293       |
|    n_updates            | 1610         |
|    policy_gradient_loss | -0.00118     |
|    value_loss           | 0.0379       |
------------------------------------------
Output 163: Average over 42 episodes - Reward: 0.7380952380952381
-------------------------------------------
| time/                   |               |
|    fps                  | 537           |
|    iterations           | 163           |
|    time_elapsed         | 621           |
|    total_timesteps      | 333824        |
| train/                  |               |
|    approx_kl            | 0.00045518205 |
|    clip_fraction        | 0.00479       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0355       |
|    explained_variance   | 0.168         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0179        |
|    n_updates            | 1620          |
|    policy_gradient_loss | -0.000422     |
|    value_loss           | 0.0329        |
-------------------------------------------
Output 164: Average over 49 episodes - Reward: 0.7346938775510204
-----------------------------------------
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 164         |
|    time_elapsed         | 625         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.009864368 |
|    clip_fraction        | 0.0277      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0557     |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00235    |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00508    |
|    value_loss           | 0.0273      |
-----------------------------------------
Output 165: Average over 52 episodes - Reward: 0.7307692307692307
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 165          |
|    time_elapsed         | 629          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0004526423 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.066       |
|    explained_variance   | 0.116        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0248       |
|    n_updates            | 1640         |
|    policy_gradient_loss | 0.0001       |
|    value_loss           | 0.0405       |
------------------------------------------
Output 166: Average over 45 episodes - Reward: 0.6
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 166          |
|    time_elapsed         | 632          |
|    total_timesteps      | 339968       |
| train/                  |              |
|    approx_kl            | 0.0010809341 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0449      |
|    explained_variance   | 0.164        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0155       |
|    n_updates            | 1650         |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 0.0371       |
------------------------------------------
Output 167: Average over 43 episodes - Reward: 0.627906976744186
------------------------------------------
| time/                   |              |
|    fps                  | 537          |
|    iterations           | 167          |
|    time_elapsed         | 635          |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 0.0009800488 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0496      |
|    explained_variance   | 0.1          |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0241       |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00189     |
|    value_loss           | 0.0423       |
------------------------------------------
Output 168: Average over 44 episodes - Reward: 0.6590909090909091
-------------------------------------------
| time/                   |               |
|    fps                  | 538           |
|    iterations           | 168           |
|    time_elapsed         | 639           |
|    total_timesteps      | 344064        |
| train/                  |               |
|    approx_kl            | 0.00049301994 |
|    clip_fraction        | 0.00566       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0414       |
|    explained_variance   | 0.169         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.016         |
|    n_updates            | 1670          |
|    policy_gradient_loss | -0.000364     |
|    value_loss           | 0.0339        |
-------------------------------------------
Output 169: Average over 42 episodes - Reward: 0.7142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 169          |
|    time_elapsed         | 642          |
|    total_timesteps      | 346112       |
| train/                  |              |
|    approx_kl            | 0.0022868146 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0423      |
|    explained_variance   | 0.148        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.023        |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00166     |
|    value_loss           | 0.0381       |
------------------------------------------
Output 170: Average over 41 episodes - Reward: 0.6097560975609756
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 170          |
|    time_elapsed         | 646          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0006575639 |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0359      |
|    explained_variance   | 0.184        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0151       |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.00157     |
|    value_loss           | 0.0318       |
------------------------------------------
Output 171: Average over 49 episodes - Reward: 0.6530612244897959
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 171          |
|    time_elapsed         | 649          |
|    total_timesteps      | 350208       |
| train/                  |              |
|    approx_kl            | 0.0007663324 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.044       |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0226       |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.00328     |
|    value_loss           | 0.0315       |
------------------------------------------
Output 172: Average over 50 episodes - Reward: 0.6
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 172         |
|    time_elapsed         | 653         |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.001176596 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0395     |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0191      |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00183    |
|    value_loss           | 0.0389      |
-----------------------------------------
Output 173: Average over 51 episodes - Reward: 0.6470588235294118
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 173          |
|    time_elapsed         | 656          |
|    total_timesteps      | 354304       |
| train/                  |              |
|    approx_kl            | 0.0007049114 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0347      |
|    explained_variance   | 0.147        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0223       |
|    n_updates            | 1720         |
|    policy_gradient_loss | -0.00102     |
|    value_loss           | 0.0434       |
------------------------------------------
Output 174: Average over 48 episodes - Reward: 0.625
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 174          |
|    time_elapsed         | 660          |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 0.0005088544 |
|    clip_fraction        | 0.00601      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0324      |
|    explained_variance   | 0.172        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.023        |
|    n_updates            | 1730         |
|    policy_gradient_loss | 6.47e-05     |
|    value_loss           | 0.0436       |
------------------------------------------
Output 175: Average over 49 episodes - Reward: 0.8163265306122449
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 175          |
|    time_elapsed         | 664          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0007937774 |
|    clip_fraction        | 0.00742      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0267      |
|    explained_variance   | 0.134        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0254       |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.000868    |
|    value_loss           | 0.0428       |
------------------------------------------
Output 176: Average over 49 episodes - Reward: 0.7142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 176          |
|    time_elapsed         | 667          |
|    total_timesteps      | 360448       |
| train/                  |              |
|    approx_kl            | 0.0020685343 |
|    clip_fraction        | 0.00542      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0244      |
|    explained_variance   | 0.221        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0127       |
|    n_updates            | 1750         |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 0.0333       |
------------------------------------------
Output 177: Average over 54 episodes - Reward: 0.7037037037037037
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 177           |
|    time_elapsed         | 671           |
|    total_timesteps      | 362496        |
| train/                  |               |
|    approx_kl            | 0.00020461192 |
|    clip_fraction        | 0.00352       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0185       |
|    explained_variance   | 0.219         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.018         |
|    n_updates            | 1760          |
|    policy_gradient_loss | -0.000284     |
|    value_loss           | 0.0366        |
-------------------------------------------
Output 178: Average over 51 episodes - Reward: 0.6862745098039216
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 178           |
|    time_elapsed         | 675           |
|    total_timesteps      | 364544        |
| train/                  |               |
|    approx_kl            | 0.00056349835 |
|    clip_fraction        | 0.0041        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0145       |
|    explained_variance   | 0.186         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.023         |
|    n_updates            | 1770          |
|    policy_gradient_loss | -0.000997     |
|    value_loss           | 0.0408        |
-------------------------------------------
Output 179: Average over 55 episodes - Reward: 0.5636363636363636
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 179          |
|    time_elapsed         | 679          |
|    total_timesteps      | 366592       |
| train/                  |              |
|    approx_kl            | 0.0012514407 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0204      |
|    explained_variance   | 0.18         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0185       |
|    n_updates            | 1780         |
|    policy_gradient_loss | -0.000337    |
|    value_loss           | 0.0398       |
------------------------------------------
Output 180: Average over 49 episodes - Reward: 0.6530612244897959
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 180           |
|    time_elapsed         | 682           |
|    total_timesteps      | 368640        |
| train/                  |               |
|    approx_kl            | 0.00018622808 |
|    clip_fraction        | 0.00444       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0258       |
|    explained_variance   | 0.16          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0222        |
|    n_updates            | 1790          |
|    policy_gradient_loss | 5.83e-05      |
|    value_loss           | 0.0495        |
-------------------------------------------
Output 181: Average over 42 episodes - Reward: 0.6428571428571429
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 181          |
|    time_elapsed         | 686          |
|    total_timesteps      | 370688       |
| train/                  |              |
|    approx_kl            | 0.0009974949 |
|    clip_fraction        | 0.00586      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0205      |
|    explained_variance   | 0.1          |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0246       |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.000789    |
|    value_loss           | 0.0402       |
------------------------------------------
Output 182: Average over 48 episodes - Reward: 0.7916666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 182          |
|    time_elapsed         | 690          |
|    total_timesteps      | 372736       |
| train/                  |              |
|    approx_kl            | 0.0004589688 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0197      |
|    explained_variance   | 0.166        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0136       |
|    n_updates            | 1810         |
|    policy_gradient_loss | -0.000275    |
|    value_loss           | 0.031        |
------------------------------------------
Output 183: Average over 51 episodes - Reward: 0.7647058823529411
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 183           |
|    time_elapsed         | 693           |
|    total_timesteps      | 374784        |
| train/                  |               |
|    approx_kl            | 0.00010569437 |
|    clip_fraction        | 0.00342       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0236       |
|    explained_variance   | 0.256         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0162        |
|    n_updates            | 1820          |
|    policy_gradient_loss | 0.000138      |
|    value_loss           | 0.029         |
-------------------------------------------
Output 184: Average over 52 episodes - Reward: 0.75
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 184           |
|    time_elapsed         | 697           |
|    total_timesteps      | 376832        |
| train/                  |               |
|    approx_kl            | 0.00071870896 |
|    clip_fraction        | 0.00679       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0239       |
|    explained_variance   | 0.129         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0228        |
|    n_updates            | 1830          |
|    policy_gradient_loss | -0.000709     |
|    value_loss           | 0.0398        |
-------------------------------------------
Output 185: Average over 50 episodes - Reward: 0.7
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 185           |
|    time_elapsed         | 701           |
|    total_timesteps      | 378880        |
| train/                  |               |
|    approx_kl            | 0.00018639045 |
|    clip_fraction        | 0.00303       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0171       |
|    explained_variance   | 0.167         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0159        |
|    n_updates            | 1840          |
|    policy_gradient_loss | -0.000303     |
|    value_loss           | 0.0377        |
-------------------------------------------
Output 186: Average over 44 episodes - Reward: 0.75
--------------------------------------------
| time/                   |                |
|    fps                  | 540            |
|    iterations           | 186            |
|    time_elapsed         | 704            |
|    total_timesteps      | 380928         |
| train/                  |                |
|    approx_kl            | 0.000115752424 |
|    clip_fraction        | 0.00283        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0134        |
|    explained_variance   | 0.174          |
|    learning_rate        | 0.0003         |
|    loss                 | 0.0133         |
|    n_updates            | 1850           |
|    policy_gradient_loss | -0.000168      |
|    value_loss           | 0.0346         |
--------------------------------------------
Output 187: Average over 44 episodes - Reward: 0.7272727272727273
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 187           |
|    time_elapsed         | 708           |
|    total_timesteps      | 382976        |
| train/                  |               |
|    approx_kl            | 3.2436714e-05 |
|    clip_fraction        | 0.00083       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0153       |
|    explained_variance   | 0.242         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00778       |
|    n_updates            | 1860          |
|    policy_gradient_loss | -7.79e-05     |
|    value_loss           | 0.029         |
-------------------------------------------
Output 188: Average over 54 episodes - Reward: 0.8333333333333334
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 188           |
|    time_elapsed         | 711           |
|    total_timesteps      | 385024        |
| train/                  |               |
|    approx_kl            | 0.00079470116 |
|    clip_fraction        | 0.00269       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00969      |
|    explained_variance   | 0.232         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0139        |
|    n_updates            | 1870          |
|    policy_gradient_loss | -0.000665     |
|    value_loss           | 0.032         |
-------------------------------------------
Output 189: Average over 49 episodes - Reward: 0.7346938775510204
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 189           |
|    time_elapsed         | 716           |
|    total_timesteps      | 387072        |
| train/                  |               |
|    approx_kl            | 9.3299284e-05 |
|    clip_fraction        | 0.00107       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00974      |
|    explained_variance   | 0.267         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0126        |
|    n_updates            | 1880          |
|    policy_gradient_loss | -9.87e-05     |
|    value_loss           | 0.0313        |
-------------------------------------------
Output 190: Average over 55 episodes - Reward: 0.7090909090909091
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 190          |
|    time_elapsed         | 720          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 7.729343e-05 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00888     |
|    explained_variance   | 0.243        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0151       |
|    n_updates            | 1890         |
|    policy_gradient_loss | -5.63e-05    |
|    value_loss           | 0.0321       |
------------------------------------------
Output 191: Average over 47 episodes - Reward: 0.8085106382978723
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 191           |
|    time_elapsed         | 724           |
|    total_timesteps      | 391168        |
| train/                  |               |
|    approx_kl            | 0.00049102306 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0109       |
|    explained_variance   | 0.175         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0177        |
|    n_updates            | 1900          |
|    policy_gradient_loss | -0.000222     |
|    value_loss           | 0.039         |
-------------------------------------------
Output 192: Average over 48 episodes - Reward: 0.7708333333333334
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 192           |
|    time_elapsed         | 729           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00035804065 |
|    clip_fraction        | 0.00288       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0174       |
|    explained_variance   | 0.194         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0111        |
|    n_updates            | 1910          |
|    policy_gradient_loss | -0.000198     |
|    value_loss           | 0.0268        |
-------------------------------------------
Output 193: Average over 56 episodes - Reward: 0.7678571428571429
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 193          |
|    time_elapsed         | 732          |
|    total_timesteps      | 395264       |
| train/                  |              |
|    approx_kl            | 5.997662e-05 |
|    clip_fraction        | 0.00103      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0149      |
|    explained_variance   | 0.185        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0146       |
|    n_updates            | 1920         |
|    policy_gradient_loss | -7.9e-05     |
|    value_loss           | 0.028        |
------------------------------------------
Output 194: Average over 43 episodes - Reward: 0.7209302325581395
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 194           |
|    time_elapsed         | 736           |
|    total_timesteps      | 397312        |
| train/                  |               |
|    approx_kl            | 0.00019601177 |
|    clip_fraction        | 0.00259       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.018        |
|    explained_variance   | 0.148         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0184        |
|    n_updates            | 1930          |
|    policy_gradient_loss | -2.78e-05     |
|    value_loss           | 0.0403        |
-------------------------------------------
Output 195: Average over 45 episodes - Reward: 0.6
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 195         |
|    time_elapsed         | 740         |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.006916265 |
|    clip_fraction        | 0.00381     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0234     |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0137      |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.000332    |
|    value_loss           | 0.0311      |
-----------------------------------------
Output 196: Average over 52 episodes - Reward: 0.8076923076923077
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 196          |
|    time_elapsed         | 743          |
|    total_timesteps      | 401408       |
| train/                  |              |
|    approx_kl            | 0.0021719323 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0267      |
|    explained_variance   | 0.128        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0162       |
|    n_updates            | 1950         |
|    policy_gradient_loss | -0.0021      |
|    value_loss           | 0.0408       |
------------------------------------------
Output 197: Average over 53 episodes - Reward: 0.7924528301886793
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 197          |
|    time_elapsed         | 747          |
|    total_timesteps      | 403456       |
| train/                  |              |
|    approx_kl            | 0.0014951914 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0258      |
|    explained_variance   | 0.163        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0219       |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.00054     |
|    value_loss           | 0.0329       |
------------------------------------------
Output 198: Average over 45 episodes - Reward: 0.6222222222222222
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 198           |
|    time_elapsed         | 750           |
|    total_timesteps      | 405504        |
| train/                  |               |
|    approx_kl            | 0.00043018803 |
|    clip_fraction        | 0.00322       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0202       |
|    explained_variance   | 0.121         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0137        |
|    n_updates            | 1970          |
|    policy_gradient_loss | -0.000872     |
|    value_loss           | 0.0353        |
-------------------------------------------
Output 199: Average over 50 episodes - Reward: 0.76
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 199          |
|    time_elapsed         | 754          |
|    total_timesteps      | 407552       |
| train/                  |              |
|    approx_kl            | 0.0028496226 |
|    clip_fraction        | 0.0041       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00987     |
|    explained_variance   | 0.139        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.016        |
|    n_updates            | 1980         |
|    policy_gradient_loss | -0.00127     |
|    value_loss           | 0.0342       |
------------------------------------------
Output 200: Average over 54 episodes - Reward: 0.7222222222222222
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 200           |
|    time_elapsed         | 758           |
|    total_timesteps      | 409600        |
| train/                  |               |
|    approx_kl            | 5.6840392e-05 |
|    clip_fraction        | 0.000537      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00794      |
|    explained_variance   | 0.196         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0211        |
|    n_updates            | 1990          |
|    policy_gradient_loss | -8.02e-05     |
|    value_loss           | 0.0318        |
-------------------------------------------
Output 201: Average over 54 episodes - Reward: 0.8518518518518519
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 201           |
|    time_elapsed         | 762           |
|    total_timesteps      | 411648        |
| train/                  |               |
|    approx_kl            | 0.00016894209 |
|    clip_fraction        | 0.00103       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00897      |
|    explained_variance   | 0.16          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0208        |
|    n_updates            | 2000          |
|    policy_gradient_loss | -0.000165     |
|    value_loss           | 0.0416        |
-------------------------------------------
Output 202: Average over 51 episodes - Reward: 0.6470588235294118
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 202          |
|    time_elapsed         | 765          |
|    total_timesteps      | 413696       |
| train/                  |              |
|    approx_kl            | 0.0022970259 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0236      |
|    explained_variance   | 0.222        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0229       |
|    n_updates            | 2010         |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 0.0333       |
------------------------------------------
Output 203: Average over 47 episodes - Reward: 0.7021276595744681
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 203         |
|    time_elapsed         | 769         |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.001647685 |
|    clip_fraction        | 0.0104      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0228     |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0188      |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00194    |
|    value_loss           | 0.0414      |
-----------------------------------------
Output 204: Average over 46 episodes - Reward: 0.7608695652173914
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 204           |
|    time_elapsed         | 773           |
|    total_timesteps      | 417792        |
| train/                  |               |
|    approx_kl            | 0.00024558365 |
|    clip_fraction        | 0.00425       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0258       |
|    explained_variance   | 0.0539        |
|    learning_rate        | 0.0003        |
|    loss                 | 0.022         |
|    n_updates            | 2030          |
|    policy_gradient_loss | -0.000357     |
|    value_loss           | 0.0364        |
-------------------------------------------
Output 205: Average over 53 episodes - Reward: 0.7547169811320755
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 205          |
|    time_elapsed         | 777          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0006319848 |
|    clip_fraction        | 0.00728      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0284      |
|    explained_variance   | 0.21         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.017        |
|    n_updates            | 2040         |
|    policy_gradient_loss | 6.97e-05     |
|    value_loss           | 0.0343       |
------------------------------------------
Output 206: Average over 58 episodes - Reward: 0.7413793103448276
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 206           |
|    time_elapsed         | 780           |
|    total_timesteps      | 421888        |
| train/                  |               |
|    approx_kl            | 0.00037454264 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0244       |
|    explained_variance   | 0.209         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.015         |
|    n_updates            | 2050          |
|    policy_gradient_loss | -0.000175     |
|    value_loss           | 0.0366        |
-------------------------------------------
Output 207: Average over 39 episodes - Reward: 0.5641025641025641
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 207          |
|    time_elapsed         | 784          |
|    total_timesteps      | 423936       |
| train/                  |              |
|    approx_kl            | 0.0053954464 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0502      |
|    explained_variance   | 0.141        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0193       |
|    n_updates            | 2060         |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 0.0441       |
------------------------------------------
Output 208: Average over 44 episodes - Reward: 0.7045454545454546
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 208         |
|    time_elapsed         | 788         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.003601056 |
|    clip_fraction        | 0.0249      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0308     |
|    explained_variance   | 0.0725      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0163      |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.00305    |
|    value_loss           | 0.0359      |
-----------------------------------------
Output 209: Average over 53 episodes - Reward: 0.7358490566037735
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 209          |
|    time_elapsed         | 792          |
|    total_timesteps      | 428032       |
| train/                  |              |
|    approx_kl            | 0.0014371789 |
|    clip_fraction        | 0.00854      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0394      |
|    explained_variance   | 0.162        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0204       |
|    n_updates            | 2080         |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 0.0359       |
------------------------------------------
Output 210: Average over 57 episodes - Reward: 0.6842105263157895
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 210          |
|    time_elapsed         | 796          |
|    total_timesteps      | 430080       |
| train/                  |              |
|    approx_kl            | 0.0018229876 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0372      |
|    explained_variance   | 0.191        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00797      |
|    n_updates            | 2090         |
|    policy_gradient_loss | -0.00256     |
|    value_loss           | 0.0419       |
------------------------------------------
Output 211: Average over 48 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 211          |
|    time_elapsed         | 800          |
|    total_timesteps      | 432128       |
| train/                  |              |
|    approx_kl            | 0.0027286268 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0381      |
|    explained_variance   | 0.196        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0182       |
|    n_updates            | 2100         |
|    policy_gradient_loss | -0.00225     |
|    value_loss           | 0.0437       |
------------------------------------------
Output 212: Average over 51 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 212          |
|    time_elapsed         | 804          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0036124752 |
|    clip_fraction        | 0.0177       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0407      |
|    explained_variance   | 0.144        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0199       |
|    n_updates            | 2110         |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 0.0406       |
------------------------------------------
Output 213: Average over 53 episodes - Reward: 0.7547169811320755
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 213          |
|    time_elapsed         | 809          |
|    total_timesteps      | 436224       |
| train/                  |              |
|    approx_kl            | 0.0011044056 |
|    clip_fraction        | 0.00786      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0321      |
|    explained_variance   | 0.182        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0123       |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.000777    |
|    value_loss           | 0.04         |
------------------------------------------
Output 214: Average over 55 episodes - Reward: 0.8363636363636363
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 214          |
|    time_elapsed         | 813          |
|    total_timesteps      | 438272       |
| train/                  |              |
|    approx_kl            | 0.0002523387 |
|    clip_fraction        | 0.0043       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0361      |
|    explained_variance   | 0.133        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0229       |
|    n_updates            | 2130         |
|    policy_gradient_loss | 0.000346     |
|    value_loss           | 0.0405       |
------------------------------------------
Output 215: Average over 48 episodes - Reward: 0.625
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 215          |
|    time_elapsed         | 817          |
|    total_timesteps      | 440320       |
| train/                  |              |
|    approx_kl            | 0.0005221976 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0406      |
|    explained_variance   | 0.171        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0135       |
|    n_updates            | 2140         |
|    policy_gradient_loss | -0.000912    |
|    value_loss           | 0.0355       |
------------------------------------------
Output 216: Average over 49 episodes - Reward: 0.673469387755102
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 216          |
|    time_elapsed         | 820          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0009460959 |
|    clip_fraction        | 0.0084       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0316      |
|    explained_variance   | 0.0872       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0151       |
|    n_updates            | 2150         |
|    policy_gradient_loss | -0.000937    |
|    value_loss           | 0.038        |
------------------------------------------
Output 217: Average over 43 episodes - Reward: 0.7441860465116279
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 217           |
|    time_elapsed         | 824           |
|    total_timesteps      | 444416        |
| train/                  |               |
|    approx_kl            | 0.00080148026 |
|    clip_fraction        | 0.00947       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0271       |
|    explained_variance   | 0.158         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0254        |
|    n_updates            | 2160          |
|    policy_gradient_loss | -0.00111      |
|    value_loss           | 0.0367        |
-------------------------------------------
Output 218: Average over 43 episodes - Reward: 0.6046511627906976
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 218          |
|    time_elapsed         | 828          |
|    total_timesteps      | 446464       |
| train/                  |              |
|    approx_kl            | 0.0009514501 |
|    clip_fraction        | 0.00654      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | 0.141        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0132       |
|    n_updates            | 2170         |
|    policy_gradient_loss | -0.000462    |
|    value_loss           | 0.0318       |
------------------------------------------
Output 219: Average over 50 episodes - Reward: 0.68
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 219           |
|    time_elapsed         | 831           |
|    total_timesteps      | 448512        |
| train/                  |               |
|    approx_kl            | 0.00079814205 |
|    clip_fraction        | 0.0132        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0289       |
|    explained_variance   | 0.11          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0146        |
|    n_updates            | 2180          |
|    policy_gradient_loss | -0.00135      |
|    value_loss           | 0.0368        |
-------------------------------------------
Output 220: Average over 48 episodes - Reward: 0.6875
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 220           |
|    time_elapsed         | 835           |
|    total_timesteps      | 450560        |
| train/                  |               |
|    approx_kl            | 0.00061035913 |
|    clip_fraction        | 0.0129        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0369       |
|    explained_variance   | 0.162         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00256      |
|    n_updates            | 2190          |
|    policy_gradient_loss | -0.000848     |
|    value_loss           | 0.0362        |
-------------------------------------------
Output 221: Average over 51 episodes - Reward: 0.6470588235294118
-------------------------------------------
| time/                   |               |
|    fps                  | 539           |
|    iterations           | 221           |
|    time_elapsed         | 838           |
|    total_timesteps      | 452608        |
| train/                  |               |
|    approx_kl            | 0.00042535705 |
|    clip_fraction        | 0.00635       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0281       |
|    explained_variance   | 0.145         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0133        |
|    n_updates            | 2200          |
|    policy_gradient_loss | -0.000702     |
|    value_loss           | 0.0343        |
-------------------------------------------
Output 222: Average over 45 episodes - Reward: 0.7555555555555555
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 222          |
|    time_elapsed         | 842          |
|    total_timesteps      | 454656       |
| train/                  |              |
|    approx_kl            | 0.0009860324 |
|    clip_fraction        | 0.0121       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0413      |
|    explained_variance   | 0.161        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0184       |
|    n_updates            | 2210         |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 0.0395       |
------------------------------------------
Output 223: Average over 45 episodes - Reward: 0.5555555555555556
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 223          |
|    time_elapsed         | 846          |
|    total_timesteps      | 456704       |
| train/                  |              |
|    approx_kl            | 0.0010126103 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0349      |
|    explained_variance   | 0.227        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0167       |
|    n_updates            | 2220         |
|    policy_gradient_loss | -0.00186     |
|    value_loss           | 0.0303       |
------------------------------------------
Output 224: Average over 44 episodes - Reward: 0.6818181818181818
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 224          |
|    time_elapsed         | 849          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0012086111 |
|    clip_fraction        | 0.00854      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0326      |
|    explained_variance   | 0.176        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0278       |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.000585    |
|    value_loss           | 0.0367       |
------------------------------------------
Output 225: Average over 51 episodes - Reward: 0.7450980392156863
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 225          |
|    time_elapsed         | 853          |
|    total_timesteps      | 460800       |
| train/                  |              |
|    approx_kl            | 0.0011606333 |
|    clip_fraction        | 0.00903      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0277      |
|    explained_variance   | 0.211        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0184       |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.00236     |
|    value_loss           | 0.0338       |
------------------------------------------
Output 226: Average over 50 episodes - Reward: 0.7
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 226           |
|    time_elapsed         | 856           |
|    total_timesteps      | 462848        |
| train/                  |               |
|    approx_kl            | 0.00028438223 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.025        |
|    explained_variance   | 0.226         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0154        |
|    n_updates            | 2250          |
|    policy_gradient_loss | -0.000233     |
|    value_loss           | 0.036         |
-------------------------------------------
Output 227: Average over 43 episodes - Reward: 0.5813953488372093
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 227          |
|    time_elapsed         | 860          |
|    total_timesteps      | 464896       |
| train/                  |              |
|    approx_kl            | 0.0003875804 |
|    clip_fraction        | 0.00371      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0259      |
|    explained_variance   | 0.206        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0193       |
|    n_updates            | 2260         |
|    policy_gradient_loss | -0.00012     |
|    value_loss           | 0.0402       |
------------------------------------------
Output 228: Average over 44 episodes - Reward: 0.6590909090909091
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 228         |
|    time_elapsed         | 863         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.001020036 |
|    clip_fraction        | 0.00278     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0198     |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0167      |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.000824   |
|    value_loss           | 0.0312      |
-----------------------------------------
Output 229: Average over 52 episodes - Reward: 0.7307692307692307
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 229           |
|    time_elapsed         | 867           |
|    total_timesteps      | 468992        |
| train/                  |               |
|    approx_kl            | 0.00071953365 |
|    clip_fraction        | 0.00562       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0314       |
|    explained_variance   | 0.222         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0225        |
|    n_updates            | 2280          |
|    policy_gradient_loss | -0.000377     |
|    value_loss           | 0.0334        |
-------------------------------------------
Output 230: Average over 47 episodes - Reward: 0.7659574468085106
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 230         |
|    time_elapsed         | 871         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.002662906 |
|    clip_fraction        | 0.0134      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0326     |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0274      |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.00122    |
|    value_loss           | 0.0417      |
-----------------------------------------
Output 231: Average over 46 episodes - Reward: 0.7391304347826086
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 231           |
|    time_elapsed         | 875           |
|    total_timesteps      | 473088        |
| train/                  |               |
|    approx_kl            | 0.00027930085 |
|    clip_fraction        | 0.00283       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0161       |
|    explained_variance   | 0.227         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0163        |
|    n_updates            | 2300          |
|    policy_gradient_loss | -0.000661     |
|    value_loss           | 0.0317        |
-------------------------------------------
Output 232: Average over 55 episodes - Reward: 0.7454545454545455
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 232         |
|    time_elapsed         | 879         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.000832267 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0204     |
|    explained_variance   | 0.19        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0157      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.00185    |
|    value_loss           | 0.0361      |
-----------------------------------------
Output 233: Average over 40 episodes - Reward: 0.6
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 233          |
|    time_elapsed         | 883          |
|    total_timesteps      | 477184       |
| train/                  |              |
|    approx_kl            | 0.0002390336 |
|    clip_fraction        | 0.00303      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0161      |
|    explained_variance   | 0.169        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0191       |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.000527    |
|    value_loss           | 0.0393       |
------------------------------------------
Output 234: Average over 47 episodes - Reward: 0.7872340425531915
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 234           |
|    time_elapsed         | 886           |
|    total_timesteps      | 479232        |
| train/                  |               |
|    approx_kl            | 0.00037290648 |
|    clip_fraction        | 0.00532       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.022        |
|    explained_variance   | 0.209         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0148        |
|    n_updates            | 2330          |
|    policy_gradient_loss | -0.000585     |
|    value_loss           | 0.0297        |
-------------------------------------------
Output 235: Average over 44 episodes - Reward: 0.6590909090909091
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 235          |
|    time_elapsed         | 890          |
|    total_timesteps      | 481280       |
| train/                  |              |
|    approx_kl            | 0.0017024092 |
|    clip_fraction        | 0.002        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.025       |
|    explained_variance   | 0.202        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0113       |
|    n_updates            | 2340         |
|    policy_gradient_loss | -0.000551    |
|    value_loss           | 0.0337       |
------------------------------------------
Output 236: Average over 34 episodes - Reward: 0.5294117647058824
-------------------------------------------
| time/                   |               |
|    fps                  | 540           |
|    iterations           | 236           |
|    time_elapsed         | 894           |
|    total_timesteps      | 483328        |
| train/                  |               |
|    approx_kl            | 0.00021850673 |
|    clip_fraction        | 0.00327       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0319       |
|    explained_variance   | 0.21          |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0147        |
|    n_updates            | 2350          |
|    policy_gradient_loss | 9.52e-05      |
|    value_loss           | 0.0321        |
-------------------------------------------
Output 237: Average over 45 episodes - Reward: 0.7111111111111111
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 237         |
|    time_elapsed         | 897         |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.007536929 |
|    clip_fraction        | 0.00947     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0268     |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00279    |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00133    |
|    value_loss           | 0.0214      |
-----------------------------------------
Output 238: Average over 39 episodes - Reward: 0.6410256410256411
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 238         |
|    time_elapsed         | 901         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.004398587 |
|    clip_fraction        | 0.0246      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0228     |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0299      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00363    |
|    value_loss           | 0.0348      |
-----------------------------------------
Output 239: Average over 47 episodes - Reward: 0.6595744680851063
-------------------------------------------
| time/                   |               |
|    fps                  | 541           |
|    iterations           | 239           |
|    time_elapsed         | 904           |
|    total_timesteps      | 489472        |
| train/                  |               |
|    approx_kl            | 0.00017323371 |
|    clip_fraction        | 0.0019        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0241       |
|    explained_variance   | 0.161         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0113        |
|    n_updates            | 2380          |
|    policy_gradient_loss | 8.94e-05      |
|    value_loss           | 0.0278        |
-------------------------------------------
Output 240: Average over 54 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 240          |
|    time_elapsed         | 907          |
|    total_timesteps      | 491520       |
| train/                  |              |
|    approx_kl            | 0.0006243846 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0244      |
|    explained_variance   | 0.217        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00653      |
|    n_updates            | 2390         |
|    policy_gradient_loss | -0.000504    |
|    value_loss           | 0.0337       |
------------------------------------------
Output 241: Average over 44 episodes - Reward: 0.7272727272727273
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 241          |
|    time_elapsed         | 911          |
|    total_timesteps      | 493568       |
| train/                  |              |
|    approx_kl            | 0.0019304489 |
|    clip_fraction        | 0.00464      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0222      |
|    explained_variance   | 0.251        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0195       |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.000836    |
|    value_loss           | 0.0426       |
------------------------------------------
Output 242: Average over 47 episodes - Reward: 0.723404255319149
-------------------------------------------
| time/                   |               |
|    fps                  | 541           |
|    iterations           | 242           |
|    time_elapsed         | 915           |
|    total_timesteps      | 495616        |
| train/                  |               |
|    approx_kl            | 0.00019371975 |
|    clip_fraction        | 0.00132       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00797      |
|    explained_variance   | 0.145         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0236        |
|    n_updates            | 2410          |
|    policy_gradient_loss | -0.000361     |
|    value_loss           | 0.0395        |
-------------------------------------------
Output 243: Average over 46 episodes - Reward: 0.8260869565217391
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 243          |
|    time_elapsed         | 919          |
|    total_timesteps      | 497664       |
| train/                  |              |
|    approx_kl            | 0.0025241943 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0275      |
|    explained_variance   | 0.17         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0065       |
|    n_updates            | 2420         |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 0.035        |
------------------------------------------
Output 244: Average over 49 episodes - Reward: 0.7346938775510204
-------------------------------------------
| time/                   |               |
|    fps                  | 541           |
|    iterations           | 244           |
|    time_elapsed         | 922           |
|    total_timesteps      | 499712        |
| train/                  |               |
|    approx_kl            | 0.00081850926 |
|    clip_fraction        | 0.00732       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0196       |
|    explained_variance   | 0.243         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00715       |
|    n_updates            | 2430          |
|    policy_gradient_loss | -0.000469     |
|    value_loss           | 0.0257        |
-------------------------------------------
Output 245: Average over 45 episodes - Reward: 0.7111111111111111
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 245          |
|    time_elapsed         | 926          |
|    total_timesteps      | 501760       |
| train/                  |              |
|    approx_kl            | 0.0006769445 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0185      |
|    explained_variance   | 0.213        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0163       |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.000464    |
|    value_loss           | 0.0314       |
------------------------------------------
Overall: Average Reward: 0.589343582786947
```

# 8x8 frozen lake map PPO - is_slippery off

```
Using cpu device
Logging to ./PPOtensorboard/PPO_3
Output 1: Average over 66 episodes - Reward: 0.0
-----------------------------
| time/              |      |
|    fps             | 1061 |
|    iterations      | 1    |
|    time_elapsed    | 1    |
|    total_timesteps | 2048 |
-----------------------------
Output 2: Average over 60 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 726        |
|    iterations           | 2          |
|    time_elapsed         | 5          |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.00955623 |
|    clip_fraction        | 0.039      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.38      |
|    explained_variance   | -42.3      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0104    |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.00942   |
|    value_loss           | 0.00396    |
----------------------------------------
Output 3: Average over 81 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 640        |
|    iterations           | 3          |
|    time_elapsed         | 9          |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.01566854 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | -3.58      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0388    |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0192    |
|    value_loss           | 0.000322   |
----------------------------------------
Output 4: Average over 96 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 602         |
|    iterations           | 4           |
|    time_elapsed         | 13          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.018199803 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -2.45       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0249     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0286     |
|    value_loss           | 2.69e-05    |
-----------------------------------------
Output 5: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 596         |
|    iterations           | 5           |
|    time_elapsed         | 17          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.014350644 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -8.98       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0441     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.024      |
|    value_loss           | 1.51e-05    |
-----------------------------------------
Output 6: Average over 81 episodes - Reward: 0.0
---------------------------------------
| time/                   |           |
|    fps                  | 599       |
|    iterations           | 6         |
|    time_elapsed         | 20        |
|    total_timesteps      | 12288     |
| train/                  |           |
|    approx_kl            | 0.0227642 |
|    clip_fraction        | 0.27      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.17     |
|    explained_variance   | -5.19     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0307   |
|    n_updates            | 50        |
|    policy_gradient_loss | -0.0235   |
|    value_loss           | 4.13e-07  |
---------------------------------------
Output 7: Average over 43 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 7           |
|    time_elapsed         | 24          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.018991759 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.1        |
|    explained_variance   | -4.36       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0311     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0251     |
|    value_loss           | 5.97e-08    |
-----------------------------------------
Output 8: Average over 38 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 8           |
|    time_elapsed         | 27          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.026966976 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -0.942      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0382     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0283     |
|    value_loss           | 5.09e-09    |
-----------------------------------------
Output 9: Average over 28 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 9           |
|    time_elapsed         | 31          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.013402104 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | -0.176      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0131     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0221     |
|    value_loss           | 1.44e-09    |
-----------------------------------------
Output 10: Average over 33 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 10          |
|    time_elapsed         | 34          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.016367413 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.985      |
|    explained_variance   | -1.98       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0328      |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 4.63e-10    |
-----------------------------------------
Output 11: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 11          |
|    time_elapsed         | 38          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.008981561 |
|    clip_fraction        | 0.0982      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.938      |
|    explained_variance   | -0.129      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000868    |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 2.04e-10    |
-----------------------------------------
Output 12: Average over 26 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 12          |
|    time_elapsed         | 41          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.007639297 |
|    clip_fraction        | 0.0567      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.928      |
|    explained_variance   | -0.584      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00501     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00755    |
|    value_loss           | 7.07e-11    |
-----------------------------------------
Output 13: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 13          |
|    time_elapsed         | 44          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.007142221 |
|    clip_fraction        | 0.0611      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.915      |
|    explained_variance   | -0.233      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0321     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00852    |
|    value_loss           | 6e-11       |
-----------------------------------------
Output 14: Average over 22 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 14          |
|    time_elapsed         | 48          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014465157 |
|    clip_fraction        | 0.0639      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.961      |
|    explained_variance   | -0.107      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.015      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00993    |
|    value_loss           | 4.76e-11    |
-----------------------------------------
Output 15: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 594         |
|    iterations           | 15          |
|    time_elapsed         | 51          |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.008315325 |
|    clip_fraction        | 0.0524      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.986      |
|    explained_variance   | -0.306      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0411     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00725    |
|    value_loss           | 1.34e-10    |
-----------------------------------------
Output 16: Average over 22 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 594         |
|    iterations           | 16          |
|    time_elapsed         | 55          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.030353658 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.974      |
|    explained_variance   | -8.91       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0423     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 1.69e-08    |
-----------------------------------------
Output 17: Average over 20 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 17           |
|    time_elapsed         | 58           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0075773764 |
|    clip_fraction        | 0.0686       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.919       |
|    explained_variance   | -4.13        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00834     |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00809     |
|    value_loss           | 1.11e-08     |
------------------------------------------
Output 18: Average over 21 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 591        |
|    iterations           | 18         |
|    time_elapsed         | 62         |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.00994532 |
|    clip_fraction        | 0.0387     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.89      |
|    explained_variance   | -1.29      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.012     |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.00679   |
|    value_loss           | 2.63e-07   |
----------------------------------------
Output 19: Average over 20 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 19           |
|    time_elapsed         | 65           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0070009637 |
|    clip_fraction        | 0.0705       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.856       |
|    explained_variance   | -1.09        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0126       |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00653     |
|    value_loss           | 1.24e-10     |
------------------------------------------
Output 20: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 586         |
|    iterations           | 20          |
|    time_elapsed         | 69          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.003147388 |
|    clip_fraction        | 0.0368      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.9        |
|    explained_variance   | -14.1       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00165    |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00722    |
|    value_loss           | 3.97e-07    |
-----------------------------------------
Output 21: Average over 28 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 585        |
|    iterations           | 21         |
|    time_elapsed         | 73         |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.04021986 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.937     |
|    explained_variance   | -7.35      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0531    |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0277    |
|    value_loss           | 1.46e-11   |
----------------------------------------
Output 22: Average over 28 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 582         |
|    iterations           | 22          |
|    time_elapsed         | 77          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.004611636 |
|    clip_fraction        | 0.0419      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.913      |
|    explained_variance   | -45.8       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0309     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 1.4e-10     |
-----------------------------------------
Output 23: Average over 22 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 580         |
|    iterations           | 23          |
|    time_elapsed         | 81          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.009748638 |
|    clip_fraction        | 0.0687      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.825      |
|    explained_variance   | -8.33       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0154     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 2.78e-11    |
-----------------------------------------
Output 24: Average over 24 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 579         |
|    iterations           | 24          |
|    time_elapsed         | 84          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.009819889 |
|    clip_fraction        | 0.0731      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | -1.38       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0269     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 5.27e-07    |
-----------------------------------------
Output 25: Average over 25 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 578         |
|    iterations           | 25          |
|    time_elapsed         | 88          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.005283555 |
|    clip_fraction        | 0.0595      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.718      |
|    explained_variance   | -117        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0329     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 3.69e-11    |
-----------------------------------------
Output 26: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 577         |
|    iterations           | 26          |
|    time_elapsed         | 92          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.008509366 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.695      |
|    explained_variance   | -1.55       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0429     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 2.06e-09    |
-----------------------------------------
Output 27: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 576         |
|    iterations           | 27          |
|    time_elapsed         | 95          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.005622804 |
|    clip_fraction        | 0.0463      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.668      |
|    explained_variance   | -0.671      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00442    |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00878    |
|    value_loss           | 7.83e-08    |
-----------------------------------------
Output 28: Average over 21 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 573          |
|    iterations           | 28           |
|    time_elapsed         | 100          |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0069093453 |
|    clip_fraction        | 0.0689       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.626       |
|    explained_variance   | -2.44        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0356      |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 2.54e-07     |
------------------------------------------
Output 29: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 567         |
|    iterations           | 29          |
|    time_elapsed         | 104         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.005159198 |
|    clip_fraction        | 0.0598      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | -1.97       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0184     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00691    |
|    value_loss           | 4.01e-07    |
-----------------------------------------
Output 30: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 562         |
|    iterations           | 30          |
|    time_elapsed         | 109         |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.004414201 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | -6.13       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0146     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00425    |
|    value_loss           | 1.8e-08     |
-----------------------------------------
Output 31: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 560         |
|    iterations           | 31          |
|    time_elapsed         | 113         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.012246929 |
|    clip_fraction        | 0.0894      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.621      |
|    explained_variance   | -1.93       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0205      |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 7.98e-08    |
-----------------------------------------
Output 32: Average over 21 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 560          |
|    iterations           | 32           |
|    time_elapsed         | 116          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0054439204 |
|    clip_fraction        | 0.0859       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.604       |
|    explained_variance   | -4.31        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00515      |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.0088      |
|    value_loss           | 6.81e-07     |
------------------------------------------
Output 33: Average over 20 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 560          |
|    iterations           | 33           |
|    time_elapsed         | 120          |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0038668327 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.544       |
|    explained_variance   | -1.79        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00313      |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00726     |
|    value_loss           | 8.97e-10     |
------------------------------------------
Output 34: Average over 21 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 560          |
|    iterations           | 34           |
|    time_elapsed         | 124          |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0059441226 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.502       |
|    explained_variance   | -0.25        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00443     |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00354     |
|    value_loss           | 3.36e-08     |
------------------------------------------
Output 35: Average over 21 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 559          |
|    iterations           | 35           |
|    time_elapsed         | 128          |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 0.0031801343 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.481       |
|    explained_variance   | -0.21        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00695      |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 3.05e-07     |
------------------------------------------
Output 36: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 557         |
|    iterations           | 36          |
|    time_elapsed         | 132         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.006066682 |
|    clip_fraction        | 0.0614      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.511      |
|    explained_variance   | -4.81       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00161     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 1.32e-06    |
-----------------------------------------
Output 37: Average over 20 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 37          |
|    time_elapsed         | 136         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.011733443 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | -7.46       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0511     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 2.85e-09    |
-----------------------------------------
Output 38: Average over 21 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 38           |
|    time_elapsed         | 140          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0035952302 |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.579       |
|    explained_variance   | -12.6        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00899     |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00587     |
|    value_loss           | 1.29e-09     |
------------------------------------------
Output 39: Average over 24 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 39           |
|    time_elapsed         | 144          |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0053893966 |
|    clip_fraction        | 0.0595       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.577       |
|    explained_variance   | -0.633       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0467      |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00952     |
|    value_loss           | 4.47e-10     |
------------------------------------------
Output 40: Average over 23 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 40          |
|    time_elapsed         | 147         |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.005165132 |
|    clip_fraction        | 0.0498      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.607      |
|    explained_variance   | -1.33       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.017      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0093     |
|    value_loss           | 3.38e-09    |
-----------------------------------------
Output 41: Average over 29 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 41           |
|    time_elapsed         | 151          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0058569466 |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.634       |
|    explained_variance   | -19.3        |
|    learning_rate        | 0.0003       |
|    loss                 | -8.77e-05    |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.0119      |
|    value_loss           | 2.01e-09     |
------------------------------------------
Output 42: Average over 34 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 42          |
|    time_elapsed         | 155         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.012088793 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | -2.64       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00813    |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0226     |
|    value_loss           | 1.52e-08    |
-----------------------------------------
Output 43: Average over 39 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 43          |
|    time_elapsed         | 159         |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.005060465 |
|    clip_fraction        | 0.0505      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | -0.461      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0149     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00886    |
|    value_loss           | 1.36e-07    |
-----------------------------------------
Output 44: Average over 36 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 44          |
|    time_elapsed         | 163         |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.006975901 |
|    clip_fraction        | 0.0779      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.612      |
|    explained_variance   | -6.58       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0164     |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00837    |
|    value_loss           | 8.42e-08    |
-----------------------------------------
Output 45: Average over 43 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 45          |
|    time_elapsed         | 168         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.008818854 |
|    clip_fraction        | 0.0763      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.649      |
|    explained_variance   | -1.05       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0235     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 7.49e-07    |
-----------------------------------------
Output 46: Average over 45 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 46          |
|    time_elapsed         | 172         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.009849883 |
|    clip_fraction        | 0.0842      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.661      |
|    explained_variance   | -0.729      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0395     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0127     |
|    value_loss           | 2.01e-07    |
-----------------------------------------
Output 47: Average over 38 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 47          |
|    time_elapsed         | 176         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.004301423 |
|    clip_fraction        | 0.0428      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.595      |
|    explained_variance   | -3.26       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0399     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00832    |
|    value_loss           | 3.98e-07    |
-----------------------------------------
Output 48: Average over 31 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 48          |
|    time_elapsed         | 180         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.006988625 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.539      |
|    explained_variance   | -4.09       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000367    |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00922    |
|    value_loss           | 4.15e-08    |
-----------------------------------------
Output 49: Average over 28 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 49           |
|    time_elapsed         | 183          |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 0.0064564827 |
|    clip_fraction        | 0.0758       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.474       |
|    explained_variance   | -0.605       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0167      |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.0161      |
|    value_loss           | 3.57e-08     |
------------------------------------------
Output 50: Average over 31 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 50          |
|    time_elapsed         | 187         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.009557342 |
|    clip_fraction        | 0.0523      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.491      |
|    explained_variance   | -1.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0326      |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 1.05e-06    |
-----------------------------------------
Output 51: Average over 39 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 51          |
|    time_elapsed         | 191         |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.009118833 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.565      |
|    explained_variance   | 0.11        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00869    |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 2.92e-08    |
-----------------------------------------
Output 52: Average over 58 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 52          |
|    time_elapsed         | 195         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.012226559 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | -0.315      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0414     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0203     |
|    value_loss           | 3.89e-08    |
-----------------------------------------
Output 53: Average over 69 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 53          |
|    time_elapsed         | 199         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.012715671 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | -2.82       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0204     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 2.58e-08    |
-----------------------------------------
Output 54: Average over 100 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 544        |
|    iterations           | 54         |
|    time_elapsed         | 203        |
|    total_timesteps      | 110592     |
| train/                  |            |
|    approx_kl            | 0.01670549 |
|    clip_fraction        | 0.151      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.859     |
|    explained_variance   | -4.27      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0253    |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.017     |
|    value_loss           | 3.43e-08   |
----------------------------------------
Output 55: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 55          |
|    time_elapsed         | 206         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.012626646 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.904      |
|    explained_variance   | -15.8       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0217     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 1.16e-06    |
-----------------------------------------
Output 56: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 56          |
|    time_elapsed         | 210         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.005975879 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.885      |
|    explained_variance   | -33.5       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00682     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 1.29e-05    |
-----------------------------------------
Output 57: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 57          |
|    time_elapsed         | 214         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.012422494 |
|    clip_fraction        | 0.0821      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.801      |
|    explained_variance   | -50.4       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0387     |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 8.55e-08    |
-----------------------------------------
Output 58: Average over 100 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 58           |
|    time_elapsed         | 217          |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0069034295 |
|    clip_fraction        | 0.082        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.808       |
|    explained_variance   | -19.5        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00482     |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.0137      |
|    value_loss           | 2.35e-06     |
------------------------------------------
Output 59: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 59          |
|    time_elapsed         | 221         |
|    total_timesteps      | 120832      |
| train/                  |             |
|    approx_kl            | 0.013671358 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.831      |
|    explained_variance   | -3.68       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0465     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0271     |
|    value_loss           | 1.85e-07    |
-----------------------------------------
Output 60: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 60          |
|    time_elapsed         | 224         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.012306709 |
|    clip_fraction        | 0.094       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.866      |
|    explained_variance   | -3.76       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0447     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 7.74e-07    |
-----------------------------------------
Output 61: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 61          |
|    time_elapsed         | 228         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.008398833 |
|    clip_fraction        | 0.0759      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.903      |
|    explained_variance   | -1.62       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00182    |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 3.14e-07    |
-----------------------------------------
Output 62: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 62          |
|    time_elapsed         | 231         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.015439628 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.929      |
|    explained_variance   | -8.42       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00164    |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 1.16e-07    |
-----------------------------------------
Output 63: Average over 99 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 548         |
|    iterations           | 63          |
|    time_elapsed         | 235         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.020197857 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.934      |
|    explained_variance   | -11         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0517     |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 6.92e-08    |
-----------------------------------------
Output 64: Average over 42 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 64          |
|    time_elapsed         | 238         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.019806769 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.884      |
|    explained_variance   | -2.62       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0211     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0212     |
|    value_loss           | 1.15e-08    |
-----------------------------------------
Output 65: Average over 34 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 65          |
|    time_elapsed         | 242         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.024046762 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.807      |
|    explained_variance   | -1.8        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 2.58e-07    |
-----------------------------------------
Output 66: Average over 27 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 66          |
|    time_elapsed         | 245         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.013581952 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.806      |
|    explained_variance   | -1.26       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0259     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 2.91e-07    |
-----------------------------------------
Output 67: Average over 29 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 67          |
|    time_elapsed         | 249         |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.040228367 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.84       |
|    explained_variance   | -2.55       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0168     |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 3.58e-09    |
-----------------------------------------
Output 68: Average over 24 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 68          |
|    time_elapsed         | 254         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.020994067 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.869      |
|    explained_variance   | -6.41       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0203     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 3.19e-07    |
-----------------------------------------
Output 69: Average over 32 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 547        |
|    iterations           | 69         |
|    time_elapsed         | 258        |
|    total_timesteps      | 141312     |
| train/                  |            |
|    approx_kl            | 0.02153644 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.89      |
|    explained_variance   | -2.73      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.000839   |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.00949   |
|    value_loss           | 8.66e-08   |
----------------------------------------
Output 70: Average over 43 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 70          |
|    time_elapsed         | 262         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.013302613 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.879      |
|    explained_variance   | -8.01       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0254      |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00803    |
|    value_loss           | 1.36e-08    |
-----------------------------------------
Output 71: Average over 30 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 545        |
|    iterations           | 71         |
|    time_elapsed         | 266        |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.02035419 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.823     |
|    explained_variance   | -13.2      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0151    |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0122    |
|    value_loss           | 8.2e-10    |
----------------------------------------
Output 72: Average over 29 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 72          |
|    time_elapsed         | 276         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.008115258 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.812      |
|    explained_variance   | -5.1        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0147     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00889    |
|    value_loss           | 3.74e-07    |
-----------------------------------------
Output 73: Average over 25 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 73         |
|    time_elapsed         | 280        |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.03493721 |
|    clip_fraction        | 0.195      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.706     |
|    explained_variance   | -2.62      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0276    |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0229    |
|    value_loss           | 8.99e-10   |
----------------------------------------
Output 74: Average over 25 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 74          |
|    time_elapsed         | 284         |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.028224444 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.769      |
|    explained_variance   | -7.42       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.107      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 6.23e-06    |
-----------------------------------------
Output 75: Average over 24 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 75          |
|    time_elapsed         | 288         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.010485093 |
|    clip_fraction        | 0.0696      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.745      |
|    explained_variance   | -6.15       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0268     |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 8.55e-09    |
-----------------------------------------
Output 76: Average over 24 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 533          |
|    iterations           | 76           |
|    time_elapsed         | 291          |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0060139643 |
|    clip_fraction        | 0.0277       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.713       |
|    explained_variance   | -4.79        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0206      |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.0065      |
|    value_loss           | 1.75e-10     |
------------------------------------------
Output 77: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 77          |
|    time_elapsed         | 295         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.007754194 |
|    clip_fraction        | 0.0593      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.712      |
|    explained_variance   | -17.4       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0004     |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00828    |
|    value_loss           | 4.52e-11    |
-----------------------------------------
Output 78: Average over 21 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 78          |
|    time_elapsed         | 299         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.004456833 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.702      |
|    explained_variance   | -133        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0228     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00714    |
|    value_loss           | 5.24e-10    |
-----------------------------------------
Output 79: Average over 23 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 79           |
|    time_elapsed         | 302          |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 0.0098529775 |
|    clip_fraction        | 0.0395       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | -13          |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0132      |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00566     |
|    value_loss           | 6.88e-12     |
------------------------------------------
Output 80: Average over 29 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 80          |
|    time_elapsed         | 306         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.015515402 |
|    clip_fraction        | 0.0878      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.617      |
|    explained_variance   | 0.00726     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0135     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 1.21e-10    |
-----------------------------------------
Output 81: Average over 25 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 81           |
|    time_elapsed         | 310          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0052757827 |
|    clip_fraction        | 0.0577       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.558       |
|    explained_variance   | -34.6        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0101       |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.0113      |
|    value_loss           | 3.01e-11     |
------------------------------------------
Output 82: Average over 25 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 82          |
|    time_elapsed         | 314         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.005551745 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.605      |
|    explained_variance   | -5.24       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0119     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 4.35e-11    |
-----------------------------------------
Output 83: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 83          |
|    time_elapsed         | 318         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.063710526 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.708      |
|    explained_variance   | -1.73       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0677     |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0256     |
|    value_loss           | 1.17e-06    |
-----------------------------------------
Output 84: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 84          |
|    time_elapsed         | 323         |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 0.014132043 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.85       |
|    explained_variance   | -22.1       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0287     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 5.75e-10    |
-----------------------------------------
Output 85: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 85          |
|    time_elapsed         | 327         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.011629807 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.856      |
|    explained_variance   | -71.8       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0349     |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 8.33e-09    |
-----------------------------------------
Output 86: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 86          |
|    time_elapsed         | 331         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.012347361 |
|    clip_fraction        | 0.0836      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.857      |
|    explained_variance   | -16.9       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0106     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00903    |
|    value_loss           | 5.73e-08    |
-----------------------------------------
Output 87: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 87          |
|    time_elapsed         | 336         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.025538405 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.851      |
|    explained_variance   | -13.5       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0659      |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0216     |
|    value_loss           | 3.07e-08    |
-----------------------------------------
Output 88: Average over 100 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 530          |
|    iterations           | 88           |
|    time_elapsed         | 339          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0062472364 |
|    clip_fraction        | 0.039        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.82        |
|    explained_variance   | -0.0114      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0239      |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00895     |
|    value_loss           | 0.000818     |
------------------------------------------
Output 89: Average over 100 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 89         |
|    time_elapsed         | 343        |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.01113071 |
|    clip_fraction        | 0.0902     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.809     |
|    explained_variance   | -0.602     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00152   |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.014     |
|    value_loss           | 5.5e-05    |
----------------------------------------
Output 90: Average over 100 episodes - Reward: 0.01
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 90          |
|    time_elapsed         | 348         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.011364978 |
|    clip_fraction        | 0.0644      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.822      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0189     |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.019      |
|    value_loss           | 0.000345    |
-----------------------------------------
Output 91: Average over 100 episodes - Reward: 0.08
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 91          |
|    time_elapsed         | 352         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.017656239 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.804      |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0294     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0176     |
|    value_loss           | 0.00873     |
-----------------------------------------
Output 92: Average over 100 episodes - Reward: 0.21
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 92          |
|    time_elapsed         | 357         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.020156778 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00215    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0265     |
|    value_loss           | 0.0316      |
-----------------------------------------
Output 93: Average over 100 episodes - Reward: 0.39
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 93          |
|    time_elapsed         | 360         |
|    total_timesteps      | 190464      |
| train/                  |             |
|    approx_kl            | 0.021701064 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.704      |
|    explained_variance   | 0.483       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.0601      |
-----------------------------------------
Output 94: Average over 100 episodes - Reward: 0.59
----------------------------------------
| time/                   |            |
|    fps                  | 527        |
|    iterations           | 94         |
|    time_elapsed         | 364        |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.01280774 |
|    clip_fraction        | 0.196      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.66      |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0163     |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.0712     |
----------------------------------------
Output 95: Average over 100 episodes - Reward: 0.76
----------------------------------------
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 95         |
|    time_elapsed         | 368        |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.01367118 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 0.326      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00784    |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.0725     |
----------------------------------------
Output 96: Average over 100 episodes - Reward: 0.86
----------------------------------------
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 96         |
|    time_elapsed         | 372        |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.01650661 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.535     |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00575   |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.0215    |
|    value_loss           | 0.0594     |
----------------------------------------
Output 97: Average over 100 episodes - Reward: 0.88
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 97          |
|    time_elapsed         | 375         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.008901229 |
|    clip_fraction        | 0.0927      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.477      |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0244      |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.0417      |
-----------------------------------------
Output 98: Average over 100 episodes - Reward: 0.9
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 98          |
|    time_elapsed         | 379         |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 0.005698063 |
|    clip_fraction        | 0.0885      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.434      |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00462     |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 0.029       |
-----------------------------------------
Output 99: Average over 100 episodes - Reward: 0.92
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 99          |
|    time_elapsed         | 383         |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.005716242 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.375      |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00289     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.03        |
-----------------------------------------
Output 100: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 100         |
|    time_elapsed         | 387         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.008601718 |
|    clip_fraction        | 0.0905      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.335      |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000534   |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.01       |
|    value_loss           | 0.0218      |
-----------------------------------------
Output 101: Average over 100 episodes - Reward: 0.98
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 101         |
|    time_elapsed         | 391         |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.010685238 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.299      |
|    explained_variance   | 0.497       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0442     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.00493     |
-----------------------------------------
Output 102: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 527          |
|    iterations           | 102          |
|    time_elapsed         | 396          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0069757365 |
|    clip_fraction        | 0.069        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.251       |
|    explained_variance   | 0.186        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0141      |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.00894     |
|    value_loss           | 0.00916      |
------------------------------------------
Output 103: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 103         |
|    time_elapsed         | 400         |
|    total_timesteps      | 210944      |
| train/                  |             |
|    approx_kl            | 0.013260649 |
|    clip_fraction        | 0.0548      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.199      |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0234     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.00374     |
-----------------------------------------
Output 104: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 104         |
|    time_elapsed         | 405         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.009351274 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.128      |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0187     |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 3.4e-05     |
-----------------------------------------
Output 105: Average over 100 episodes - Reward: 0.97
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 105         |
|    time_elapsed         | 408         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.007741304 |
|    clip_fraction        | 0.026       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0102     |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.000958   |
|    value_loss           | 0.00299     |
-----------------------------------------
Output 106: Average over 100 episodes - Reward: 0.98
----------------------------------------
| time/                   |            |
|    fps                  | 524        |
|    iterations           | 106        |
|    time_elapsed         | 413        |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.01135004 |
|    clip_fraction        | 0.0772     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.121     |
|    explained_variance   | 0.179      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00639   |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.00729   |
|    value_loss           | 0.00913    |
----------------------------------------
Output 107: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 522        |
|    iterations           | 107        |
|    time_elapsed         | 419        |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.00827909 |
|    clip_fraction        | 0.0416     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0911    |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00452    |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.00714   |
|    value_loss           | 0.0102     |
----------------------------------------
Output 108: Average over 100 episodes - Reward: 0.98
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 108          |
|    time_elapsed         | 422          |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0028982228 |
|    clip_fraction        | 0.0285       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0757      |
|    explained_variance   | 0.343        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00402      |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00497     |
|    value_loss           | 0.00289      |
------------------------------------------
Output 109: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 523         |
|    iterations           | 109         |
|    time_elapsed         | 426         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.005481352 |
|    clip_fraction        | 0.0226      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.062      |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0148     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0055     |
|    value_loss           | 0.00389     |
-----------------------------------------
Output 110: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 110          |
|    time_elapsed         | 430          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0025658521 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0527      |
|    explained_variance   | 0.337        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0028      |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00274     |
|    value_loss           | 0.00302      |
------------------------------------------
Output 111: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 111          |
|    time_elapsed         | 434          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0014019976 |
|    clip_fraction        | 0.00674      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0404      |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000515    |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00233     |
|    value_loss           | 8.9e-06      |
------------------------------------------
Output 112: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 112          |
|    time_elapsed         | 438          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0059091668 |
|    clip_fraction        | 0.0213       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0467      |
|    explained_variance   | 0.341        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00764     |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.00433     |
|    value_loss           | 0.00303      |
------------------------------------------
Output 113: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 523          |
|    iterations           | 113          |
|    time_elapsed         | 441          |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 0.0017481251 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0415      |
|    explained_variance   | 0.448        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000808    |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00418     |
|    value_loss           | 0.000374     |
------------------------------------------
Output 114: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 524         |
|    iterations           | 114         |
|    time_elapsed         | 445         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.010577077 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0238     |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00676    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00376    |
|    value_loss           | 2.5e-06     |
-----------------------------------------
Output 115: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 115          |
|    time_elapsed         | 448          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0062539554 |
|    clip_fraction        | 0.00322      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.033       |
|    explained_variance   | 0.358        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00559      |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00259     |
|    value_loss           | 0.00409      |
------------------------------------------
Output 116: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 524          |
|    iterations           | 116          |
|    time_elapsed         | 452          |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0074264808 |
|    clip_fraction        | 0.0343       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0724      |
|    explained_variance   | 0.91         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0222      |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.00247     |
|    value_loss           | 1.02e-05     |
------------------------------------------
Output 117: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 117         |
|    time_elapsed         | 456         |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.015120713 |
|    clip_fraction        | 0.0898      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0819     |
|    explained_variance   | 0.981       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00461    |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 2.49e-05    |
-----------------------------------------
Output 118: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 118         |
|    time_elapsed         | 459         |
|    total_timesteps      | 241664      |
| train/                  |             |
|    approx_kl            | 0.009952472 |
|    clip_fraction        | 0.00884     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0523     |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00998    |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00764    |
|    value_loss           | 5.08e-06    |
-----------------------------------------
Output 119: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 119         |
|    time_elapsed         | 463         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.017145326 |
|    clip_fraction        | 0.0217      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0652     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0207     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00636    |
|    value_loss           | 9.34e-07    |
-----------------------------------------
Output 120: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 120         |
|    time_elapsed         | 467         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.008581959 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0015     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0213     |
|    value_loss           | 0.00273     |
-----------------------------------------
Output 121: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 121         |
|    time_elapsed         | 470         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.004646722 |
|    clip_fraction        | 0.0365      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00112     |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00624    |
|    value_loss           | 3.38e-05    |
-----------------------------------------
Output 122: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 526         |
|    iterations           | 122         |
|    time_elapsed         | 474         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.014251228 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0732     |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.019      |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 2.19e-05    |
-----------------------------------------
Output 123: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 123         |
|    time_elapsed         | 477         |
|    total_timesteps      | 251904      |
| train/                  |             |
|    approx_kl            | 0.005732785 |
|    clip_fraction        | 0.0104      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0525     |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00159    |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00571    |
|    value_loss           | 4.9e-06     |
-----------------------------------------
Output 124: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 527         |
|    iterations           | 124         |
|    time_elapsed         | 481         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.013754174 |
|    clip_fraction        | 0.0817      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.106      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0421     |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0144     |
|    value_loss           | 1.55e-06    |
-----------------------------------------
Output 125: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 125         |
|    time_elapsed         | 484         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.026324498 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.138      |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0331     |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0305     |
|    value_loss           | 7.3e-05     |
-----------------------------------------
Output 126: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 126         |
|    time_elapsed         | 488         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.015886866 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00853    |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0264     |
|    value_loss           | 4.6e-05     |
-----------------------------------------
Output 127: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 127         |
|    time_elapsed         | 491         |
|    total_timesteps      | 260096      |
| train/                  |             |
|    approx_kl            | 0.011791678 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0739     |
|    explained_variance   | 0.989       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 1.14e-05    |
-----------------------------------------
Output 128: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 529        |
|    iterations           | 128        |
|    time_elapsed         | 495        |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.00629388 |
|    clip_fraction        | 0.0325     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0565    |
|    explained_variance   | 0.998      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0169    |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.00935   |
|    value_loss           | 2.65e-06   |
----------------------------------------
Output 129: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 129         |
|    time_elapsed         | 499         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.011957061 |
|    clip_fraction        | 0.0275      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0623     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.025      |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0026     |
|    value_loss           | 3.76e-08    |
-----------------------------------------
Output 130: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 130         |
|    time_elapsed         | 502         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.058459826 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0989     |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0212     |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0266     |
|    value_loss           | 0.000106    |
-----------------------------------------
Output 131: Average over 100 episodes - Reward: 0.92
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 131         |
|    time_elapsed         | 506         |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.032891635 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0545     |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.017      |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 1.35e-05    |
-----------------------------------------
Output 132: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 132         |
|    time_elapsed         | 511         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.013935834 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0974     |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.018       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0174     |
|    value_loss           | 0.0304      |
-----------------------------------------
Output 133: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 528        |
|    iterations           | 133        |
|    time_elapsed         | 515        |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.07456036 |
|    clip_fraction        | 0.0839     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0929    |
|    explained_variance   | 0.305      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0539    |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.00332    |
----------------------------------------
Output 134: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 134         |
|    time_elapsed         | 518         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.022734342 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.252      |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0368     |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0344     |
|    value_loss           | 0.000256    |
-----------------------------------------
Output 135: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 135         |
|    time_elapsed         | 522         |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.012208366 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.276       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0021     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.022      |
|    value_loss           | 0.00407     |
-----------------------------------------
Output 136: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 136          |
|    time_elapsed         | 526          |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0036415965 |
|    clip_fraction        | 0.0453       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.147       |
|    explained_variance   | 0.305        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0146      |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.00785     |
|    value_loss           | 0.00354      |
------------------------------------------
Output 137: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 137         |
|    time_elapsed         | 530         |
|    total_timesteps      | 280576      |
| train/                  |             |
|    approx_kl            | 0.019062625 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.129      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0541     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0197     |
|    value_loss           | 8.27e-05    |
-----------------------------------------
Output 138: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 529          |
|    iterations           | 138          |
|    time_elapsed         | 534          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0016352041 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0.985        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00752      |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.01        |
|    value_loss           | 2.09e-05     |
------------------------------------------
Output 139: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 529        |
|    iterations           | 139        |
|    time_elapsed         | 538        |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.02305676 |
|    clip_fraction        | 0.0548     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0834    |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.000275  |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.00379    |
----------------------------------------
Output 140: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 529           |
|    iterations           | 140           |
|    time_elapsed         | 541           |
|    total_timesteps      | 286720        |
| train/                  |               |
|    approx_kl            | 0.00052235235 |
|    clip_fraction        | 0.0042        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0709       |
|    explained_variance   | 0.931         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00108      |
|    n_updates            | 1390          |
|    policy_gradient_loss | -0.00177      |
|    value_loss           | 8.42e-06      |
-------------------------------------------
Output 141: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 141          |
|    time_elapsed         | 546          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0014757712 |
|    clip_fraction        | 0.00884      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0651      |
|    explained_variance   | 0.987        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0127      |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00485     |
|    value_loss           | 9.28e-06     |
------------------------------------------
Output 142: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 142          |
|    time_elapsed         | 550          |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 0.0007760164 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0595      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000211    |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00291     |
|    value_loss           | 1.47e-06     |
------------------------------------------
Output 143: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 143          |
|    time_elapsed         | 554          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0010011215 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0589      |
|    explained_variance   | 0.522        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0209      |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 0.00196      |
------------------------------------------
Output 144: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 528          |
|    iterations           | 144          |
|    time_elapsed         | 557          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0010266319 |
|    clip_fraction        | 0.00967      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0598      |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000274    |
|    n_updates            | 1430         |
|    policy_gradient_loss | -0.000328    |
|    value_loss           | 3.46e-06     |
------------------------------------------
Output 145: Average over 100 episodes - Reward: 0.28
-----------------------------------------
| time/                   |             |
|    fps                  | 528         |
|    iterations           | 145         |
|    time_elapsed         | 561         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.020533033 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.137      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00723    |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 1.86e-06    |
-----------------------------------------
Output 146: Average over 100 episodes - Reward: 0.69
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 146         |
|    time_elapsed         | 565         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.044081524 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.187      |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0433      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0264     |
|    value_loss           | 0.105       |
-----------------------------------------
Output 147: Average over 100 episodes - Reward: 0.97
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 147         |
|    time_elapsed         | 568         |
|    total_timesteps      | 301056      |
| train/                  |             |
|    approx_kl            | 0.050612304 |
|    clip_fraction        | 0.0981      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00351     |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0317     |
|    value_loss           | 0.0657      |
-----------------------------------------
Output 148: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 529         |
|    iterations           | 148         |
|    time_elapsed         | 572         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.013171597 |
|    clip_fraction        | 0.0474      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | -0.883      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0186     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00761    |
|    value_loss           | 0.00572     |
-----------------------------------------
Output 149: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 149         |
|    time_elapsed         | 575         |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.011850243 |
|    clip_fraction        | 0.0778      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.165      |
|    explained_variance   | 0.606       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.000127    |
-----------------------------------------
Output 150: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 150        |
|    time_elapsed         | 578        |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.03802294 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0922    |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0235    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0286    |
|    value_loss           | 0.000102   |
----------------------------------------
Output 151: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 151         |
|    time_elapsed         | 582         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.021127945 |
|    clip_fraction        | 0.0455      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0713     |
|    explained_variance   | 0.986       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0229     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 1.57e-05    |
-----------------------------------------
Output 152: Average over 100 episodes - Reward: 0.99
----------------------------------------
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 152        |
|    time_elapsed         | 586        |
|    total_timesteps      | 311296     |
| train/                  |            |
|    approx_kl            | 0.06137252 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0913    |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0165    |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 8.68e-05   |
----------------------------------------
Output 153: Average over 100 episodes - Reward: 0.98
----------------------------------------
| time/                   |            |
|    fps                  | 530        |
|    iterations           | 153        |
|    time_elapsed         | 590        |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.05996625 |
|    clip_fraction        | 0.0317     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0398    |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0214    |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 0.00163    |
----------------------------------------
Output 154: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 154         |
|    time_elapsed         | 593         |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.009630589 |
|    clip_fraction        | 0.0207      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.029      |
|    explained_variance   | 0.325       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0341     |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00201    |
|    value_loss           | 0.00515     |
-----------------------------------------
Output 155: Average over 99 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 530         |
|    iterations           | 155         |
|    time_elapsed         | 597         |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.017681766 |
|    clip_fraction        | 0.0116      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0324     |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0167     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00306    |
|    value_loss           | 5.87e-06    |
-----------------------------------------
Output 156: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 156         |
|    time_elapsed         | 601         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.014563652 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.263      |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0462     |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0532     |
|    value_loss           | 0.000973    |
-----------------------------------------
Output 157: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 157         |
|    time_elapsed         | 605         |
|    total_timesteps      | 321536      |
| train/                  |             |
|    approx_kl            | 0.006305323 |
|    clip_fraction        | 0.0923      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.163      |
|    explained_variance   | 0.26        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0305     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.000407    |
-----------------------------------------
Output 158: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 158          |
|    time_elapsed         | 608          |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 0.0055059665 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.137       |
|    explained_variance   | 0.4          |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0192      |
|    n_updates            | 1570         |
|    policy_gradient_loss | -0.0213      |
|    value_loss           | 0.00303      |
------------------------------------------
Output 159: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 159         |
|    time_elapsed         | 612         |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.021674046 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0235     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.00264     |
-----------------------------------------
Output 160: Average over 100 episodes - Reward: 1.0
-------------------------------------------
| time/                   |               |
|    fps                  | 531           |
|    iterations           | 160           |
|    time_elapsed         | 616           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00069968007 |
|    clip_fraction        | 0.015         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0824       |
|    explained_variance   | 0.953         |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00678      |
|    n_updates            | 1590          |
|    policy_gradient_loss | -0.00378      |
|    value_loss           | 2.83e-05      |
-------------------------------------------
Output 161: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 161         |
|    time_elapsed         | 620         |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.010805925 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0663     |
|    explained_variance   | 0.991       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.019      |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00768    |
|    value_loss           | 1.25e-05    |
-----------------------------------------
Output 162: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 162         |
|    time_elapsed         | 624         |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.008632803 |
|    clip_fraction        | 0.0285      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.068      |
|    explained_variance   | 0.995       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00358    |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00582    |
|    value_loss           | 5.94e-06    |
-----------------------------------------
Output 163: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 163         |
|    time_elapsed         | 628         |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.015478287 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0811     |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0104     |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.00221     |
-----------------------------------------
Output 164: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 164         |
|    time_elapsed         | 632         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.048117593 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0158     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 1.39e-05    |
-----------------------------------------
Output 165: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 165         |
|    time_elapsed         | 636         |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.010727936 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.213      |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.049      |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.0338     |
|    value_loss           | 0.000273    |
-----------------------------------------
Output 166: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 166         |
|    time_elapsed         | 639         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.009780035 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0587     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0328     |
|    value_loss           | 0.000128    |
-----------------------------------------
Output 167: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 167         |
|    time_elapsed         | 643         |
|    total_timesteps      | 342016      |
| train/                  |             |
|    approx_kl            | 0.019363374 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.031      |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0216     |
|    value_loss           | 5.82e-05    |
-----------------------------------------
Output 168: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 168         |
|    time_elapsed         | 647         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.047899656 |
|    clip_fraction        | 0.0505      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0531     |
|    explained_variance   | 0.977       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0197     |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.0188     |
|    value_loss           | 3.72e-05    |
-----------------------------------------
Output 169: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 531         |
|    iterations           | 169         |
|    time_elapsed         | 650         |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.002908793 |
|    clip_fraction        | 0.00869     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0347     |
|    explained_variance   | 0.994       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00442    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00548    |
|    value_loss           | 6.55e-06    |
-----------------------------------------
Output 170: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 531          |
|    iterations           | 170          |
|    time_elapsed         | 654          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0026292368 |
|    clip_fraction        | 0.00801      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0223      |
|    explained_variance   | 0.417        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00327     |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.000831    |
|    value_loss           | 0.00385      |
------------------------------------------
Output 171: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 532          |
|    iterations           | 171          |
|    time_elapsed         | 658          |
|    total_timesteps      | 350208       |
| train/                  |              |
|    approx_kl            | 0.0010073154 |
|    clip_fraction        | 0.00254      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0149      |
|    explained_variance   | 0.275        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00373      |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.000985    |
|    value_loss           | 0.00359      |
------------------------------------------
Output 172: Average over 100 episodes - Reward: 0.02
---------------------------------------
| time/                   |           |
|    fps                  | 532       |
|    iterations           | 172       |
|    time_elapsed         | 661       |
|    total_timesteps      | 352256    |
| train/                  |           |
|    approx_kl            | 0.2901681 |
|    clip_fraction        | 0.131     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0757   |
|    explained_variance   | 0.928     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0524   |
|    n_updates            | 1710      |
|    policy_gradient_loss | -0.0247   |
|    value_loss           | 6.01e-06  |
---------------------------------------
Output 173: Average over 100 episodes - Reward: 0.14
-----------------------------------------
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 173         |
|    time_elapsed         | 665         |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.042466976 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.297      |
|    explained_variance   | -0.552      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0616     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0343     |
|    value_loss           | 0.03        |
-----------------------------------------
Output 174: Average over 100 episodes - Reward: 0.4
-----------------------------------------
| time/                   |             |
|    fps                  | 532         |
|    iterations           | 174         |
|    time_elapsed         | 669         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.030728351 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.269      |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00044    |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0231     |
|    value_loss           | 0.0341      |
-----------------------------------------
Output 175: Average over 100 episodes - Reward: 0.58
----------------------------------------
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 175        |
|    time_elapsed         | 672        |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.02894476 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.261     |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00303   |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0365    |
|    value_loss           | 0.0605     |
----------------------------------------
Output 176: Average over 100 episodes - Reward: 0.77
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 176         |
|    time_elapsed         | 675         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.008892574 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00866     |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.0284     |
|    value_loss           | 0.0747      |
-----------------------------------------
Output 177: Average over 100 episodes - Reward: 0.88
----------------------------------------
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 177        |
|    time_elapsed         | 679        |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.00976898 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.206     |
|    explained_variance   | 0.265      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00612   |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0246    |
|    value_loss           | 0.0492     |
----------------------------------------
Output 178: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 178         |
|    time_elapsed         | 683         |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.030583246 |
|    clip_fraction        | 0.0581      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.162      |
|    explained_variance   | 0.204       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.027      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0194     |
|    value_loss           | 0.0266      |
-----------------------------------------
Output 179: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 532        |
|    iterations           | 179        |
|    time_elapsed         | 687        |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.03395506 |
|    clip_fraction        | 0.0743     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.162     |
|    explained_variance   | 0.107      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0357    |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.0113    |
|    value_loss           | 0.000405   |
----------------------------------------
Output 180: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 180        |
|    time_elapsed         | 691        |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.05929849 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0567    |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.000579   |
----------------------------------------
Output 181: Average over 100 episodes - Reward: 0.99
----------------------------------------
| time/                   |            |
|    fps                  | 533        |
|    iterations           | 181        |
|    time_elapsed         | 695        |
|    total_timesteps      | 370688     |
| train/                  |            |
|    approx_kl            | 0.09613324 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.168     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0522    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0483    |
|    value_loss           | 0.000214   |
----------------------------------------
Output 182: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 182         |
|    time_elapsed         | 698         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.017891478 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.244      |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.00344     |
-----------------------------------------
Output 183: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 533         |
|    iterations           | 183         |
|    time_elapsed         | 701         |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.011788532 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.178      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.024      |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0283     |
|    value_loss           | 0.000135    |
-----------------------------------------
Output 184: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 184         |
|    time_elapsed         | 705         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.008612316 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0106     |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0198     |
|    value_loss           | 7.75e-05    |
-----------------------------------------
Output 185: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 185         |
|    time_elapsed         | 709         |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.004112335 |
|    clip_fraction        | 0.0343      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00236    |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.00965    |
|    value_loss           | 2.19e-05    |
-----------------------------------------
Output 186: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 186          |
|    time_elapsed         | 712          |
|    total_timesteps      | 380928       |
| train/                  |              |
|    approx_kl            | 0.0022830898 |
|    clip_fraction        | 0.0247       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0736      |
|    explained_variance   | 0.312        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.02        |
|    n_updates            | 1850         |
|    policy_gradient_loss | -0.00732     |
|    value_loss           | 0.00338      |
------------------------------------------
Output 187: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 187         |
|    time_elapsed         | 716         |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.008066225 |
|    clip_fraction        | 0.0136      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0681     |
|    explained_variance   | 0.961       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0156     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.000455   |
|    value_loss           | 1.31e-05    |
-----------------------------------------
Output 188: Average over 100 episodes - Reward: 0.99
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 188          |
|    time_elapsed         | 720          |
|    total_timesteps      | 385024       |
| train/                  |              |
|    approx_kl            | 0.0084254965 |
|    clip_fraction        | 0.0552       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0681      |
|    explained_variance   | 0.292        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00263     |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00953     |
|    value_loss           | 0.00355      |
------------------------------------------
Output 189: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 189         |
|    time_elapsed         | 724         |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.073140174 |
|    clip_fraction        | 0.0636      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0553     |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0444     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 0.00339     |
-----------------------------------------
Output 190: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 190         |
|    time_elapsed         | 727         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.073582634 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0897     |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0441     |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 1.42e-05    |
-----------------------------------------
Output 191: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 191         |
|    time_elapsed         | 731         |
|    total_timesteps      | 391168      |
| train/                  |             |
|    approx_kl            | 0.021584101 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.306      |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0316     |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0264     |
|    value_loss           | 0.000242    |
-----------------------------------------
Output 192: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 192         |
|    time_elapsed         | 735         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.016901875 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.212      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0377     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.000136    |
-----------------------------------------
Output 193: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 193         |
|    time_elapsed         | 738         |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.008358977 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.186      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0349     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0265     |
|    value_loss           | 8.67e-05    |
-----------------------------------------
Output 194: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 194         |
|    time_elapsed         | 742         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.015848577 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.981       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0229     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0219     |
|    value_loss           | 2.79e-05    |
-----------------------------------------
Output 195: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 195         |
|    time_elapsed         | 746         |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.004383558 |
|    clip_fraction        | 0.0651      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.153      |
|    explained_variance   | 0.993       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0115      |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00751    |
|    value_loss           | 8.85e-06    |
-----------------------------------------
Output 196: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 196          |
|    time_elapsed         | 750          |
|    total_timesteps      | 401408       |
| train/                  |              |
|    approx_kl            | 0.0048411153 |
|    clip_fraction        | 0.0368       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.145       |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00945     |
|    n_updates            | 1950         |
|    policy_gradient_loss | -0.00668     |
|    value_loss           | 7.18e-06     |
------------------------------------------
Output 197: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 197         |
|    time_elapsed         | 753         |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.010263557 |
|    clip_fraction        | 0.0663      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0103      |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00914    |
|    value_loss           | 6e-06       |
-----------------------------------------
Output 198: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 198         |
|    time_elapsed         | 757         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.013884893 |
|    clip_fraction        | 0.0833      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.153      |
|    explained_variance   | 0.996       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0192     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.00798    |
|    value_loss           | 6.87e-06    |
-----------------------------------------
Output 199: Average over 100 episodes - Reward: 0.95
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 199         |
|    time_elapsed         | 761         |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.038860723 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.166      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0314     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 2.81e-08    |
-----------------------------------------
Output 200: Average over 100 episodes - Reward: 0.96
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 200         |
|    time_elapsed         | 765         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.014950564 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.224      |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0236     |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0247     |
|    value_loss           | 0.0106      |
-----------------------------------------
Output 201: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 201          |
|    time_elapsed         | 769          |
|    total_timesteps      | 411648       |
| train/                  |              |
|    approx_kl            | 0.0066884584 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.165       |
|    explained_variance   | 0.192        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00062      |
|    n_updates            | 2000         |
|    policy_gradient_loss | -0.0145      |
|    value_loss           | 0.0114       |
------------------------------------------
Output 202: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 202          |
|    time_elapsed         | 773          |
|    total_timesteps      | 413696       |
| train/                  |              |
|    approx_kl            | 0.0139368465 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.156       |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0227      |
|    n_updates            | 2010         |
|    policy_gradient_loss | -0.0171      |
|    value_loss           | 9.35e-05     |
------------------------------------------
Output 203: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 203        |
|    time_elapsed         | 777        |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.03576683 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.165     |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0444    |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.0249    |
|    value_loss           | 5.04e-05   |
----------------------------------------
Output 204: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 204        |
|    time_elapsed         | 781        |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.03578677 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.217     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.012     |
|    n_updates            | 2030       |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.000194   |
----------------------------------------
Output 205: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 205        |
|    time_elapsed         | 784        |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.01840649 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.166     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0543    |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0279    |
|    value_loss           | 0.000102   |
----------------------------------------
Output 206: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 206        |
|    time_elapsed         | 788        |
|    total_timesteps      | 421888     |
| train/                  |            |
|    approx_kl            | 0.05715007 |
|    clip_fraction        | 0.149      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.165     |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0422    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0313    |
|    value_loss           | 3.13e-05   |
----------------------------------------
Output 207: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 207         |
|    time_elapsed         | 791         |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.029173188 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.237      |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0528     |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0346     |
|    value_loss           | 0.000107    |
-----------------------------------------
Output 208: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 208         |
|    time_elapsed         | 795         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.024264868 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.153      |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0359     |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0314     |
|    value_loss           | 4.99e-05    |
-----------------------------------------
Output 209: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 209         |
|    time_elapsed         | 798         |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.029636899 |
|    clip_fraction        | 0.0254      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0886     |
|    explained_variance   | 0.989       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.013      |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 1.48e-05    |
-----------------------------------------
Output 210: Average over 100 episodes - Reward: 0.94
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 210         |
|    time_elapsed         | 802         |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.025580196 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.152      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0544     |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0229     |
|    value_loss           | 1.52e-06    |
-----------------------------------------
Output 211: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 211         |
|    time_elapsed         | 806         |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.021380141 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.254      |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00586     |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0225     |
|    value_loss           | 0.0194      |
-----------------------------------------
Output 212: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 212         |
|    time_elapsed         | 809         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.028818797 |
|    clip_fraction        | 0.0926      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.233      |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0231     |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.019      |
|    value_loss           | 0.00433     |
-----------------------------------------
Output 213: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 213         |
|    time_elapsed         | 812         |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.018327728 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.216      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0117     |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.023      |
|    value_loss           | 0.000145    |
-----------------------------------------
Output 214: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 214         |
|    time_elapsed         | 816         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.013472239 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.165      |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0247     |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0246     |
|    value_loss           | 5.97e-05    |
-----------------------------------------
Output 215: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 215        |
|    time_elapsed         | 820        |
|    total_timesteps      | 440320     |
| train/                  |            |
|    approx_kl            | 0.01153482 |
|    clip_fraction        | 0.0393     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00701   |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0129    |
|    value_loss           | 3.3e-05    |
----------------------------------------
Output 216: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 216          |
|    time_elapsed         | 823          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0028144568 |
|    clip_fraction        | 0.0302       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | 0.99         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00476     |
|    n_updates            | 2150         |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 1.31e-05     |
------------------------------------------
Output 217: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 217         |
|    time_elapsed         | 827         |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.003683574 |
|    clip_fraction        | 0.0441      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.992       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0206     |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.00671    |
|    value_loss           | 1.01e-05    |
-----------------------------------------
Output 218: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 218          |
|    time_elapsed         | 831          |
|    total_timesteps      | 446464       |
| train/                  |              |
|    approx_kl            | 0.0022306882 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00146      |
|    n_updates            | 2170         |
|    policy_gradient_loss | -0.00431     |
|    value_loss           | 5.79e-06     |
------------------------------------------
Output 219: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 537         |
|    iterations           | 219         |
|    time_elapsed         | 835         |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.005030704 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0945     |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00336    |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.00516    |
|    value_loss           | 4.16e-06    |
-----------------------------------------
Output 220: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 220          |
|    time_elapsed         | 839          |
|    total_timesteps      | 450560       |
| train/                  |              |
|    approx_kl            | 0.0029843808 |
|    clip_fraction        | 0.0484       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00348     |
|    n_updates            | 2190         |
|    policy_gradient_loss | -0.00358     |
|    value_loss           | 1.08e-06     |
------------------------------------------
Output 221: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 221         |
|    time_elapsed         | 842         |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.007443277 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.135      |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00148    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00374    |
|    value_loss           | 2.18e-06    |
-----------------------------------------
Output 222: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 536         |
|    iterations           | 222         |
|    time_elapsed         | 846         |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.012329534 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.14       |
|    explained_variance   | 0.992       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00334    |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0231     |
|    value_loss           | 1e-05       |
-----------------------------------------
Output 223: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 223          |
|    time_elapsed         | 850          |
|    total_timesteps      | 456704       |
| train/                  |              |
|    approx_kl            | 0.0057616746 |
|    clip_fraction        | 0.0388       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0988      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00251      |
|    n_updates            | 2220         |
|    policy_gradient_loss | -0.00819     |
|    value_loss           | 1.73e-06     |
------------------------------------------
Output 224: Average over 100 episodes - Reward: 0.6
------------------------------------------
| time/                   |              |
|    fps                  | 536          |
|    iterations           | 224          |
|    time_elapsed         | 854          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0147109665 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0258      |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.013       |
|    value_loss           | 1.03e-06     |
------------------------------------------
Output 225: Average over 100 episodes - Reward: 0.84
----------------------------------------
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 225        |
|    time_elapsed         | 858        |
|    total_timesteps      | 460800     |
| train/                  |            |
|    approx_kl            | 0.04571975 |
|    clip_fraction        | 0.157      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.221     |
|    explained_variance   | 0.0814     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0359     |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0224    |
|    value_loss           | 0.0896     |
----------------------------------------
Output 226: Average over 100 episodes - Reward: 0.99
---------------------------------------
| time/                   |           |
|    fps                  | 536       |
|    iterations           | 226       |
|    time_elapsed         | 862       |
|    total_timesteps      | 462848    |
| train/                  |           |
|    approx_kl            | 0.0283792 |
|    clip_fraction        | 0.0997    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.184    |
|    explained_variance   | 0.105     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0148    |
|    n_updates            | 2250      |
|    policy_gradient_loss | -0.0207   |
|    value_loss           | 0.0395    |
---------------------------------------
Output 227: Average over 100 episodes - Reward: 0.92
----------------------------------------
| time/                   |            |
|    fps                  | 536        |
|    iterations           | 227        |
|    time_elapsed         | 866        |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.06335106 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.218     |
|    explained_variance   | -0.23      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0266    |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.0223    |
|    value_loss           | 0.00267    |
----------------------------------------
Output 228: Average over 100 episodes - Reward: 0.99
----------------------------------------
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 228        |
|    time_elapsed         | 871        |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.01186456 |
|    clip_fraction        | 0.156      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.335     |
|    explained_variance   | 0.0934     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0054     |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0091    |
|    value_loss           | 0.0289     |
----------------------------------------
Output 229: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 229         |
|    time_elapsed         | 876         |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.021752259 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.329      |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0239     |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0263     |
|    value_loss           | 0.00386     |
-----------------------------------------
Output 230: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 230         |
|    time_elapsed         | 881         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.011371849 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.324      |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0429     |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0243     |
|    value_loss           | 0.00017     |
-----------------------------------------
Output 231: Average over 100 episodes - Reward: 0.99
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 231         |
|    time_elapsed         | 885         |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.027837154 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.264      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0284     |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.000107    |
-----------------------------------------
Output 232: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 232        |
|    time_elapsed         | 889        |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.01623333 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.222     |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0317    |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0202    |
|    value_loss           | 0.00325    |
----------------------------------------
Output 233: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 534        |
|    iterations           | 233        |
|    time_elapsed         | 892        |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.01855064 |
|    clip_fraction        | 0.075      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.187     |
|    explained_variance   | 0.382      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0541    |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0146    |
|    value_loss           | 0.0029     |
----------------------------------------
Output 234: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 234         |
|    time_elapsed         | 896         |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.008807367 |
|    clip_fraction        | 0.0454      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.169      |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0167     |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.00883    |
|    value_loss           | 2.5e-05     |
-----------------------------------------
Output 235: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 235         |
|    time_elapsed         | 899         |
|    total_timesteps      | 481280      |
| train/                  |             |
|    approx_kl            | 0.039568953 |
|    clip_fraction        | 0.0583      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.165      |
|    explained_variance   | 0.989       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0176     |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 1.6e-05     |
-----------------------------------------
Output 236: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 236          |
|    time_elapsed         | 903          |
|    total_timesteps      | 483328       |
| train/                  |              |
|    approx_kl            | 0.0034239753 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000602    |
|    n_updates            | 2350         |
|    policy_gradient_loss | -0.00511     |
|    value_loss           | 2.78e-06     |
------------------------------------------
Output 237: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 237         |
|    time_elapsed         | 907         |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.007769142 |
|    clip_fraction        | 0.0581      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.138      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00595     |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00493    |
|    value_loss           | 1.41e-06    |
-----------------------------------------
Output 238: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 534         |
|    iterations           | 238         |
|    time_elapsed         | 911         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.001800803 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0172     |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00371    |
|    value_loss           | 3.47e-06    |
-----------------------------------------
Output 239: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 239         |
|    time_elapsed         | 914         |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.010986578 |
|    clip_fraction        | 0.068       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00123    |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.00107    |
|    value_loss           | 7.36e-07    |
-----------------------------------------
Output 240: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 534          |
|    iterations           | 240          |
|    time_elapsed         | 918          |
|    total_timesteps      | 491520       |
| train/                  |              |
|    approx_kl            | 0.0047849934 |
|    clip_fraction        | 0.0462       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.169       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00307     |
|    n_updates            | 2390         |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 3.57e-07     |
------------------------------------------
Output 241: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 241         |
|    time_elapsed         | 922         |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.006692307 |
|    clip_fraction        | 0.0988      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.162      |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0123     |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 3.62e-05    |
-----------------------------------------
Output 242: Average over 100 episodes - Reward: 1.0
------------------------------------------
| time/                   |              |
|    fps                  | 535          |
|    iterations           | 242          |
|    time_elapsed         | 926          |
|    total_timesteps      | 495616       |
| train/                  |              |
|    approx_kl            | 0.0134951165 |
|    clip_fraction        | 0.0823       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.142       |
|    explained_variance   | 0.992        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.021       |
|    n_updates            | 2410         |
|    policy_gradient_loss | -0.0125      |
|    value_loss           | 7.53e-06     |
------------------------------------------
Output 243: Average over 100 episodes - Reward: 1.0
-----------------------------------------
| time/                   |             |
|    fps                  | 535         |
|    iterations           | 243         |
|    time_elapsed         | 929         |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.007411478 |
|    clip_fraction        | 0.0686      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0107     |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.00114    |
|    value_loss           | 1.19e-06    |
-----------------------------------------
Output 244: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 244        |
|    time_elapsed         | 933        |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.02498835 |
|    clip_fraction        | 0.0579     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 1          |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00539   |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.00473   |
|    value_loss           | 4.07e-09   |
----------------------------------------
Output 245: Average over 100 episodes - Reward: 1.0
----------------------------------------
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 245        |
|    time_elapsed         | 937        |
|    total_timesteps      | 501760     |
| train/                  |            |
|    approx_kl            | 0.04565585 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.206     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0318    |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.000147   |
----------------------------------------
Overall: Average Reward: 0.7437646340221928
```

# 8x8 frozen lake map PPO - is_slippery off
```
Using cpu device
Logging to ./PPOtensorboard/PPO_4
Output 1: Average over 68 episodes - Reward: 0.0
-----------------------------
| time/              |      |
|    fps             | 1022 |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
Output 2: Average over 66 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 745         |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.008898015 |
|    clip_fraction        | 0.0262      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -8.33       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0442     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0088     |
|    value_loss           | 0.00526     |
-----------------------------------------
Output 3: Average over 74 episodes - Reward: 0.0
----------------------------------------
| time/                   |            |
|    fps                  | 652        |
|    iterations           | 3          |
|    time_elapsed         | 9          |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.01007098 |
|    clip_fraction        | 0.0718     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.37      |
|    explained_variance   | -1.26      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0438    |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.014     |
|    value_loss           | 0.000433   |
----------------------------------------
Output 4: Average over 86 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 636         |
|    iterations           | 4           |
|    time_elapsed         | 12          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.010500294 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | -1.88       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0327     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.000111    |
-----------------------------------------
Output 5: Average over 84 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 615         |
|    iterations           | 5           |
|    time_elapsed         | 16          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.013072573 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -6.91       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0484     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0195     |
|    value_loss           | 4.47e-05    |
-----------------------------------------
Output 6: Average over 96 episodes - Reward: 0.010416666666666666
-----------------------------------------
| time/                   |             |
|    fps                  | 607         |
|    iterations           | 6           |
|    time_elapsed         | 20          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.020190157 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -1.4        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.026      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0228     |
|    value_loss           | 1.67e-06    |
-----------------------------------------
Output 7: Average over 100 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 604          |
|    iterations           | 7            |
|    time_elapsed         | 23           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0067512495 |
|    clip_fraction        | 0.0523       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.19        |
|    explained_variance   | -0.0313      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00734     |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.011       |
|    value_loss           | 0.00272      |
------------------------------------------
Output 8: Average over 100 episodes - Reward: 0.02
----------------------------------------
| time/                   |            |
|    fps                  | 600        |
|    iterations           | 8          |
|    time_elapsed         | 27         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00571044 |
|    clip_fraction        | 0.0241     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -1.87      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0301    |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.0117    |
|    value_loss           | 0.000288   |
----------------------------------------
Output 9: Average over 100 episodes - Reward: 0.01
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 9            |
|    time_elapsed         | 31           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0051703984 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.14        |
|    explained_variance   | 0.181        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0159       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00993     |
|    value_loss           | 0.0062       |
------------------------------------------
Output 10: Average over 98 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 580         |
|    iterations           | 10          |
|    time_elapsed         | 35          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.011358933 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.00379     |
-----------------------------------------
Output 11: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 569         |
|    iterations           | 11          |
|    time_elapsed         | 39          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.014981709 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -6.39       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0462     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.000556    |
-----------------------------------------
Output 12: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 564         |
|    iterations           | 12          |
|    time_elapsed         | 43          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.005882006 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00224    |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 0.00569     |
-----------------------------------------
Output 13: Average over 100 episodes - Reward: 0.0
-----------------------------------------
| time/                   |             |
|    fps                  | 563         |
|    iterations           | 13          |
|    time_elapsed         | 47          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.006418375 |
|    clip_fraction        | 0.0551      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -3.26       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0331     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.000442    |
-----------------------------------------
Output 14: Average over 100 episodes - Reward: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 563         |
|    iterations           | 14          |
|    time_elapsed         | 50          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.016858118 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.955      |
|    explained_variance   | -0.528      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0203     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0195     |
|    value_loss           | 6.31e-05    |
-----------------------------------------
Output 15: Average over 100 episodes - Reward: 0.01
-----------------------------------------
| time/                   |             |
|    fps                  | 565         |
|    iterations           | 15          |
|    time_elapsed         | 54          |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.009897208 |
|    clip_fraction        | 0.0854      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.902      |
|    explained_variance   | 0.0102      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00614    |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 0.00791     |
-----------------------------------------
Output 16: Average over 88 episodes - Reward: 0.0
------------------------------------------
| time/                   |              |
|    fps                  | 563          |
|    iterations           | 16           |
|    time_elapsed         | 58           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0066365954 |
|    clip_fraction        | 0.0582       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | 0.122        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00127      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0117      |
|    value_loss           | 0.00758      |
------------------------------------------
Output 17: Average over 93 episodes - Reward: 0.021505376344086023
-----------------------------------------
| time/                   |             |
|    fps                  | 563         |
|    iterations           | 17          |
|    time_elapsed         | 61          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.008268384 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.787      |
|    explained_variance   | -3.14       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0218     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.000279    |
-----------------------------------------
Output 18: Average over 89 episodes - Reward: 0.011235955056179775
------------------------------------------
| time/                   |              |
|    fps                  | 561          |
|    iterations           | 18           |
|    time_elapsed         | 65           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0066724997 |
|    clip_fraction        | 0.0586       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.723       |
|    explained_variance   | 0.0564       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0296       |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00659     |
|    value_loss           | 0.00763      |
------------------------------------------
Output 19: Average over 86 episodes - Reward: 0.046511627906976744
-----------------------------------------
| time/                   |             |
|    fps                  | 561         |
|    iterations           | 19          |
|    time_elapsed         | 69          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.006780224 |
|    clip_fraction        | 0.0664      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.666      |
|    explained_variance   | 0.0631      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0126     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00739    |
|    value_loss           | 0.0043      |
-----------------------------------------
Output 20: Average over 60 episodes - Reward: 0.1
------------------------------------------
| time/                   |              |
|    fps                  | 560          |
|    iterations           | 20           |
|    time_elapsed         | 73           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0041488344 |
|    clip_fraction        | 0.0407       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.643       |
|    explained_variance   | 0.11         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00686      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00735     |
|    value_loss           | 0.0134       |
------------------------------------------
Output 21: Average over 82 episodes - Reward: 0.07317073170731707
------------------------------------------
| time/                   |              |
|    fps                  | 561          |
|    iterations           | 21           |
|    time_elapsed         | 76           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0056623872 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.639       |
|    explained_variance   | 0.196        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0321       |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00597     |
|    value_loss           | 0.0198       |
------------------------------------------
Output 22: Average over 88 episodes - Reward: 0.03409090909090909
------------------------------------------
| time/                   |              |
|    fps                  | 560          |
|    iterations           | 22           |
|    time_elapsed         | 80           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0058072843 |
|    clip_fraction        | 0.0646       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.586       |
|    explained_variance   | 0.327        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0151      |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00906     |
|    value_loss           | 0.0178       |
------------------------------------------
Output 23: Average over 64 episodes - Reward: 0.015625
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 23           |
|    time_elapsed         | 85           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0065208976 |
|    clip_fraction        | 0.07         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.563       |
|    explained_variance   | 0.0571       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00681     |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.0089      |
|    value_loss           | 0.0138       |
------------------------------------------
Output 24: Average over 77 episodes - Reward: 0.05194805194805195
----------------------------------------
| time/                   |            |
|    fps                  | 546        |
|    iterations           | 24         |
|    time_elapsed         | 89         |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.00817571 |
|    clip_fraction        | 0.0717     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.00387    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0309    |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.00947   |
|    value_loss           | 0.00519    |
----------------------------------------
Output 25: Average over 69 episodes - Reward: 0.07246376811594203
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 25          |
|    time_elapsed         | 93          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.004805957 |
|    clip_fraction        | 0.0503      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.487      |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0106     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00727    |
|    value_loss           | 0.0127      |
-----------------------------------------
Output 26: Average over 69 episodes - Reward: 0.07246376811594203
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 26           |
|    time_elapsed         | 97           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0055887895 |
|    clip_fraction        | 0.0463       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.493       |
|    explained_variance   | 0.207        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00687      |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00763     |
|    value_loss           | 0.0159       |
------------------------------------------
Output 27: Average over 82 episodes - Reward: 0.012195121951219513
-----------------------------------------
| time/                   |             |
|    fps                  | 545         |
|    iterations           | 27          |
|    time_elapsed         | 101         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.005248784 |
|    clip_fraction        | 0.0606      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.488      |
|    explained_variance   | 0.107       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00142     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.0175      |
-----------------------------------------
Output 28: Average over 85 episodes - Reward: 0.023529411764705882
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 28          |
|    time_elapsed         | 105         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.002892485 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.47       |
|    explained_variance   | 0.00572     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0206     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00691    |
|    value_loss           | 0.00513     |
-----------------------------------------
Output 29: Average over 63 episodes - Reward: 0.07936507936507936
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 29          |
|    time_elapsed         | 109         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.004149422 |
|    clip_fraction        | 0.0481      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.447      |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.02        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00801    |
|    value_loss           | 0.00625     |
-----------------------------------------
Output 30: Average over 66 episodes - Reward: 0.07575757575757576
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 30          |
|    time_elapsed         | 113         |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.004954491 |
|    clip_fraction        | 0.0317      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.446      |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00364    |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00475    |
|    value_loss           | 0.0161      |
-----------------------------------------
Output 31: Average over 69 episodes - Reward: 0.043478260869565216
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 31           |
|    time_elapsed         | 117          |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0034413687 |
|    clip_fraction        | 0.0324       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.422       |
|    explained_variance   | 0.151        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000293     |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0054      |
|    value_loss           | 0.0178       |
------------------------------------------
Output 32: Average over 80 episodes - Reward: 0.05
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 32           |
|    time_elapsed         | 120          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0049412446 |
|    clip_fraction        | 0.0385       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.372       |
|    explained_variance   | 0.131        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00282      |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00651     |
|    value_loss           | 0.0104       |
------------------------------------------
Output 33: Average over 59 episodes - Reward: 0.0847457627118644
-----------------------------------------
| time/                   |             |
|    fps                  | 542         |
|    iterations           | 33          |
|    time_elapsed         | 124         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.007080162 |
|    clip_fraction        | 0.0665      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.319      |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000734   |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00641    |
|    value_loss           | 0.0132      |
-----------------------------------------
Output 34: Average over 68 episodes - Reward: 0.16176470588235295
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 34          |
|    time_elapsed         | 128         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.003843524 |
|    clip_fraction        | 0.049       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.311      |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.018       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00339    |
|    value_loss           | 0.017       |
-----------------------------------------
Output 35: Average over 81 episodes - Reward: 0.024691358024691357
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 35           |
|    time_elapsed         | 131          |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 0.0038814684 |
|    clip_fraction        | 0.0556       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.298       |
|    explained_variance   | 0.254        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00167     |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00566     |
|    value_loss           | 0.0299       |
------------------------------------------
Output 36: Average over 52 episodes - Reward: 0.057692307692307696
------------------------------------------
| time/                   |              |
|    fps                  | 544          |
|    iterations           | 36           |
|    time_elapsed         | 135          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0030271302 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.276       |
|    explained_variance   | -0.199       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0252      |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00738     |
|    value_loss           | 0.0103       |
------------------------------------------
Output 37: Average over 65 episodes - Reward: 0.1076923076923077
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 37           |
|    time_elapsed         | 138          |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0028881398 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.259       |
|    explained_variance   | 0.121        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00278     |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00374     |
|    value_loss           | 0.0109       |
------------------------------------------
Output 38: Average over 63 episodes - Reward: 0.06349206349206349
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 38           |
|    time_elapsed         | 142          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0024312136 |
|    clip_fraction        | 0.0209       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.247       |
|    explained_variance   | 0.193        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0112       |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00368     |
|    value_loss           | 0.0208       |
------------------------------------------
Output 39: Average over 60 episodes - Reward: 0.18333333333333332
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 39          |
|    time_elapsed         | 146         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.005036618 |
|    clip_fraction        | 0.0492      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.248      |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00582    |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0044     |
|    value_loss           | 0.0138      |
-----------------------------------------
Output 40: Average over 71 episodes - Reward: 0.028169014084507043
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 40           |
|    time_elapsed         | 149          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0022008894 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.245       |
|    explained_variance   | 0.278        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0133       |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00182     |
|    value_loss           | 0.0277       |
------------------------------------------
Output 41: Average over 63 episodes - Reward: 0.07936507936507936
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 41           |
|    time_elapsed         | 153          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0033623744 |
|    clip_fraction        | 0.0363       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.246       |
|    explained_variance   | 0.073        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0096       |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00473     |
|    value_loss           | 0.00963      |
------------------------------------------
Output 42: Average over 67 episodes - Reward: 0.08955223880597014
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 42           |
|    time_elapsed         | 157          |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0030035775 |
|    clip_fraction        | 0.0407       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.227       |
|    explained_variance   | 0.194        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0075       |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00346     |
|    value_loss           | 0.0166       |
------------------------------------------
Output 43: Average over 59 episodes - Reward: 0.1016949152542373
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 43           |
|    time_elapsed         | 161          |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0023191408 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.216       |
|    explained_variance   | 0.197        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0112       |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00248     |
|    value_loss           | 0.0199       |
------------------------------------------
Output 44: Average over 60 episodes - Reward: 0.2
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 44          |
|    time_elapsed         | 164         |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.008484285 |
|    clip_fraction        | 0.0548      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00216    |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00327    |
|    value_loss           | 0.0186      |
-----------------------------------------
Output 45: Average over 48 episodes - Reward: 0.125
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 45           |
|    time_elapsed         | 168          |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0020309486 |
|    clip_fraction        | 0.0264       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.17        |
|    explained_variance   | 0.191        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00729      |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00302     |
|    value_loss           | 0.0331       |
------------------------------------------
Output 46: Average over 75 episodes - Reward: 0.14666666666666667
----------------------------------------
| time/                   |            |
|    fps                  | 546        |
|    iterations           | 46         |
|    time_elapsed         | 172        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.00580104 |
|    clip_fraction        | 0.0272     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.191     |
|    explained_variance   | 0.0496     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0204    |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.00561   |
|    value_loss           | 0.0205     |
----------------------------------------
Output 47: Average over 70 episodes - Reward: 0.14285714285714285
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 47           |
|    time_elapsed         | 176          |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0030604284 |
|    clip_fraction        | 0.0278       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.195       |
|    explained_variance   | 0.245        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0238       |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 0.0297       |
------------------------------------------
Output 48: Average over 76 episodes - Reward: 0.06578947368421052
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 48           |
|    time_elapsed         | 180          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0035268534 |
|    clip_fraction        | 0.0406       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.19        |
|    explained_variance   | 0.242        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0175       |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00694     |
|    value_loss           | 0.0276       |
------------------------------------------
Output 49: Average over 60 episodes - Reward: 0.08333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 49           |
|    time_elapsed         | 183          |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 0.0008912211 |
|    clip_fraction        | 0.00908      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.183       |
|    explained_variance   | 0.25         |
|    learning_rate        | 0.0003       |
|    loss                 | 3.18e-05     |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00168     |
|    value_loss           | 0.0181       |
------------------------------------------
Output 50: Average over 61 episodes - Reward: 0.16393442622950818
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 50           |
|    time_elapsed         | 186          |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0019989272 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.157       |
|    explained_variance   | 0.205        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0104       |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00239     |
|    value_loss           | 0.0176       |
------------------------------------------
Output 51: Average over 80 episodes - Reward: 0.1
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 51           |
|    time_elapsed         | 190          |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0015536316 |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.154       |
|    explained_variance   | 0.198        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.019        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.0033      |
|    value_loss           | 0.0273       |
------------------------------------------
Output 52: Average over 60 episodes - Reward: 0.15
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 52          |
|    time_elapsed         | 193         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.001238175 |
|    clip_fraction        | 0.0141      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.163      |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00956     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00168    |
|    value_loss           | 0.0244      |
-----------------------------------------
Output 53: Average over 60 episodes - Reward: 0.05
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 53           |
|    time_elapsed         | 197          |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 0.0016387783 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0.278        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0176       |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00111     |
|    value_loss           | 0.0253       |
------------------------------------------
Output 54: Average over 54 episodes - Reward: 0.18518518518518517
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 54           |
|    time_elapsed         | 200          |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 0.0031194673 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.151       |
|    explained_variance   | 0.211        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00262      |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.00411     |
|    value_loss           | 0.0127       |
------------------------------------------
Output 55: Average over 69 episodes - Reward: 0.13043478260869565
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 55           |
|    time_elapsed         | 204          |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0011706457 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | 0.265        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00288     |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00221     |
|    value_loss           | 0.0233       |
------------------------------------------
Output 56: Average over 79 episodes - Reward: 0.0759493670886076
-----------------------------------------
| time/                   |             |
|    fps                  | 551         |
|    iterations           | 56          |
|    time_elapsed         | 207         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.002492757 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0026     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00464    |
|    value_loss           | 0.0273      |
-----------------------------------------
Output 57: Average over 67 episodes - Reward: 0.08955223880597014
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 57           |
|    time_elapsed         | 211          |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0021176485 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.428        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00381     |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00434     |
|    value_loss           | 0.0177       |
------------------------------------------
Output 58: Average over 55 episodes - Reward: 0.23636363636363636
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 58           |
|    time_elapsed         | 215          |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0013064235 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0957      |
|    explained_variance   | 0.409        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000309    |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00117     |
|    value_loss           | 0.0154       |
------------------------------------------
Output 59: Average over 71 episodes - Reward: 0.14084507042253522
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 59           |
|    time_elapsed         | 218          |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 0.0010763863 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0957      |
|    explained_variance   | 0.397        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0145       |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00239     |
|    value_loss           | 0.0301       |
------------------------------------------
Output 60: Average over 61 episodes - Reward: 0.2459016393442623
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 60          |
|    time_elapsed         | 221         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.003223936 |
|    clip_fraction        | 0.0174      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0966     |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0149      |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00407    |
|    value_loss           | 0.0236      |
-----------------------------------------
Output 61: Average over 67 episodes - Reward: 0.14925373134328357
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 61           |
|    time_elapsed         | 225          |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0016921919 |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.488        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00262      |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00233     |
|    value_loss           | 0.0274       |
------------------------------------------
Output 62: Average over 61 episodes - Reward: 0.18032786885245902
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 62          |
|    time_elapsed         | 228         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.004435104 |
|    clip_fraction        | 0.0279      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0898     |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00492    |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00507    |
|    value_loss           | 0.022       |
-----------------------------------------
Output 63: Average over 53 episodes - Reward: 0.3584905660377358
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 63           |
|    time_elapsed         | 232          |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0054028886 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0883      |
|    explained_variance   | 0.506        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0165       |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.00397     |
|    value_loss           | 0.022        |
------------------------------------------
Output 64: Average over 57 episodes - Reward: 0.12280701754385964
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 64          |
|    time_elapsed         | 236         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.014286152 |
|    clip_fraction        | 0.0398      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00168    |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0048     |
|    value_loss           | 0.0215      |
-----------------------------------------
Output 65: Average over 63 episodes - Reward: 0.23809523809523808
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 65          |
|    time_elapsed         | 239         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.002128406 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.133      |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00647     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0018     |
|    value_loss           | 0.0188      |
-----------------------------------------
Output 66: Average over 66 episodes - Reward: 0.2727272727272727
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 66          |
|    time_elapsed         | 243         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.003290498 |
|    clip_fraction        | 0.0395      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.155      |
|    explained_variance   | 0.644       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000896    |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00425    |
|    value_loss           | 0.0182      |
-----------------------------------------
Output 67: Average over 58 episodes - Reward: 0.29310344827586204
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 67           |
|    time_elapsed         | 247          |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0025280996 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.125       |
|    explained_variance   | 0.556        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0212       |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00313     |
|    value_loss           | 0.0255       |
------------------------------------------
Output 68: Average over 56 episodes - Reward: 0.30357142857142855
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 68          |
|    time_elapsed         | 251         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.001942806 |
|    clip_fraction        | 0.0186      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.63        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0104     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0025     |
|    value_loss           | 0.0221      |
-----------------------------------------
Output 69: Average over 62 episodes - Reward: 0.24193548387096775
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 69           |
|    time_elapsed         | 256          |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 0.0020002418 |
|    clip_fraction        | 0.0286       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.653        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00559      |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00289     |
|    value_loss           | 0.0191       |
------------------------------------------
Output 70: Average over 62 episodes - Reward: 0.20967741935483872
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 70           |
|    time_elapsed         | 260          |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0018734356 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0.741        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00521      |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00182     |
|    value_loss           | 0.0168       |
------------------------------------------
Output 71: Average over 58 episodes - Reward: 0.20689655172413793
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 71           |
|    time_elapsed         | 264          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0018180183 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.661        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00174      |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00165     |
|    value_loss           | 0.0213       |
------------------------------------------
Output 72: Average over 49 episodes - Reward: 0.14285714285714285
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 72          |
|    time_elapsed         | 267         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.002845965 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.142      |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0186      |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00136    |
|    value_loss           | 0.0202      |
-----------------------------------------
Output 73: Average over 59 episodes - Reward: 0.3220338983050847
-----------------------------------------
| time/                   |             |
|    fps                  | 551         |
|    iterations           | 73          |
|    time_elapsed         | 271         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.004315342 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00622    |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00332    |
|    value_loss           | 0.0161      |
-----------------------------------------
Output 74: Average over 59 episodes - Reward: 0.288135593220339
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 74           |
|    time_elapsed         | 274          |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 0.0019752593 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.139       |
|    explained_variance   | 0.62         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0036       |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00201     |
|    value_loss           | 0.021        |
------------------------------------------
Output 75: Average over 45 episodes - Reward: 0.26666666666666666
-----------------------------------------
| time/                   |             |
|    fps                  | 551         |
|    iterations           | 75          |
|    time_elapsed         | 278         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.002249803 |
|    clip_fraction        | 0.0175      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.133      |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0125      |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00199    |
|    value_loss           | 0.019       |
-----------------------------------------
Output 76: Average over 55 episodes - Reward: 0.2
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 76           |
|    time_elapsed         | 281          |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0011695339 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.567        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00709      |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.0018      |
|    value_loss           | 0.0191       |
------------------------------------------
Output 77: Average over 58 episodes - Reward: 0.1896551724137931
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 77           |
|    time_elapsed         | 285          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0043832986 |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0.66         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00397      |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.0019      |
|    value_loss           | 0.0178       |
------------------------------------------
Output 78: Average over 58 episodes - Reward: 0.29310344827586204
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 78           |
|    time_elapsed         | 289          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0019128697 |
|    clip_fraction        | 0.0199       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0.655        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00295      |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.0019      |
|    value_loss           | 0.0185       |
------------------------------------------
Output 79: Average over 52 episodes - Reward: 0.36538461538461536
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 79           |
|    time_elapsed         | 292          |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 0.0011655592 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.113       |
|    explained_variance   | 0.657        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0108       |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 0.0193       |
------------------------------------------
Output 80: Average over 56 episodes - Reward: 0.25
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 80           |
|    time_elapsed         | 296          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0022890908 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.111       |
|    explained_variance   | 0.652        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00756      |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.002       |
|    value_loss           | 0.0207       |
------------------------------------------
Output 81: Average over 53 episodes - Reward: 0.3584905660377358
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 81           |
|    time_elapsed         | 300          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0017410492 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.631        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00988     |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 0.0205       |
------------------------------------------
Output 82: Average over 45 episodes - Reward: 0.3333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 82           |
|    time_elapsed         | 304          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0016870095 |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.635        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.013        |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.0018      |
|    value_loss           | 0.0201       |
------------------------------------------
Output 83: Average over 54 episodes - Reward: 0.35185185185185186
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 83           |
|    time_elapsed         | 307          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0027516915 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0956      |
|    explained_variance   | 0.548        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0262       |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00425     |
|    value_loss           | 0.0189       |
------------------------------------------
Output 84: Average over 53 episodes - Reward: 0.3018867924528302
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 84           |
|    time_elapsed         | 310          |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 0.0023104139 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0.59         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00459     |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00264     |
|    value_loss           | 0.0232       |
------------------------------------------
Output 85: Average over 60 episodes - Reward: 0.21666666666666667
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 85           |
|    time_elapsed         | 314          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0024687015 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.681        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00859      |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00272     |
|    value_loss           | 0.018        |
------------------------------------------
Output 86: Average over 60 episodes - Reward: 0.2
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 86          |
|    time_elapsed         | 318         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.002843871 |
|    clip_fraction        | 0.0278      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.582       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00791     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00491    |
|    value_loss           | 0.0233      |
-----------------------------------------
Output 87: Average over 55 episodes - Reward: 0.32727272727272727
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 87          |
|    time_elapsed         | 322         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.001858244 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00203    |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00267    |
|    value_loss           | 0.0197      |
-----------------------------------------
Output 88: Average over 47 episodes - Reward: 0.3617021276595745
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 88           |
|    time_elapsed         | 327          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0018862087 |
|    clip_fraction        | 0.0246       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0978      |
|    explained_variance   | 0.573        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0151       |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00269     |
|    value_loss           | 0.0238       |
------------------------------------------
Output 89: Average over 68 episodes - Reward: 0.22058823529411764
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 89           |
|    time_elapsed         | 333          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0015236303 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0826      |
|    explained_variance   | 0.603        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00183      |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00195     |
|    value_loss           | 0.0191       |
------------------------------------------
Output 90: Average over 59 episodes - Reward: 0.1864406779661017
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 90           |
|    time_elapsed         | 337          |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 0.0026391528 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.668        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0116       |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 0.0207       |
------------------------------------------
Output 91: Average over 61 episodes - Reward: 0.2786885245901639
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 91          |
|    time_elapsed         | 342         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.004267507 |
|    clip_fraction        | 0.023       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.104      |
|    explained_variance   | 0.68        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00365     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00374    |
|    value_loss           | 0.0191      |
-----------------------------------------
Output 92: Average over 51 episodes - Reward: 0.2549019607843137
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 92           |
|    time_elapsed         | 348          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0027175848 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.64         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00586      |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00412     |
|    value_loss           | 0.0229       |
------------------------------------------
Output 93: Average over 56 episodes - Reward: 0.23214285714285715
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 93           |
|    time_elapsed         | 352          |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 0.0014199016 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.665        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0102       |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.000644    |
|    value_loss           | 0.018        |
------------------------------------------
Output 94: Average over 57 episodes - Reward: 0.15789473684210525
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 94           |
|    time_elapsed         | 356          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0021206269 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.702        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.026        |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.00149     |
|    value_loss           | 0.0185       |
------------------------------------------
Output 95: Average over 74 episodes - Reward: 0.16216216216216217
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 95           |
|    time_elapsed         | 359          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0017088895 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.105       |
|    explained_variance   | 0.705        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00451      |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.00268     |
|    value_loss           | 0.0173       |
------------------------------------------
Output 96: Average over 49 episodes - Reward: 0.2857142857142857
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 96           |
|    time_elapsed         | 363          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0025343578 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.689        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0105       |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.00112     |
|    value_loss           | 0.0194       |
------------------------------------------
Output 97: Average over 43 episodes - Reward: 0.32558139534883723
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 97           |
|    time_elapsed         | 367          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0008351053 |
|    clip_fraction        | 0.00483      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0902      |
|    explained_variance   | 0.661        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00928      |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.000864    |
|    value_loss           | 0.0171       |
------------------------------------------
Output 98: Average over 57 episodes - Reward: 0.2807017543859649
-------------------------------------------
| time/                   |               |
|    fps                  | 541           |
|    iterations           | 98            |
|    time_elapsed         | 370           |
|    total_timesteps      | 200704        |
| train/                  |               |
|    approx_kl            | 0.00085784413 |
|    clip_fraction        | 0.01          |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0706       |
|    explained_variance   | 0.565         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00974       |
|    n_updates            | 970           |
|    policy_gradient_loss | -0.00127      |
|    value_loss           | 0.017         |
-------------------------------------------
Output 99: Average over 56 episodes - Reward: 0.32142857142857145
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 99           |
|    time_elapsed         | 374          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0015142257 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0988      |
|    explained_variance   | 0.622        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0065      |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00364     |
|    value_loss           | 0.0202       |
------------------------------------------
Output 100: Average over 43 episodes - Reward: 0.4186046511627907
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 100         |
|    time_elapsed         | 378         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.004625505 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00712     |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00301    |
|    value_loss           | 0.0191      |
-----------------------------------------
Output 101: Average over 64 episodes - Reward: 0.25
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 101          |
|    time_elapsed         | 382          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0014451555 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0739      |
|    explained_variance   | 0.58         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000815    |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 0.0192       |
------------------------------------------
Output 102: Average over 50 episodes - Reward: 0.34
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 102          |
|    time_elapsed         | 386          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0020350073 |
|    clip_fraction        | 0.0334       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.655        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00975      |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.00302     |
|    value_loss           | 0.0224       |
------------------------------------------
Output 103: Average over 70 episodes - Reward: 0.32857142857142857
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 103          |
|    time_elapsed         | 389          |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 0.0018742643 |
|    clip_fraction        | 0.0224       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0864      |
|    explained_variance   | 0.619        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0153       |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00276     |
|    value_loss           | 0.0181       |
------------------------------------------
Output 104: Average over 49 episodes - Reward: 0.2653061224489796
----------------------------------------
| time/                   |            |
|    fps                  | 541        |
|    iterations           | 104        |
|    time_elapsed         | 393        |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.00232518 |
|    clip_fraction        | 0.0124     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.124     |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0167     |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.00241   |
|    value_loss           | 0.0257     |
----------------------------------------
Output 105: Average over 43 episodes - Reward: 0.2558139534883721
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 105          |
|    time_elapsed         | 397          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 0.0017191644 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.657        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00332      |
|    n_updates            | 1040         |
|    policy_gradient_loss | -0.00366     |
|    value_loss           | 0.0182       |
------------------------------------------
Output 106: Average over 51 episodes - Reward: 0.27450980392156865
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 106          |
|    time_elapsed         | 400          |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 0.0023526035 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.616        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00125     |
|    n_updates            | 1050         |
|    policy_gradient_loss | -0.00401     |
|    value_loss           | 0.0147       |
------------------------------------------
Output 107: Average over 49 episodes - Reward: 0.1836734693877551
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 107          |
|    time_elapsed         | 405          |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 0.0029355483 |
|    clip_fraction        | 0.0296       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.622        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00408     |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00519     |
|    value_loss           | 0.0195       |
------------------------------------------
Output 108: Average over 55 episodes - Reward: 0.3090909090909091
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 108          |
|    time_elapsed         | 409          |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0015810061 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.115       |
|    explained_variance   | 0.68         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00269     |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.0034      |
|    value_loss           | 0.0156       |
------------------------------------------
Output 109: Average over 50 episodes - Reward: 0.34
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 109         |
|    time_elapsed         | 413         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.003690204 |
|    clip_fraction        | 0.0325      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00897     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00418    |
|    value_loss           | 0.0207      |
-----------------------------------------
Output 110: Average over 45 episodes - Reward: 0.26666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 538          |
|    iterations           | 110          |
|    time_elapsed         | 418          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0040276446 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.678        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00286      |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00575     |
|    value_loss           | 0.0186       |
------------------------------------------
Output 111: Average over 44 episodes - Reward: 0.29545454545454547
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 111          |
|    time_elapsed         | 421          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0023415494 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0.573        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00703      |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00225     |
|    value_loss           | 0.0196       |
------------------------------------------
Output 112: Average over 48 episodes - Reward: 0.2708333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 112          |
|    time_elapsed         | 425          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0029417502 |
|    clip_fraction        | 0.0293       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.106       |
|    explained_variance   | 0.608        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00312      |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.0052      |
|    value_loss           | 0.0177       |
------------------------------------------
Output 113: Average over 47 episodes - Reward: 0.19148936170212766
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 113          |
|    time_elapsed         | 429          |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 0.0015825466 |
|    clip_fraction        | 0.0168       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.103       |
|    explained_variance   | 0.612        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0115       |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00218     |
|    value_loss           | 0.0176       |
------------------------------------------
Output 114: Average over 37 episodes - Reward: 0.32432432432432434
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 114          |
|    time_elapsed         | 432          |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 0.0026420373 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.105       |
|    explained_variance   | 0.601        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0067       |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.00483     |
|    value_loss           | 0.0172       |
------------------------------------------
Output 115: Average over 36 episodes - Reward: 0.3888888888888889
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 115          |
|    time_elapsed         | 436          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0065466296 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.591        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00337     |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00508     |
|    value_loss           | 0.0163       |
------------------------------------------
Output 116: Average over 40 episodes - Reward: 0.375
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 116         |
|    time_elapsed         | 440         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.002711289 |
|    clip_fraction        | 0.0386      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.152      |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00596    |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00348    |
|    value_loss           | 0.0169      |
-----------------------------------------
Output 117: Average over 37 episodes - Reward: 0.32432432432432434
-----------------------------------------
| time/                   |             |
|    fps                  | 539         |
|    iterations           | 117         |
|    time_elapsed         | 444         |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.008554438 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.584       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00673     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00416    |
|    value_loss           | 0.0188      |
-----------------------------------------
Output 118: Average over 47 episodes - Reward: 0.1702127659574468
------------------------------------------
| time/                   |              |
|    fps                  | 539          |
|    iterations           | 118          |
|    time_elapsed         | 447          |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 0.0031907246 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.156       |
|    explained_variance   | 0.59         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0097       |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.00188     |
|    value_loss           | 0.0172       |
------------------------------------------
Output 119: Average over 39 episodes - Reward: 0.358974358974359
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 119          |
|    time_elapsed         | 450          |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 0.0037607835 |
|    clip_fraction        | 0.0208       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.135       |
|    explained_variance   | 0.601        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00677      |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00227     |
|    value_loss           | 0.0168       |
------------------------------------------
Output 120: Average over 41 episodes - Reward: 0.4146341463414634
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 120          |
|    time_elapsed         | 454          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0016379543 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.629        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00759      |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.00205     |
|    value_loss           | 0.0178       |
------------------------------------------
Output 121: Average over 42 episodes - Reward: 0.3333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 121          |
|    time_elapsed         | 458          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0044109197 |
|    clip_fraction        | 0.0312       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.674        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0107      |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00396     |
|    value_loss           | 0.0164       |
------------------------------------------
Output 122: Average over 48 episodes - Reward: 0.2708333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 122          |
|    time_elapsed         | 461          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0018889781 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.604        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0163       |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00255     |
|    value_loss           | 0.0188       |
------------------------------------------
Output 123: Average over 44 episodes - Reward: 0.3181818181818182
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 123          |
|    time_elapsed         | 465          |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 0.0044003157 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.673        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00681      |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00557     |
|    value_loss           | 0.0164       |
------------------------------------------
Output 124: Average over 48 episodes - Reward: 0.375
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 124          |
|    time_elapsed         | 469          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0017781503 |
|    clip_fraction        | 0.0221       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.11        |
|    explained_variance   | 0.567        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00731      |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00344     |
|    value_loss           | 0.018        |
------------------------------------------
Output 125: Average over 48 episodes - Reward: 0.2916666666666667
----------------------------------------
| time/                   |            |
|    fps                  | 540        |
|    iterations           | 125        |
|    time_elapsed         | 473        |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.00411377 |
|    clip_fraction        | 0.0237     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.136     |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0133     |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.00341   |
|    value_loss           | 0.0215     |
----------------------------------------
Output 126: Average over 35 episodes - Reward: 0.3142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 126          |
|    time_elapsed         | 476          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0070301453 |
|    clip_fraction        | 0.026        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.151       |
|    explained_variance   | 0.657        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000618    |
|    n_updates            | 1250         |
|    policy_gradient_loss | -0.00367     |
|    value_loss           | 0.019        |
------------------------------------------
Output 127: Average over 37 episodes - Reward: 0.2972972972972973
-----------------------------------------
| time/                   |             |
|    fps                  | 540         |
|    iterations           | 127         |
|    time_elapsed         | 480         |
|    total_timesteps      | 260096      |
| train/                  |             |
|    approx_kl            | 0.005782257 |
|    clip_fraction        | 0.0277      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0179      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.00425    |
|    value_loss           | 0.0156      |
-----------------------------------------
Output 128: Average over 43 episodes - Reward: 0.27906976744186046
------------------------------------------
| time/                   |              |
|    fps                  | 540          |
|    iterations           | 128          |
|    time_elapsed         | 484          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0015235269 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.429        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00104      |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00239     |
|    value_loss           | 0.0211       |
------------------------------------------
Output 129: Average over 46 episodes - Reward: 0.10869565217391304
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 129          |
|    time_elapsed         | 488          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0030658597 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.144       |
|    explained_variance   | 0.503        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.016        |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 0.0219       |
------------------------------------------
Output 130: Average over 43 episodes - Reward: 0.23255813953488372
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 130         |
|    time_elapsed         | 492         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.014360162 |
|    clip_fraction        | 0.0606      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.169      |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00338    |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 0.021       |
-----------------------------------------
Output 131: Average over 41 episodes - Reward: 0.24390243902439024
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 131          |
|    time_elapsed         | 495          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0030222288 |
|    clip_fraction        | 0.0276       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.159       |
|    explained_variance   | 0.391        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0231       |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00383     |
|    value_loss           | 0.0216       |
------------------------------------------
Output 132: Average over 45 episodes - Reward: 0.35555555555555557
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 132          |
|    time_elapsed         | 499          |
|    total_timesteps      | 270336       |
| train/                  |              |
|    approx_kl            | 0.0021010707 |
|    clip_fraction        | 0.0247       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | 0.407        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00412      |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00229     |
|    value_loss           | 0.0217       |
------------------------------------------
Output 133: Average over 46 episodes - Reward: 0.2608695652173913
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 133         |
|    time_elapsed         | 503         |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.002948286 |
|    clip_fraction        | 0.0273      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.144      |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0124      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00293    |
|    value_loss           | 0.0285      |
-----------------------------------------
Output 134: Average over 40 episodes - Reward: 0.45
-----------------------------------------
| time/                   |             |
|    fps                  | 541         |
|    iterations           | 134         |
|    time_elapsed         | 506         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.002889113 |
|    clip_fraction        | 0.0304      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.165      |
|    explained_variance   | 0.506       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0158      |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00388    |
|    value_loss           | 0.0215      |
-----------------------------------------
Output 135: Average over 41 episodes - Reward: 0.3902439024390244
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 135          |
|    time_elapsed         | 510          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0025985437 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.147       |
|    explained_variance   | 0.474        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00569      |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00255     |
|    value_loss           | 0.0239       |
------------------------------------------
Output 136: Average over 47 episodes - Reward: 0.2553191489361702
------------------------------------------
| time/                   |              |
|    fps                  | 541          |
|    iterations           | 136          |
|    time_elapsed         | 513          |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0019814665 |
|    clip_fraction        | 0.0252       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0.475        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0174       |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.0028      |
|    value_loss           | 0.0228       |
------------------------------------------
Output 137: Average over 47 episodes - Reward: 0.19148936170212766
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 137          |
|    time_elapsed         | 517          |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 0.0021739244 |
|    clip_fraction        | 0.0272       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.154       |
|    explained_variance   | 0.448        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00544      |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00401     |
|    value_loss           | 0.0248       |
------------------------------------------
Output 138: Average over 41 episodes - Reward: 0.1951219512195122
------------------------------------------
| time/                   |              |
|    fps                  | 542          |
|    iterations           | 138          |
|    time_elapsed         | 520          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0058758734 |
|    clip_fraction        | 0.0399       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.174       |
|    explained_variance   | 0.562        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0127      |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.00436     |
|    value_loss           | 0.0189       |
------------------------------------------
Output 139: Average over 46 episodes - Reward: 0.2391304347826087
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 139          |
|    time_elapsed         | 524          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0031446596 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.158       |
|    explained_variance   | 0.445        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0146       |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00555     |
|    value_loss           | 0.019        |
------------------------------------------
Output 140: Average over 39 episodes - Reward: 0.38461538461538464
-----------------------------------------
| time/                   |             |
|    fps                  | 543         |
|    iterations           | 140         |
|    time_elapsed         | 527         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.003814795 |
|    clip_fraction        | 0.042       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.19       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00456    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00343    |
|    value_loss           | 0.0176      |
-----------------------------------------
Output 141: Average over 53 episodes - Reward: 0.18867924528301888
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 141          |
|    time_elapsed         | 531          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0030762176 |
|    clip_fraction        | 0.0296       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.197       |
|    explained_variance   | 0.58         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0111       |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00361     |
|    value_loss           | 0.0193       |
------------------------------------------
Output 142: Average over 32 episodes - Reward: 0.375
------------------------------------------
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 142          |
|    time_elapsed         | 534          |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 0.0045256778 |
|    clip_fraction        | 0.0454       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.196       |
|    explained_variance   | 0.545        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0101       |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00516     |
|    value_loss           | 0.0213       |
------------------------------------------
Output 143: Average over 39 episodes - Reward: 0.358974358974359
------------------------------------------
| time/                   |              |
|    fps                  | 544          |
|    iterations           | 143          |
|    time_elapsed         | 538          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0037638564 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.167       |
|    explained_variance   | 0.473        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00896     |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00521     |
|    value_loss           | 0.0172       |
------------------------------------------
Output 144: Average over 36 episodes - Reward: 0.3055555555555556
-----------------------------------------
| time/                   |             |
|    fps                  | 544         |
|    iterations           | 144         |
|    time_elapsed         | 541         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.007446411 |
|    clip_fraction        | 0.0569      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.027       |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00611    |
|    value_loss           | 0.0195      |
-----------------------------------------
Output 145: Average over 38 episodes - Reward: 0.13157894736842105
------------------------------------------
| time/                   |              |
|    fps                  | 545          |
|    iterations           | 145          |
|    time_elapsed         | 544          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0028313103 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.189       |
|    explained_variance   | 0.554        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00922      |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 0.0192       |
------------------------------------------
Output 146: Average over 33 episodes - Reward: 0.3333333333333333
----------------------------------------
| time/                   |            |
|    fps                  | 545        |
|    iterations           | 146        |
|    time_elapsed         | 547        |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.00316412 |
|    clip_fraction        | 0.0286     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.173     |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0013     |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.00445   |
|    value_loss           | 0.0153     |
----------------------------------------
Output 147: Average over 35 episodes - Reward: 0.3142857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 546          |
|    iterations           | 147          |
|    time_elapsed         | 551          |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 0.0022392978 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0.484        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00363      |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 0.0178       |
------------------------------------------
Output 148: Average over 37 episodes - Reward: 0.35135135135135137
-----------------------------------------
| time/                   |             |
|    fps                  | 546         |
|    iterations           | 148         |
|    time_elapsed         | 554         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.002543461 |
|    clip_fraction        | 0.018       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.163      |
|    explained_variance   | 0.51        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00732    |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00254    |
|    value_loss           | 0.0166      |
-----------------------------------------
Output 149: Average over 40 episodes - Reward: 0.375
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 149          |
|    time_elapsed         | 557          |
|    total_timesteps      | 305152       |
| train/                  |              |
|    approx_kl            | 0.0030795876 |
|    clip_fraction        | 0.051        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.167       |
|    explained_variance   | 0.58         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0113      |
|    n_updates            | 1480         |
|    policy_gradient_loss | -0.00486     |
|    value_loss           | 0.0162       |
------------------------------------------
Output 150: Average over 39 episodes - Reward: 0.4358974358974359
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 150          |
|    time_elapsed         | 561          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0030735405 |
|    clip_fraction        | 0.0218       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.165       |
|    explained_variance   | 0.543        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00838      |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 0.0222       |
------------------------------------------
Output 151: Average over 39 episodes - Reward: 0.358974358974359
-----------------------------------------
| time/                   |             |
|    fps                  | 547         |
|    iterations           | 151         |
|    time_elapsed         | 565         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.003935194 |
|    clip_fraction        | 0.0372      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.167      |
|    explained_variance   | 0.47        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00327     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00496    |
|    value_loss           | 0.0244      |
-----------------------------------------
Output 152: Average over 36 episodes - Reward: 0.4166666666666667
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 152          |
|    time_elapsed         | 568          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0019881278 |
|    clip_fraction        | 0.0246       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.157       |
|    explained_variance   | 0.558        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00616      |
|    n_updates            | 1510         |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 0.0193       |
------------------------------------------
Output 153: Average over 37 episodes - Reward: 0.2972972972972973
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 153          |
|    time_elapsed         | 572          |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 0.0014446053 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.166       |
|    explained_variance   | 0.524        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00966      |
|    n_updates            | 1520         |
|    policy_gradient_loss | -0.00195     |
|    value_loss           | 0.0175       |
------------------------------------------
Output 154: Average over 36 episodes - Reward: 0.4166666666666667
------------------------------------------
| time/                   |              |
|    fps                  | 547          |
|    iterations           | 154          |
|    time_elapsed         | 575          |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 0.0027228976 |
|    clip_fraction        | 0.0276       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | 0.5          |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0117       |
|    n_updates            | 1530         |
|    policy_gradient_loss | -0.00367     |
|    value_loss           | 0.0213       |
------------------------------------------
Output 155: Average over 37 episodes - Reward: 0.10810810810810811
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 155          |
|    time_elapsed         | 579          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0028720144 |
|    clip_fraction        | 0.0243       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.168       |
|    explained_variance   | 0.544        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00172      |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.0028      |
|    value_loss           | 0.0222       |
------------------------------------------
Output 156: Average over 30 episodes - Reward: 0.43333333333333335
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 156          |
|    time_elapsed         | 582          |
|    total_timesteps      | 319488       |
| train/                  |              |
|    approx_kl            | 0.0034630205 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.145       |
|    explained_variance   | 0.574        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00582      |
|    n_updates            | 1550         |
|    policy_gradient_loss | -0.00379     |
|    value_loss           | 0.0127       |
------------------------------------------
Output 157: Average over 35 episodes - Reward: 0.2571428571428571
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 157          |
|    time_elapsed         | 586          |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 0.0034150933 |
|    clip_fraction        | 0.0355       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.138       |
|    explained_variance   | 0.554        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0185       |
|    n_updates            | 1560         |
|    policy_gradient_loss | -0.00381     |
|    value_loss           | 0.0148       |
------------------------------------------
Output 158: Average over 42 episodes - Reward: 0.38095238095238093
----------------------------------------
| time/                   |            |
|    fps                  | 548        |
|    iterations           | 158        |
|    time_elapsed         | 589        |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.00271526 |
|    clip_fraction        | 0.0262     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.141     |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00431    |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.00235   |
|    value_loss           | 0.0172     |
----------------------------------------
Output 159: Average over 28 episodes - Reward: 0.4642857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 548          |
|    iterations           | 159          |
|    time_elapsed         | 593          |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 0.0028494871 |
|    clip_fraction        | 0.0309       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 0.531        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00698      |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00373     |
|    value_loss           | 0.0231       |
------------------------------------------
Output 160: Average over 29 episodes - Reward: 0.4482758620689655
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 160         |
|    time_elapsed         | 596         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.002137443 |
|    clip_fraction        | 0.0233      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00275    |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00341    |
|    value_loss           | 0.0134      |
-----------------------------------------
Output 161: Average over 34 episodes - Reward: 0.38235294117647056
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 161          |
|    time_elapsed         | 600          |
|    total_timesteps      | 329728       |
| train/                  |              |
|    approx_kl            | 0.0037181424 |
|    clip_fraction        | 0.0423       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.666        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000282     |
|    n_updates            | 1600         |
|    policy_gradient_loss | -0.00403     |
|    value_loss           | 0.0135       |
------------------------------------------
Output 162: Average over 31 episodes - Reward: 0.3548387096774194
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 162         |
|    time_elapsed         | 603         |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.004616735 |
|    clip_fraction        | 0.0511      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0108      |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00548    |
|    value_loss           | 0.0179      |
-----------------------------------------
Output 163: Average over 34 episodes - Reward: 0.3235294117647059
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 163          |
|    time_elapsed         | 607          |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 0.0028924947 |
|    clip_fraction        | 0.0316       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.146       |
|    explained_variance   | 0.602        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00652      |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00393     |
|    value_loss           | 0.0147       |
------------------------------------------
Output 164: Average over 33 episodes - Reward: 0.3939393939393939
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 164          |
|    time_elapsed         | 610          |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 0.0035168966 |
|    clip_fraction        | 0.0439       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.154       |
|    explained_variance   | 0.588        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00935      |
|    n_updates            | 1630         |
|    policy_gradient_loss | -0.00418     |
|    value_loss           | 0.0163       |
------------------------------------------
Output 165: Average over 35 episodes - Reward: 0.4857142857142857
-----------------------------------------
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 165         |
|    time_elapsed         | 614         |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.005079914 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.148      |
|    explained_variance   | 0.551       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000626    |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.00431    |
|    value_loss           | 0.0186      |
-----------------------------------------
Output 166: Average over 32 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 549          |
|    iterations           | 166          |
|    time_elapsed         | 618          |
|    total_timesteps      | 339968       |
| train/                  |              |
|    approx_kl            | 0.0029426059 |
|    clip_fraction        | 0.0414       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.159       |
|    explained_variance   | 0.602        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0162       |
|    n_updates            | 1650         |
|    policy_gradient_loss | -0.00383     |
|    value_loss           | 0.0171       |
------------------------------------------
Output 167: Average over 36 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 167          |
|    time_elapsed         | 621          |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 0.0021858113 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.14        |
|    explained_variance   | 0.533        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000341     |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00303     |
|    value_loss           | 0.0156       |
------------------------------------------
Output 168: Average over 32 episodes - Reward: 0.5625
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 168         |
|    time_elapsed         | 625         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.006691753 |
|    clip_fraction        | 0.0311      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.597       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00397    |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00445    |
|    value_loss           | 0.0165      |
-----------------------------------------
Output 169: Average over 25 episodes - Reward: 0.28
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 169          |
|    time_elapsed         | 628          |
|    total_timesteps      | 346112       |
| train/                  |              |
|    approx_kl            | 0.0021762443 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.128       |
|    explained_variance   | 0.586        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00189     |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00237     |
|    value_loss           | 0.015        |
------------------------------------------
Output 170: Average over 36 episodes - Reward: 0.25
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 170          |
|    time_elapsed         | 632          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0047812825 |
|    clip_fraction        | 0.0384       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.302        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00766      |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.00601     |
|    value_loss           | 0.0095       |
------------------------------------------
Output 171: Average over 30 episodes - Reward: 0.3333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 171          |
|    time_elapsed         | 635          |
|    total_timesteps      | 350208       |
| train/                  |              |
|    approx_kl            | 0.0038139129 |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.165       |
|    explained_variance   | 0.165        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00102     |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.00718     |
|    value_loss           | 0.0257       |
------------------------------------------
Output 172: Average over 27 episodes - Reward: 0.2962962962962963
----------------------------------------
| time/                   |            |
|    fps                  | 550        |
|    iterations           | 172        |
|    time_elapsed         | 639        |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.01034845 |
|    clip_fraction        | 0.0356     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.15      |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00566   |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.00584   |
|    value_loss           | 0.0172     |
----------------------------------------
Output 173: Average over 32 episodes - Reward: 0.59375
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 173         |
|    time_elapsed         | 643         |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.001976512 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.403       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00818    |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00205    |
|    value_loss           | 0.0118      |
-----------------------------------------
Output 174: Average over 32 episodes - Reward: 0.34375
-----------------------------------------
| time/                   |             |
|    fps                  | 550         |
|    iterations           | 174         |
|    time_elapsed         | 647         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.008953303 |
|    clip_fraction        | 0.0273      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.487       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0152      |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.00301    |
|    value_loss           | 0.0182      |
-----------------------------------------
Output 175: Average over 27 episodes - Reward: 0.5555555555555556
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 175          |
|    time_elapsed         | 650          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0034632343 |
|    clip_fraction        | 0.0445       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.147       |
|    explained_variance   | 0.424        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00353      |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.00452     |
|    value_loss           | 0.0202       |
------------------------------------------
Output 176: Average over 26 episodes - Reward: 0.5769230769230769
------------------------------------------
| time/                   |              |
|    fps                  | 550          |
|    iterations           | 176          |
|    time_elapsed         | 654          |
|    total_timesteps      | 360448       |
| train/                  |              |
|    approx_kl            | 0.0033154744 |
|    clip_fraction        | 0.026        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.141       |
|    explained_variance   | 0.487        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00184      |
|    n_updates            | 1750         |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 0.0145       |
------------------------------------------
Output 177: Average over 28 episodes - Reward: 0.35714285714285715
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 177          |
|    time_elapsed         | 657          |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 0.0020547463 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.577        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00316      |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 0.0131       |
------------------------------------------
Output 178: Average over 28 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 178          |
|    time_elapsed         | 661          |
|    total_timesteps      | 364544       |
| train/                  |              |
|    approx_kl            | 0.0023478563 |
|    clip_fraction        | 0.0293       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.111       |
|    explained_variance   | 0.532        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00749      |
|    n_updates            | 1770         |
|    policy_gradient_loss | -0.0017      |
|    value_loss           | 0.0119       |
------------------------------------------
Output 179: Average over 30 episodes - Reward: 0.43333333333333335
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 179          |
|    time_elapsed         | 665          |
|    total_timesteps      | 366592       |
| train/                  |              |
|    approx_kl            | 0.0024139308 |
|    clip_fraction        | 0.0402       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.113       |
|    explained_variance   | 0.585        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0101       |
|    n_updates            | 1780         |
|    policy_gradient_loss | -0.00336     |
|    value_loss           | 0.0133       |
------------------------------------------
Output 180: Average over 29 episodes - Reward: 0.4482758620689655
-----------------------------------------
| time/                   |             |
|    fps                  | 551         |
|    iterations           | 180         |
|    time_elapsed         | 668         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.002440428 |
|    clip_fraction        | 0.0147      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.438       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0263      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0025     |
|    value_loss           | 0.0172      |
-----------------------------------------
Output 181: Average over 28 episodes - Reward: 0.35714285714285715
------------------------------------------
| time/                   |              |
|    fps                  | 551          |
|    iterations           | 181          |
|    time_elapsed         | 671          |
|    total_timesteps      | 370688       |
| train/                  |              |
|    approx_kl            | 0.0019350206 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.115       |
|    explained_variance   | 0.49         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000949    |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.00178     |
|    value_loss           | 0.0162       |
------------------------------------------
Output 182: Average over 30 episodes - Reward: 0.43333333333333335
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 182          |
|    time_elapsed         | 675          |
|    total_timesteps      | 372736       |
| train/                  |              |
|    approx_kl            | 0.0019693202 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0955      |
|    explained_variance   | 0.383        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00517      |
|    n_updates            | 1810         |
|    policy_gradient_loss | -0.00212     |
|    value_loss           | 0.0151       |
------------------------------------------
Output 183: Average over 27 episodes - Reward: 0.4444444444444444
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 183         |
|    time_elapsed         | 678         |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.004908381 |
|    clip_fraction        | 0.0316      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0108      |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.00281    |
|    value_loss           | 0.0144      |
-----------------------------------------
Output 184: Average over 28 episodes - Reward: 0.35714285714285715
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 184          |
|    time_elapsed         | 682          |
|    total_timesteps      | 376832       |
| train/                  |              |
|    approx_kl            | 0.0014717805 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0981      |
|    explained_variance   | 0.586        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0106       |
|    n_updates            | 1830         |
|    policy_gradient_loss | -0.00163     |
|    value_loss           | 0.0123       |
------------------------------------------
Output 185: Average over 34 episodes - Reward: 0.4411764705882353
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 185          |
|    time_elapsed         | 685          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0023825238 |
|    clip_fraction        | 0.0121       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0867      |
|    explained_variance   | 0.29         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00916      |
|    n_updates            | 1840         |
|    policy_gradient_loss | -0.00211     |
|    value_loss           | 0.0153       |
------------------------------------------
Output 186: Average over 28 episodes - Reward: 0.39285714285714285
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 186         |
|    time_elapsed         | 689         |
|    total_timesteps      | 380928      |
| train/                  |             |
|    approx_kl            | 0.004055172 |
|    clip_fraction        | 0.0317      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00319     |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00213    |
|    value_loss           | 0.015       |
-----------------------------------------
Output 187: Average over 25 episodes - Reward: 0.36
-----------------------------------------
| time/                   |             |
|    fps                  | 552         |
|    iterations           | 187         |
|    time_elapsed         | 692         |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.003005984 |
|    clip_fraction        | 0.0439      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00369    |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00426    |
|    value_loss           | 0.0131      |
-----------------------------------------
Output 188: Average over 28 episodes - Reward: 0.4642857142857143
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 188          |
|    time_elapsed         | 696          |
|    total_timesteps      | 385024       |
| train/                  |              |
|    approx_kl            | 0.0014705525 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.53         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0108       |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00194     |
|    value_loss           | 0.0108       |
------------------------------------------
Output 189: Average over 26 episodes - Reward: 0.5384615384615384
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 189          |
|    time_elapsed         | 699          |
|    total_timesteps      | 387072       |
| train/                  |              |
|    approx_kl            | 0.0034879765 |
|    clip_fraction        | 0.0407       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.115       |
|    explained_variance   | 0.545        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00447      |
|    n_updates            | 1880         |
|    policy_gradient_loss | -0.00344     |
|    value_loss           | 0.0144       |
------------------------------------------
Output 190: Average over 30 episodes - Reward: 0.36666666666666664
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 190          |
|    time_elapsed         | 703          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0016098927 |
|    clip_fraction        | 0.0205       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.564        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00896      |
|    n_updates            | 1890         |
|    policy_gradient_loss | -0.000853    |
|    value_loss           | 0.0121       |
------------------------------------------
Output 191: Average over 29 episodes - Reward: 0.4827586206896552
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 191         |
|    time_elapsed         | 707         |
|    total_timesteps      | 391168      |
| train/                  |             |
|    approx_kl            | 0.011621024 |
|    clip_fraction        | 0.0433      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0119      |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00406    |
|    value_loss           | 0.0154      |
-----------------------------------------
Output 192: Average over 26 episodes - Reward: 0.38461538461538464
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 192          |
|    time_elapsed         | 711          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0033470928 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.659        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00277      |
|    n_updates            | 1910         |
|    policy_gradient_loss | -0.00225     |
|    value_loss           | 0.0124       |
------------------------------------------
Output 193: Average over 27 episodes - Reward: 0.4074074074074074
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 193          |
|    time_elapsed         | 715          |
|    total_timesteps      | 395264       |
| train/                  |              |
|    approx_kl            | 0.0022633136 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.644        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00547      |
|    n_updates            | 1920         |
|    policy_gradient_loss | -0.00169     |
|    value_loss           | 0.0105       |
------------------------------------------
Output 194: Average over 28 episodes - Reward: 0.35714285714285715
------------------------------------------
| time/                   |              |
|    fps                  | 552          |
|    iterations           | 194          |
|    time_elapsed         | 718          |
|    total_timesteps      | 397312       |
| train/                  |              |
|    approx_kl            | 0.0013024859 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.125       |
|    explained_variance   | 0.407        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00426      |
|    n_updates            | 1930         |
|    policy_gradient_loss | -0.00249     |
|    value_loss           | 0.0117       |
------------------------------------------
Output 195: Average over 27 episodes - Reward: 0.6666666666666666
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 195          |
|    time_elapsed         | 722          |
|    total_timesteps      | 399360       |
| train/                  |              |
|    approx_kl            | 0.0019911835 |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.138       |
|    explained_variance   | 0.411        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00727      |
|    n_updates            | 1940         |
|    policy_gradient_loss | -0.00264     |
|    value_loss           | 0.018        |
------------------------------------------
Output 196: Average over 25 episodes - Reward: 0.52
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 196         |
|    time_elapsed         | 725         |
|    total_timesteps      | 401408      |
| train/                  |             |
|    approx_kl            | 0.009863447 |
|    clip_fraction        | 0.036       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00346     |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0037     |
|    value_loss           | 0.0126      |
-----------------------------------------
Output 197: Average over 27 episodes - Reward: 0.4074074074074074
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 197          |
|    time_elapsed         | 728          |
|    total_timesteps      | 403456       |
| train/                  |              |
|    approx_kl            | 0.0024202117 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.139       |
|    explained_variance   | 0.548        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00917      |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 0.0123       |
------------------------------------------
Output 198: Average over 28 episodes - Reward: 0.32142857142857145
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 198         |
|    time_elapsed         | 732         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.002910091 |
|    clip_fraction        | 0.032       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0029      |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.00392    |
|    value_loss           | 0.0116      |
-----------------------------------------
Output 199: Average over 26 episodes - Reward: 0.34615384615384615
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 199          |
|    time_elapsed         | 736          |
|    total_timesteps      | 407552       |
| train/                  |              |
|    approx_kl            | 0.0026286812 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.163       |
|    explained_variance   | 0.527        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000976    |
|    n_updates            | 1980         |
|    policy_gradient_loss | -0.00302     |
|    value_loss           | 0.0117       |
------------------------------------------
Output 200: Average over 31 episodes - Reward: 0.45161290322580644
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 200          |
|    time_elapsed         | 740          |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0036033755 |
|    clip_fraction        | 0.0346       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.154       |
|    explained_variance   | 0.5          |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0118      |
|    n_updates            | 1990         |
|    policy_gradient_loss | -0.00324     |
|    value_loss           | 0.0145       |
------------------------------------------
Output 201: Average over 32 episodes - Reward: 0.4375
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 201         |
|    time_elapsed         | 743         |
|    total_timesteps      | 411648      |
| train/                  |             |
|    approx_kl            | 0.012444817 |
|    clip_fraction        | 0.0374      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.18       |
|    explained_variance   | 0.487       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00203     |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00329    |
|    value_loss           | 0.0176      |
-----------------------------------------
Output 202: Average over 34 episodes - Reward: 0.3235294117647059
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 202         |
|    time_elapsed         | 747         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.008070963 |
|    clip_fraction        | 0.0504      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.215      |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00421     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00312    |
|    value_loss           | 0.014       |
-----------------------------------------
Output 203: Average over 30 episodes - Reward: 0.5333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 203          |
|    time_elapsed         | 750          |
|    total_timesteps      | 415744       |
| train/                  |              |
|    approx_kl            | 0.0039951694 |
|    clip_fraction        | 0.0465       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.194       |
|    explained_variance   | 0.643        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0128       |
|    n_updates            | 2020         |
|    policy_gradient_loss | -0.00538     |
|    value_loss           | 0.0146       |
------------------------------------------
Output 204: Average over 28 episodes - Reward: 0.6071428571428571
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 204         |
|    time_elapsed         | 754         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.004479845 |
|    clip_fraction        | 0.0535      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.185      |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00907    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.00437    |
|    value_loss           | 0.017       |
-----------------------------------------
Output 205: Average over 27 episodes - Reward: 0.5185185185185185
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 205          |
|    time_elapsed         | 758          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0024953713 |
|    clip_fraction        | 0.0296       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.158       |
|    explained_variance   | 0.509        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0135       |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.00238     |
|    value_loss           | 0.012        |
------------------------------------------
Output 206: Average over 30 episodes - Reward: 0.36666666666666664
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 206          |
|    time_elapsed         | 761          |
|    total_timesteps      | 421888       |
| train/                  |              |
|    approx_kl            | 0.0042081666 |
|    clip_fraction        | 0.0387       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.176       |
|    explained_variance   | 0.55         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0109      |
|    n_updates            | 2050         |
|    policy_gradient_loss | -0.00315     |
|    value_loss           | 0.013        |
------------------------------------------
Output 207: Average over 30 episodes - Reward: 0.43333333333333335
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 207          |
|    time_elapsed         | 765          |
|    total_timesteps      | 423936       |
| train/                  |              |
|    approx_kl            | 0.0026228721 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.168       |
|    explained_variance   | 0.477        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00621      |
|    n_updates            | 2060         |
|    policy_gradient_loss | -0.00387     |
|    value_loss           | 0.0145       |
------------------------------------------
Output 208: Average over 30 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 208          |
|    time_elapsed         | 768          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0029716592 |
|    clip_fraction        | 0.0198       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 0.502        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0129       |
|    n_updates            | 2070         |
|    policy_gradient_loss | -0.00185     |
|    value_loss           | 0.0149       |
------------------------------------------
Output 209: Average over 26 episodes - Reward: 0.23076923076923078
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 209          |
|    time_elapsed         | 772          |
|    total_timesteps      | 428032       |
| train/                  |              |
|    approx_kl            | 0.0032772692 |
|    clip_fraction        | 0.0331       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0.517        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00728      |
|    n_updates            | 2080         |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 0.0153       |
------------------------------------------
Output 210: Average over 26 episodes - Reward: 0.4230769230769231
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 210          |
|    time_elapsed         | 775          |
|    total_timesteps      | 430080       |
| train/                  |              |
|    approx_kl            | 0.0035440356 |
|    clip_fraction        | 0.0474       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.156       |
|    explained_variance   | 0.505        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0041       |
|    n_updates            | 2090         |
|    policy_gradient_loss | -0.00597     |
|    value_loss           | 0.00917      |
------------------------------------------
Output 211: Average over 29 episodes - Reward: 0.41379310344827586
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 211          |
|    time_elapsed         | 778          |
|    total_timesteps      | 432128       |
| train/                  |              |
|    approx_kl            | 0.0025574397 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 0.442        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00172     |
|    n_updates            | 2100         |
|    policy_gradient_loss | -0.0023      |
|    value_loss           | 0.013        |
------------------------------------------
Output 212: Average over 28 episodes - Reward: 0.39285714285714285
------------------------------------------
| time/                   |              |
|    fps                  | 555          |
|    iterations           | 212          |
|    time_elapsed         | 782          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0020702707 |
|    clip_fraction        | 0.0278       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.174       |
|    explained_variance   | 0.488        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0112       |
|    n_updates            | 2110         |
|    policy_gradient_loss | -0.00191     |
|    value_loss           | 0.0142       |
------------------------------------------
Output 213: Average over 27 episodes - Reward: 0.37037037037037035
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 213          |
|    time_elapsed         | 786          |
|    total_timesteps      | 436224       |
| train/                  |              |
|    approx_kl            | 0.0034255853 |
|    clip_fraction        | 0.0491       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.155       |
|    explained_variance   | 0.381        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000546    |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.00474     |
|    value_loss           | 0.0143       |
------------------------------------------
Output 214: Average over 34 episodes - Reward: 0.47058823529411764
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 214         |
|    time_elapsed         | 789         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.005111766 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.172      |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00052    |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.00272    |
|    value_loss           | 0.0112      |
-----------------------------------------
Output 215: Average over 27 episodes - Reward: 0.4444444444444444
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 215          |
|    time_elapsed         | 793          |
|    total_timesteps      | 440320       |
| train/                  |              |
|    approx_kl            | 0.0045599504 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.17        |
|    explained_variance   | 0.575        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00797      |
|    n_updates            | 2140         |
|    policy_gradient_loss | -0.00435     |
|    value_loss           | 0.0161       |
------------------------------------------
Output 216: Average over 30 episodes - Reward: 0.3333333333333333
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 216          |
|    time_elapsed         | 797          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0039812983 |
|    clip_fraction        | 0.0366       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.146       |
|    explained_variance   | 0.555        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000507     |
|    n_updates            | 2150         |
|    policy_gradient_loss | -0.00334     |
|    value_loss           | 0.0146       |
------------------------------------------
Output 217: Average over 27 episodes - Reward: 0.6296296296296297
----------------------------------------
| time/                   |            |
|    fps                  | 555        |
|    iterations           | 217        |
|    time_elapsed         | 800        |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.00424543 |
|    clip_fraction        | 0.0301     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.594      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0042     |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.00322   |
|    value_loss           | 0.0118     |
----------------------------------------
Output 218: Average over 26 episodes - Reward: 0.34615384615384615
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 218         |
|    time_elapsed         | 804         |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.004601448 |
|    clip_fraction        | 0.035       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0256      |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.00294    |
|    value_loss           | 0.0146      |
-----------------------------------------
Output 219: Average over 28 episodes - Reward: 0.21428571428571427
------------------------------------------
| time/                   |              |
|    fps                  | 555          |
|    iterations           | 219          |
|    time_elapsed         | 807          |
|    total_timesteps      | 448512       |
| train/                  |              |
|    approx_kl            | 0.0025206502 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.366        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.014       |
|    n_updates            | 2180         |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 0.0129       |
------------------------------------------
Output 220: Average over 29 episodes - Reward: 0.27586206896551724
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 220         |
|    time_elapsed         | 811         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.014903564 |
|    clip_fraction        | 0.0447      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00345     |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.00633    |
|    value_loss           | 0.0156      |
-----------------------------------------
Output 221: Average over 27 episodes - Reward: 0.4074074074074074
-----------------------------------------
| time/                   |             |
|    fps                  | 555         |
|    iterations           | 221         |
|    time_elapsed         | 815         |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.004713732 |
|    clip_fraction        | 0.0376      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.185      |
|    explained_variance   | 0.145       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00173    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00489    |
|    value_loss           | 0.0169      |
-----------------------------------------
Output 222: Average over 29 episodes - Reward: 0.3103448275862069
------------------------------------------
| time/                   |              |
|    fps                  | 555          |
|    iterations           | 222          |
|    time_elapsed         | 819          |
|    total_timesteps      | 454656       |
| train/                  |              |
|    approx_kl            | 0.0047774054 |
|    clip_fraction        | 0.0473       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.166       |
|    explained_variance   | 0.255        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0108      |
|    n_updates            | 2210         |
|    policy_gradient_loss | -0.00519     |
|    value_loss           | 0.0141       |
------------------------------------------
Output 223: Average over 28 episodes - Reward: 0.6071428571428571
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 223         |
|    time_elapsed         | 823         |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.005171293 |
|    clip_fraction        | 0.0362      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.171      |
|    explained_variance   | 0.353       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00693     |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.00337    |
|    value_loss           | 0.0191      |
-----------------------------------------
Output 224: Average over 27 episodes - Reward: 0.48148148148148145
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 224         |
|    time_elapsed         | 826         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.003474744 |
|    clip_fraction        | 0.0449      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00729     |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.00207    |
|    value_loss           | 0.0173      |
-----------------------------------------
Output 225: Average over 30 episodes - Reward: 0.43333333333333335
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 225          |
|    time_elapsed         | 830          |
|    total_timesteps      | 460800       |
| train/                  |              |
|    approx_kl            | 0.0075937063 |
|    clip_fraction        | 0.0516       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.186       |
|    explained_variance   | 0.553        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00665      |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.00379     |
|    value_loss           | 0.0149       |
------------------------------------------
Output 226: Average over 33 episodes - Reward: 0.48484848484848486
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 226          |
|    time_elapsed         | 835          |
|    total_timesteps      | 462848       |
| train/                  |              |
|    approx_kl            | 0.0063985535 |
|    clip_fraction        | 0.0484       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.184       |
|    explained_variance   | 0.483        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0131      |
|    n_updates            | 2250         |
|    policy_gradient_loss | -0.00429     |
|    value_loss           | 0.0142       |
------------------------------------------
Output 227: Average over 32 episodes - Reward: 0.46875
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 227         |
|    time_elapsed         | 839         |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.005023271 |
|    clip_fraction        | 0.0451      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.193      |
|    explained_variance   | 0.462       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0069      |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.00409    |
|    value_loss           | 0.0184      |
-----------------------------------------
Output 228: Average over 31 episodes - Reward: 0.3548387096774194
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 228         |
|    time_elapsed         | 842         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.004610081 |
|    clip_fraction        | 0.0408      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.174      |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0122     |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.00519    |
|    value_loss           | 0.022       |
-----------------------------------------
Output 229: Average over 26 episodes - Reward: 0.46153846153846156
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 229          |
|    time_elapsed         | 847          |
|    total_timesteps      | 468992       |
| train/                  |              |
|    approx_kl            | 0.0032651057 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.161       |
|    explained_variance   | 0.31         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00113     |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.00434     |
|    value_loss           | 0.0197       |
------------------------------------------
Output 230: Average over 32 episodes - Reward: 0.4375
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 230          |
|    time_elapsed         | 851          |
|    total_timesteps      | 471040       |
| train/                  |              |
|    approx_kl            | 0.0027232417 |
|    clip_fraction        | 0.0413       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.142       |
|    explained_variance   | 0.219        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00248     |
|    n_updates            | 2290         |
|    policy_gradient_loss | -0.00291     |
|    value_loss           | 0.0162       |
------------------------------------------
Output 231: Average over 29 episodes - Reward: 0.27586206896551724
------------------------------------------
| time/                   |              |
|    fps                  | 553          |
|    iterations           | 231          |
|    time_elapsed         | 854          |
|    total_timesteps      | 473088       |
| train/                  |              |
|    approx_kl            | 0.0038722607 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.158       |
|    explained_variance   | 0.475        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00948      |
|    n_updates            | 2300         |
|    policy_gradient_loss | -0.00492     |
|    value_loss           | 0.0142       |
------------------------------------------
Output 232: Average over 27 episodes - Reward: 0.48148148148148145
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 232         |
|    time_elapsed         | 858         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.009093117 |
|    clip_fraction        | 0.0299      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.144      |
|    explained_variance   | 0.456       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0115      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.00424    |
|    value_loss           | 0.0142      |
-----------------------------------------
Output 233: Average over 29 episodes - Reward: 0.41379310344827586
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 233         |
|    time_elapsed         | 861         |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.005897702 |
|    clip_fraction        | 0.0275      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00441     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.00267    |
|    value_loss           | 0.0145      |
-----------------------------------------
Output 234: Average over 29 episodes - Reward: 0.4482758620689655
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 234         |
|    time_elapsed         | 865         |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.002825226 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.139      |
|    explained_variance   | 0.523       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00807     |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.00407    |
|    value_loss           | 0.013       |
-----------------------------------------
Output 235: Average over 28 episodes - Reward: 0.5714285714285714
-----------------------------------------
| time/                   |             |
|    fps                  | 553         |
|    iterations           | 235         |
|    time_elapsed         | 868         |
|    total_timesteps      | 481280      |
| train/                  |             |
|    approx_kl            | 0.004020022 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00258     |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.00133    |
|    value_loss           | 0.0151      |
-----------------------------------------
Output 236: Average over 25 episodes - Reward: 0.56
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 236          |
|    time_elapsed         | 872          |
|    total_timesteps      | 483328       |
| train/                  |              |
|    approx_kl            | 0.0016739517 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.502        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0021       |
|    n_updates            | 2350         |
|    policy_gradient_loss | -0.00116     |
|    value_loss           | 0.015        |
------------------------------------------
Output 237: Average over 29 episodes - Reward: 0.5172413793103449
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 237         |
|    time_elapsed         | 876         |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.003552867 |
|    clip_fraction        | 0.0405      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.128      |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000223    |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00702    |
|    value_loss           | 0.0137      |
-----------------------------------------
Output 238: Average over 33 episodes - Reward: 0.3939393939393939
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 238          |
|    time_elapsed         | 879          |
|    total_timesteps      | 487424       |
| train/                  |              |
|    approx_kl            | 0.0039708978 |
|    clip_fraction        | 0.0343       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.508        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00933      |
|    n_updates            | 2370         |
|    policy_gradient_loss | -0.00249     |
|    value_loss           | 0.0133       |
------------------------------------------
Output 239: Average over 32 episodes - Reward: 0.375
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 239          |
|    time_elapsed         | 882          |
|    total_timesteps      | 489472       |
| train/                  |              |
|    approx_kl            | 0.0090152975 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.552        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00741     |
|    n_updates            | 2380         |
|    policy_gradient_loss | -0.00423     |
|    value_loss           | 0.0146       |
------------------------------------------
Output 240: Average over 27 episodes - Reward: 0.2222222222222222
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 240         |
|    time_elapsed         | 886         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.004164514 |
|    clip_fraction        | 0.0303      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00282    |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.00228    |
|    value_loss           | 0.0144      |
-----------------------------------------
Output 241: Average over 35 episodes - Reward: 0.5714285714285714
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 241          |
|    time_elapsed         | 889          |
|    total_timesteps      | 493568       |
| train/                  |              |
|    approx_kl            | 0.0050030374 |
|    clip_fraction        | 0.035        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.141       |
|    explained_variance   | 0.435        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00778      |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.0037      |
|    value_loss           | 0.0133       |
------------------------------------------
Output 242: Average over 29 episodes - Reward: 0.41379310344827586
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 242         |
|    time_elapsed         | 893         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.002582596 |
|    clip_fraction        | 0.0245      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.131      |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0051      |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.00238    |
|    value_loss           | 0.0186      |
-----------------------------------------
Output 243: Average over 25 episodes - Reward: 0.4
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 243          |
|    time_elapsed         | 897          |
|    total_timesteps      | 497664       |
| train/                  |              |
|    approx_kl            | 0.0029631574 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.118       |
|    explained_variance   | 0.532        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.033        |
|    n_updates            | 2420         |
|    policy_gradient_loss | -0.00321     |
|    value_loss           | 0.0142       |
------------------------------------------
Output 244: Average over 28 episodes - Reward: 0.5
-----------------------------------------
| time/                   |             |
|    fps                  | 554         |
|    iterations           | 244         |
|    time_elapsed         | 900         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.003355233 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.403       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000776   |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0059     |
|    value_loss           | 0.0108      |
-----------------------------------------
Output 245: Average over 30 episodes - Reward: 0.5
------------------------------------------
| time/                   |              |
|    fps                  | 554          |
|    iterations           | 245          |
|    time_elapsed         | 904          |
|    total_timesteps      | 501760       |
| train/                  |              |
|    approx_kl            | 0.0027383165 |
|    clip_fraction        | 0.0197       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0868      |
|    explained_variance   | 0.487        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00758      |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.00275     |
|    value_loss           | 0.013        |
------------------------------------------
Overall: Average Reward: 0.22795991166978088
```

# 8x8 frozen lake map DQN - is_slippery off
```
Logging to ./DQNtensorboard/DQN_2
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 27.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.998    |
| time/               |          |
|    episodes         | 4        |
|    fps              | 3211     |
|    time_elapsed     | 0        |
|    total_timesteps  | 111      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00369  |
|    n_updates        | 2        |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.995    |
| time/               |          |
|    episodes         | 8        |
|    fps              | 1428     |
|    time_elapsed     | 0        |
|    total_timesteps  | 266      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00382  |
|    n_updates        | 41       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.992    |
| time/               |          |
|    episodes         | 12       |
|    fps              | 1263     |
|    time_elapsed     | 0        |
|    total_timesteps  | 439      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00181  |
|    n_updates        | 84       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.989    |
| time/               |          |
|    episodes         | 16       |
|    fps              | 1195     |
|    time_elapsed     | 0        |
|    total_timesteps  | 562      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00135  |
|    n_updates        | 115      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.986    |
| time/               |          |
|    episodes         | 20       |
|    fps              | 1143     |
|    time_elapsed     | 0        |
|    total_timesteps  | 735      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000955 |
|    n_updates        | 158      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.984    |
| time/               |          |
|    episodes         | 24       |
|    fps              | 1135     |
|    time_elapsed     | 0        |
|    total_timesteps  | 842      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000214 |
|    n_updates        | 185      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.981    |
| time/               |          |
|    episodes         | 28       |
|    fps              | 1121     |
|    time_elapsed     | 0        |
|    total_timesteps  | 979      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000148 |
|    n_updates        | 219      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.977    |
| time/               |          |
|    episodes         | 32       |
|    fps              | 1125     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1196     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000133 |
|    n_updates        | 273      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.972    |
| time/               |          |
|    episodes         | 36       |
|    fps              | 1121     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1483     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.98e-05 |
|    n_updates        | 345      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.969    |
| time/               |          |
|    episodes         | 40       |
|    fps              | 1119     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1620     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000145 |
|    n_updates        | 379      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.968    |
| time/               |          |
|    episodes         | 44       |
|    fps              | 1113     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1699     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.74e-05 |
|    n_updates        | 399      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.966    |
| time/               |          |
|    episodes         | 48       |
|    fps              | 1105     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1795     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.77e-05 |
|    n_updates        | 423      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.963    |
| time/               |          |
|    episodes         | 52       |
|    fps              | 1102     |
|    time_elapsed     | 1        |
|    total_timesteps  | 1954     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.71e-05 |
|    n_updates        | 463      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.96     |
| time/               |          |
|    episodes         | 56       |
|    fps              | 1101     |
|    time_elapsed     | 1        |
|    total_timesteps  | 2118     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000104 |
|    n_updates        | 504      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.958    |
| time/               |          |
|    episodes         | 60       |
|    fps              | 1102     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2234     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.27e-05 |
|    n_updates        | 533      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.955    |
| time/               |          |
|    episodes         | 64       |
|    fps              | 1105     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2364     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.95e-05 |
|    n_updates        | 565      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.952    |
| time/               |          |
|    episodes         | 68       |
|    fps              | 1103     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2528     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.26e-05 |
|    n_updates        | 606      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.949    |
| time/               |          |
|    episodes         | 72       |
|    fps              | 1101     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2689     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.05e-05 |
|    n_updates        | 647      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.947    |
| time/               |          |
|    episodes         | 76       |
|    fps              | 1098     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2803     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.49e-05 |
|    n_updates        | 675      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.945    |
| time/               |          |
|    episodes         | 80       |
|    fps              | 1099     |
|    time_elapsed     | 2        |
|    total_timesteps  | 2901     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.54e-05 |
|    n_updates        | 700      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.942    |
| time/               |          |
|    episodes         | 84       |
|    fps              | 1101     |
|    time_elapsed     | 2        |
|    total_timesteps  | 3031     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.44e-05 |
|    n_updates        | 732      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.939    |
| time/               |          |
|    episodes         | 88       |
|    fps              | 1101     |
|    time_elapsed     | 2        |
|    total_timesteps  | 3194     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.83e-05 |
|    n_updates        | 773      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.936    |
| time/               |          |
|    episodes         | 92       |
|    fps              | 1097     |
|    time_elapsed     | 3        |
|    total_timesteps  | 3357     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.67e-05 |
|    n_updates        | 814      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.933    |
| time/               |          |
|    episodes         | 96       |
|    fps              | 1096     |
|    time_elapsed     | 3        |
|    total_timesteps  | 3547     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.98e-05 |
|    n_updates        | 861      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.931    |
| time/               |          |
|    episodes         | 100      |
|    fps              | 1091     |
|    time_elapsed     | 3        |
|    total_timesteps  | 3627     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000101 |
|    n_updates        | 881      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 104      |
|    fps              | 1087     |
|    time_elapsed     | 3        |
|    total_timesteps  | 3817     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.39e-05 |
|    n_updates        | 929      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.927    |
| time/               |          |
|    episodes         | 108      |
|    fps              | 1085     |
|    time_elapsed     | 3        |
|    total_timesteps  | 3868     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.41e-06 |
|    n_updates        | 941      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.924    |
| time/               |          |
|    episodes         | 112      |
|    fps              | 1078     |
|    time_elapsed     | 3        |
|    total_timesteps  | 4007     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.74e-05 |
|    n_updates        | 976      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.922    |
| time/               |          |
|    episodes         | 116      |
|    fps              | 1078     |
|    time_elapsed     | 3        |
|    total_timesteps  | 4120     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.32e-05 |
|    n_updates        | 1004     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.919    |
| time/               |          |
|    episodes         | 120      |
|    fps              | 1075     |
|    time_elapsed     | 3        |
|    total_timesteps  | 4260     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.18e-06 |
|    n_updates        | 1039     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.916    |
| time/               |          |
|    episodes         | 124      |
|    fps              | 1072     |
|    time_elapsed     | 4        |
|    total_timesteps  | 4407     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.93e-05 |
|    n_updates        | 1076     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.914    |
| time/               |          |
|    episodes         | 128      |
|    fps              | 1072     |
|    time_elapsed     | 4        |
|    total_timesteps  | 4538     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.14e-05 |
|    n_updates        | 1109     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.911    |
| time/               |          |
|    episodes         | 132      |
|    fps              | 1069     |
|    time_elapsed     | 4        |
|    total_timesteps  | 4682     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.45e-07 |
|    n_updates        | 1145     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.908    |
| time/               |          |
|    episodes         | 136      |
|    fps              | 1069     |
|    time_elapsed     | 4        |
|    total_timesteps  | 4841     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-05 |
|    n_updates        | 1185     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.905    |
| time/               |          |
|    episodes         | 140      |
|    fps              | 1066     |
|    time_elapsed     | 4        |
|    total_timesteps  | 5019     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.57e-06 |
|    n_updates        | 1229     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.902    |
| time/               |          |
|    episodes         | 144      |
|    fps              | 1063     |
|    time_elapsed     | 4        |
|    total_timesteps  | 5144     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-05 |
|    n_updates        | 1260     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.9      |
| time/               |          |
|    episodes         | 148      |
|    fps              | 1057     |
|    time_elapsed     | 4        |
|    total_timesteps  | 5246     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.19e-05 |
|    n_updates        | 1286     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.898    |
| time/               |          |
|    episodes         | 152      |
|    fps              | 1053     |
|    time_elapsed     | 5        |
|    total_timesteps  | 5383     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.1e-06  |
|    n_updates        | 1320     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.895    |
| time/               |          |
|    episodes         | 156      |
|    fps              | 1052     |
|    time_elapsed     | 5        |
|    total_timesteps  | 5503     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.27e-06 |
|    n_updates        | 1350     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.892    |
| time/               |          |
|    episodes         | 160      |
|    fps              | 1052     |
|    time_elapsed     | 5        |
|    total_timesteps  | 5679     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-05 |
|    n_updates        | 1394     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.89     |
| time/               |          |
|    episodes         | 164      |
|    fps              | 1048     |
|    time_elapsed     | 5        |
|    total_timesteps  | 5774     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.97e-06 |
|    n_updates        | 1418     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.888    |
| time/               |          |
|    episodes         | 168      |
|    fps              | 1044     |
|    time_elapsed     | 5        |
|    total_timesteps  | 5903     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.37e-06 |
|    n_updates        | 1450     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.886    |
| time/               |          |
|    episodes         | 172      |
|    fps              | 1041     |
|    time_elapsed     | 5        |
|    total_timesteps  | 6001     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.29e-06 |
|    n_updates        | 1475     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.885    |
| time/               |          |
|    episodes         | 176      |
|    fps              | 1041     |
|    time_elapsed     | 5        |
|    total_timesteps  | 6049     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.22e-05 |
|    n_updates        | 1487     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.883    |
| time/               |          |
|    episodes         | 180      |
|    fps              | 1039     |
|    time_elapsed     | 5        |
|    total_timesteps  | 6151     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.35e-06 |
|    n_updates        | 1512     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.881    |
| time/               |          |
|    episodes         | 184      |
|    fps              | 1037     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6237     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.12e-06 |
|    n_updates        | 1534     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.878    |
| time/               |          |
|    episodes         | 188      |
|    fps              | 1031     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6441     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.27e-06 |
|    n_updates        | 1585     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.875    |
| time/               |          |
|    episodes         | 192      |
|    fps              | 1031     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6586     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.89e-05 |
|    n_updates        | 1621     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.873    |
| time/               |          |
|    episodes         | 196      |
|    fps              | 1031     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6693     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.7e-05  |
|    n_updates        | 1648     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.871    |
| time/               |          |
|    episodes         | 200      |
|    fps              | 1031     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6798     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.93e-06 |
|    n_updates        | 1674     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.868    |
| time/               |          |
|    episodes         | 204      |
|    fps              | 1033     |
|    time_elapsed     | 6        |
|    total_timesteps  | 6944     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.46e-05 |
|    n_updates        | 1710     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.866    |
| time/               |          |
|    episodes         | 208      |
|    fps              | 1033     |
|    time_elapsed     | 6        |
|    total_timesteps  | 7072     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.42e-07 |
|    n_updates        | 1742     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.863    |
| time/               |          |
|    episodes         | 212      |
|    fps              | 1030     |
|    time_elapsed     | 6        |
|    total_timesteps  | 7195     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-06 |
|    n_updates        | 1773     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.862    |
| time/               |          |
|    episodes         | 216      |
|    fps              | 1029     |
|    time_elapsed     | 7        |
|    total_timesteps  | 7278     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.46e-06 |
|    n_updates        | 1794     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.858    |
| time/               |          |
|    episodes         | 220      |
|    fps              | 1027     |
|    time_elapsed     | 7        |
|    total_timesteps  | 7452     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.9e-06  |
|    n_updates        | 1837     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.856    |
| time/               |          |
|    episodes         | 224      |
|    fps              | 1026     |
|    time_elapsed     | 7        |
|    total_timesteps  | 7598     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.21e-07 |
|    n_updates        | 1874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.853    |
| time/               |          |
|    episodes         | 228      |
|    fps              | 1025     |
|    time_elapsed     | 7        |
|    total_timesteps  | 7747     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.78e-06 |
|    n_updates        | 1911     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.849    |
| time/               |          |
|    episodes         | 232      |
|    fps              | 1022     |
|    time_elapsed     | 7        |
|    total_timesteps  | 7973     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.6e-05  |
|    n_updates        | 1968     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.845    |
| time/               |          |
|    episodes         | 236      |
|    fps              | 1021     |
|    time_elapsed     | 7        |
|    total_timesteps  | 8162     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-06 |
|    n_updates        | 2015     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.842    |
| time/               |          |
|    episodes         | 240      |
|    fps              | 1021     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8328     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.26e-06 |
|    n_updates        | 2056     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.839    |
| time/               |          |
|    episodes         | 244      |
|    fps              | 1019     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8484     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.26e-06 |
|    n_updates        | 2095     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.836    |
| time/               |          |
|    episodes         | 248      |
|    fps              | 1019     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8617     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.62e-07 |
|    n_updates        | 2129     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.835    |
| time/               |          |
|    episodes         | 252      |
|    fps              | 1019     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8702     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.67e-06 |
|    n_updates        | 2150     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.834    |
| time/               |          |
|    episodes         | 256      |
|    fps              | 1020     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8756     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.67e-07 |
|    n_updates        | 2163     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.831    |
| time/               |          |
|    episodes         | 260      |
|    fps              | 1020     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8888     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.43e-06 |
|    n_updates        | 2196     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.83     |
| time/               |          |
|    episodes         | 264      |
|    fps              | 1019     |
|    time_elapsed     | 8        |
|    total_timesteps  | 8969     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.99e-07 |
|    n_updates        | 2217     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.828    |
| time/               |          |
|    episodes         | 268      |
|    fps              | 1020     |
|    time_elapsed     | 8        |
|    total_timesteps  | 9074     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.92e-06 |
|    n_updates        | 2243     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.824    |
| time/               |          |
|    episodes         | 272      |
|    fps              | 1020     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9247     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.14e-06 |
|    n_updates        | 2286     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.823    |
| time/               |          |
|    episodes         | 276      |
|    fps              | 1020     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9327     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.93e-06 |
|    n_updates        | 2306     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.819    |
| time/               |          |
|    episodes         | 280      |
|    fps              | 1020     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9523     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.2e-07  |
|    n_updates        | 2355     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.817    |
| time/               |          |
|    episodes         | 284      |
|    fps              | 1020     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9632     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.25e-07 |
|    n_updates        | 2382     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.815    |
| time/               |          |
|    episodes         | 288      |
|    fps              | 1020     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9730     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 2407     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.813    |
| time/               |          |
|    episodes         | 292      |
|    fps              | 1018     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9834     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-06 |
|    n_updates        | 2433     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.811    |
| time/               |          |
|    episodes         | 296      |
|    fps              | 1017     |
|    time_elapsed     | 9        |
|    total_timesteps  | 9943     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.13e-07 |
|    n_updates        | 2460     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.809    |
| time/               |          |
|    episodes         | 300      |
|    fps              | 1014     |
|    time_elapsed     | 9        |
|    total_timesteps  | 10037    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.75e-05 |
|    n_updates        | 2484     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.807    |
| time/               |          |
|    episodes         | 304      |
|    fps              | 1013     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10161    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-05 |
|    n_updates        | 2515     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.805    |
| time/               |          |
|    episodes         | 308      |
|    fps              | 1011     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10259    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-05 |
|    n_updates        | 2539     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.802    |
| time/               |          |
|    episodes         | 312      |
|    fps              | 1009     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10407    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.85e-06 |
|    n_updates        | 2576     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.799    |
| time/               |          |
|    episodes         | 316      |
|    fps              | 1009     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10574    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.58e-06 |
|    n_updates        | 2618     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.797    |
| time/               |          |
|    episodes         | 320      |
|    fps              | 1010     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10703    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-05 |
|    n_updates        | 2650     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.794    |
| time/               |          |
|    episodes         | 324      |
|    fps              | 1011     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10824    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.88e-06 |
|    n_updates        | 2680     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.793    |
| time/               |          |
|    episodes         | 328      |
|    fps              | 1011     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10882    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.63e-06 |
|    n_updates        | 2695     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.791    |
| time/               |          |
|    episodes         | 332      |
|    fps              | 1011     |
|    time_elapsed     | 10       |
|    total_timesteps  | 10991    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.65e-06 |
|    n_updates        | 2722     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.788    |
| time/               |          |
|    episodes         | 336      |
|    fps              | 1011     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11160    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-06 |
|    n_updates        | 2764     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.785    |
| time/               |          |
|    episodes         | 340      |
|    fps              | 1011     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11303    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.39e-07 |
|    n_updates        | 2800     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.784    |
| time/               |          |
|    episodes         | 344      |
|    fps              | 1010     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11365    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.1e-05  |
|    n_updates        | 2816     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 28.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.782    |
| time/               |          |
|    episodes         | 348      |
|    fps              | 1011     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11467    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.45e-06 |
|    n_updates        | 2841     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.779    |
| time/               |          |
|    episodes         | 352      |
|    fps              | 1012     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11641    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.22e-06 |
|    n_updates        | 2885     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.777    |
| time/               |          |
|    episodes         | 356      |
|    fps              | 1012     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11725    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-06 |
|    n_updates        | 2906     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.775    |
| time/               |          |
|    episodes         | 360      |
|    fps              | 1013     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11851    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.16e-06 |
|    n_updates        | 2937     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.773    |
| time/               |          |
|    episodes         | 364      |
|    fps              | 1013     |
|    time_elapsed     | 11       |
|    total_timesteps  | 11969    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.3e-06  |
|    n_updates        | 2967     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.771    |
| time/               |          |
|    episodes         | 368      |
|    fps              | 1013     |
|    time_elapsed     | 11       |
|    total_timesteps  | 12071    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.3e-06  |
|    n_updates        | 2992     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.768    |
| time/               |          |
|    episodes         | 372      |
|    fps              | 1013     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12200    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.65e-06 |
|    n_updates        | 3024     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.765    |
| time/               |          |
|    episodes         | 376      |
|    fps              | 1013     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12389    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.55e-07 |
|    n_updates        | 3072     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 29.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.763    |
| time/               |          |
|    episodes         | 380      |
|    fps              | 1013     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12477    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.03e-06 |
|    n_updates        | 3094     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.76     |
| time/               |          |
|    episodes         | 384      |
|    fps              | 1014     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12657    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.92e-05 |
|    n_updates        | 3139     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.757    |
| time/               |          |
|    episodes         | 388      |
|    fps              | 1015     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12788    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.29e-06 |
|    n_updates        | 3171     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.754    |
| time/               |          |
|    episodes         | 392      |
|    fps              | 1016     |
|    time_elapsed     | 12       |
|    total_timesteps  | 12948    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 3211     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.752    |
| time/               |          |
|    episodes         | 396      |
|    fps              | 1015     |
|    time_elapsed     | 12       |
|    total_timesteps  | 13057    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.03e-06 |
|    n_updates        | 3239     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.751    |
| time/               |          |
|    episodes         | 400      |
|    fps              | 1015     |
|    time_elapsed     | 12       |
|    total_timesteps  | 13117    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.45e-06 |
|    n_updates        | 3254     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.748    |
| time/               |          |
|    episodes         | 404      |
|    fps              | 1014     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13259    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.74e-07 |
|    n_updates        | 3289     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.746    |
| time/               |          |
|    episodes         | 408      |
|    fps              | 1015     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13356    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-06 |
|    n_updates        | 3313     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.743    |
| time/               |          |
|    episodes         | 412      |
|    fps              | 1015     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13514    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.15e-06 |
|    n_updates        | 3353     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.739    |
| time/               |          |
|    episodes         | 416      |
|    fps              | 1016     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13725    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-06  |
|    n_updates        | 3406     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.736    |
| time/               |          |
|    episodes         | 420      |
|    fps              | 1016     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13880    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.18e-06 |
|    n_updates        | 3444     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.734    |
| time/               |          |
|    episodes         | 424      |
|    fps              | 1016     |
|    time_elapsed     | 13       |
|    total_timesteps  | 13982    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.54e-07 |
|    n_updates        | 3470     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.732    |
| time/               |          |
|    episodes         | 428      |
|    fps              | 1016     |
|    time_elapsed     | 13       |
|    total_timesteps  | 14125    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.22e-06 |
|    n_updates        | 3506     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.727    |
| time/               |          |
|    episodes         | 432      |
|    fps              | 1015     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14362    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-05 |
|    n_updates        | 3565     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.725    |
| time/               |          |
|    episodes         | 436      |
|    fps              | 1015     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14473    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.93e-07 |
|    n_updates        | 3593     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.722    |
| time/               |          |
|    episodes         | 440      |
|    fps              | 1015     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14633    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.8e-08  |
|    n_updates        | 3633     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.718    |
| time/               |          |
|    episodes         | 444      |
|    fps              | 1012     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14829    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.83e-07 |
|    n_updates        | 3682     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.716    |
| time/               |          |
|    episodes         | 448      |
|    fps              | 1012     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14925    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.38e-07 |
|    n_updates        | 3706     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.715    |
| time/               |          |
|    episodes         | 452      |
|    fps              | 1012     |
|    time_elapsed     | 14       |
|    total_timesteps  | 14982    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.02e-08 |
|    n_updates        | 3720     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.713    |
| time/               |          |
|    episodes         | 456      |
|    fps              | 1011     |
|    time_elapsed     | 14       |
|    total_timesteps  | 15093    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-06  |
|    n_updates        | 3748     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.712    |
| time/               |          |
|    episodes         | 460      |
|    fps              | 1011     |
|    time_elapsed     | 14       |
|    total_timesteps  | 15143    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.68e-07 |
|    n_updates        | 3760     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.71     |
| time/               |          |
|    episodes         | 464      |
|    fps              | 1010     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15263    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.51e-06 |
|    n_updates        | 3790     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.707    |
| time/               |          |
|    episodes         | 468      |
|    fps              | 1008     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15409    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-06 |
|    n_updates        | 3827     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.705    |
| time/               |          |
|    episodes         | 472      |
|    fps              | 1008     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15538    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.12e-07 |
|    n_updates        | 3859     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.703    |
| time/               |          |
|    episodes         | 476      |
|    fps              | 1008     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15617    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.88e-07 |
|    n_updates        | 3879     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.701    |
| time/               |          |
|    episodes         | 480      |
|    fps              | 1007     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15743    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.42e-07 |
|    n_updates        | 3910     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.697    |
| time/               |          |
|    episodes         | 484      |
|    fps              | 1007     |
|    time_elapsed     | 15       |
|    total_timesteps  | 15923    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-07 |
|    n_updates        | 3955     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.693    |
| time/               |          |
|    episodes         | 488      |
|    fps              | 1007     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16135    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.04e-08 |
|    n_updates        | 4008     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.69     |
| time/               |          |
|    episodes         | 492      |
|    fps              | 1007     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16315    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.09e-08 |
|    n_updates        | 4053     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.687    |
| time/               |          |
|    episodes         | 496      |
|    fps              | 1007     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16488    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.02e-06 |
|    n_updates        | 4096     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.684    |
| time/               |          |
|    episodes         | 500      |
|    fps              | 1006     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16608    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.12e-06 |
|    n_updates        | 4126     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.683    |
| time/               |          |
|    episodes         | 504      |
|    fps              | 1006     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16706    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.17e-08 |
|    n_updates        | 4151     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.68     |
| time/               |          |
|    episodes         | 508      |
|    fps              | 1005     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16867    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.82e-08 |
|    n_updates        | 4191     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.678    |
| time/               |          |
|    episodes         | 512      |
|    fps              | 1005     |
|    time_elapsed     | 16       |
|    total_timesteps  | 16955    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.21e-08 |
|    n_updates        | 4213     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.675    |
| time/               |          |
|    episodes         | 516      |
|    fps              | 1005     |
|    time_elapsed     | 16       |
|    total_timesteps  | 17081    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.06e-06 |
|    n_updates        | 4245     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.674    |
| time/               |          |
|    episodes         | 520      |
|    fps              | 1005     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17150    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-05 |
|    n_updates        | 4262     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.671    |
| time/               |          |
|    episodes         | 524      |
|    fps              | 1004     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17303    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.92e-07 |
|    n_updates        | 4300     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.67     |
| time/               |          |
|    episodes         | 528      |
|    fps              | 1004     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17375    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-07 |
|    n_updates        | 4318     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.668    |
| time/               |          |
|    episodes         | 532      |
|    fps              | 1004     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17464    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.53e-08 |
|    n_updates        | 4340     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.666    |
| time/               |          |
|    episodes         | 536      |
|    fps              | 1004     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17579    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.41e-08 |
|    n_updates        | 4369     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.664    |
| time/               |          |
|    episodes         | 540      |
|    fps              | 1003     |
|    time_elapsed     | 17       |
|    total_timesteps  | 17675    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.96e-06 |
|    n_updates        | 4393     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.661    |
| time/               |          |
|    episodes         | 544      |
|    fps              | 999      |
|    time_elapsed     | 17       |
|    total_timesteps  | 17868    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.12e-06 |
|    n_updates        | 4441     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 30.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.658    |
| time/               |          |
|    episodes         | 548      |
|    fps              | 997      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18014    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.5e-08  |
|    n_updates        | 4478     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.655    |
| time/               |          |
|    episodes         | 552      |
|    fps              | 996      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18158    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.68e-07 |
|    n_updates        | 4514     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.652    |
| time/               |          |
|    episodes         | 556      |
|    fps              | 996      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18312    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-08 |
|    n_updates        | 4552     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.648    |
| time/               |          |
|    episodes         | 560      |
|    fps              | 995      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18505    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.83e-08 |
|    n_updates        | 4601     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.645    |
| time/               |          |
|    episodes         | 564      |
|    fps              | 994      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18695    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.29e-08 |
|    n_updates        | 4648     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.642    |
| time/               |          |
|    episodes         | 568      |
|    fps              | 993      |
|    time_elapsed     | 18       |
|    total_timesteps  | 18816    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.04e-05 |
|    n_updates        | 4678     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.641    |
| time/               |          |
|    episodes         | 572      |
|    fps              | 993      |
|    time_elapsed     | 19       |
|    total_timesteps  | 18888    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-08 |
|    n_updates        | 4696     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.638    |
| time/               |          |
|    episodes         | 576      |
|    fps              | 992      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19043    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.92e-06 |
|    n_updates        | 4735     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.636    |
| time/               |          |
|    episodes         | 580      |
|    fps              | 991      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19157    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.02e-08 |
|    n_updates        | 4764     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 584      |
|    fps              | 989      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19347    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.83e-09 |
|    n_updates        | 4811     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.631    |
| time/               |          |
|    episodes         | 588      |
|    fps              | 989      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19421    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.56e-06 |
|    n_updates        | 4830     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.63     |
| time/               |          |
|    episodes         | 592      |
|    fps              | 988      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19497    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.3e-07  |
|    n_updates        | 4849     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.627    |
| time/               |          |
|    episodes         | 596      |
|    fps              | 987      |
|    time_elapsed     | 19       |
|    total_timesteps  | 19631    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.51e-08 |
|    n_updates        | 4882     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.624    |
| time/               |          |
|    episodes         | 600      |
|    fps              | 985      |
|    time_elapsed     | 20       |
|    total_timesteps  | 19777    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.18e-06 |
|    n_updates        | 4919     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.623    |
| time/               |          |
|    episodes         | 604      |
|    fps              | 984      |
|    time_elapsed     | 20       |
|    total_timesteps  | 19852    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-06 |
|    n_updates        | 4937     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.62     |
| time/               |          |
|    episodes         | 608      |
|    fps              | 983      |
|    time_elapsed     | 20       |
|    total_timesteps  | 19992    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.5e-08  |
|    n_updates        | 4972     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.619    |
| time/               |          |
|    episodes         | 612      |
|    fps              | 982      |
|    time_elapsed     | 20       |
|    total_timesteps  | 20071    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.32e-06 |
|    n_updates        | 4992     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.616    |
| time/               |          |
|    episodes         | 616      |
|    fps              | 980      |
|    time_elapsed     | 20       |
|    total_timesteps  | 20221    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-06  |
|    n_updates        | 5030     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 32.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.613    |
| time/               |          |
|    episodes         | 620      |
|    fps              | 980      |
|    time_elapsed     | 20       |
|    total_timesteps  | 20366    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.05e-06 |
|    n_updates        | 5066     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 31.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.611    |
| time/               |          |
|    episodes         | 624      |
|    fps              | 979      |
|    time_elapsed     | 20       |
|    total_timesteps  | 20495    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.21e-06 |
|    n_updates        | 5098     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.605    |
| time/               |          |
|    episodes         | 628      |
|    fps              | 974      |
|    time_elapsed     | 21       |
|    total_timesteps  | 20768    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.78e-06 |
|    n_updates        | 5166     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.601    |
| time/               |          |
|    episodes         | 632      |
|    fps              | 971      |
|    time_elapsed     | 21       |
|    total_timesteps  | 20974    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.15e-06 |
|    n_updates        | 5218     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.6      |
| time/               |          |
|    episodes         | 636      |
|    fps              | 970      |
|    time_elapsed     | 21       |
|    total_timesteps  | 21063    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-07 |
|    n_updates        | 5240     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.597    |
| time/               |          |
|    episodes         | 640      |
|    fps              | 969      |
|    time_elapsed     | 21       |
|    total_timesteps  | 21189    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.47e-07 |
|    n_updates        | 5272     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.593    |
| time/               |          |
|    episodes         | 644      |
|    fps              | 968      |
|    time_elapsed     | 22       |
|    total_timesteps  | 21418    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.46e-07 |
|    n_updates        | 5329     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.589    |
| time/               |          |
|    episodes         | 648      |
|    fps              | 967      |
|    time_elapsed     | 22       |
|    total_timesteps  | 21609    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.83e-06 |
|    n_updates        | 5377     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.588    |
| time/               |          |
|    episodes         | 652      |
|    fps              | 967      |
|    time_elapsed     | 22       |
|    total_timesteps  | 21678    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-06 |
|    n_updates        | 5394     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.9     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.586    |
| time/               |          |
|    episodes         | 656      |
|    fps              | 965      |
|    time_elapsed     | 22       |
|    total_timesteps  | 21797    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.26e-07 |
|    n_updates        | 5424     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.5     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.585    |
| time/               |          |
|    episodes         | 660      |
|    fps              | 964      |
|    time_elapsed     | 22       |
|    total_timesteps  | 21858    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.61e-06 |
|    n_updates        | 5439     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.4     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.581    |
| time/               |          |
|    episodes         | 664      |
|    fps              | 963      |
|    time_elapsed     | 22       |
|    total_timesteps  | 22031    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.07e-07 |
|    n_updates        | 5482     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.578    |
| time/               |          |
|    episodes         | 668      |
|    fps              | 959      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22195    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-07 |
|    n_updates        | 5523     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.4     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.576    |
| time/               |          |
|    episodes         | 672      |
|    fps              | 958      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22327    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.92e-08 |
|    n_updates        | 5556     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.4     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.573    |
| time/               |          |
|    episodes         | 676      |
|    fps              | 958      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22478    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.37e-06 |
|    n_updates        | 5594     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 34.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.57     |
| time/               |          |
|    episodes         | 680      |
|    fps              | 957      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22636    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.58e-06 |
|    n_updates        | 5633     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.568    |
| time/               |          |
|    episodes         | 684      |
|    fps              | 957      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22714    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00468  |
|    n_updates        | 5653     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 33.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.567    |
| time/               |          |
|    episodes         | 688      |
|    fps              | 956      |
|    time_elapsed     | 23       |
|    total_timesteps  | 22813    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.75e-07 |
|    n_updates        | 5678     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 35.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.562    |
| time/               |          |
|    episodes         | 692      |
|    fps              | 952      |
|    time_elapsed     | 24       |
|    total_timesteps  | 23042    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-07 |
|    n_updates        | 5735     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.557    |
| time/               |          |
|    episodes         | 696      |
|    fps              | 951      |
|    time_elapsed     | 24       |
|    total_timesteps  | 23309    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.42e-07 |
|    n_updates        | 5802     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.555    |
| time/               |          |
|    episodes         | 700      |
|    fps              | 950      |
|    time_elapsed     | 24       |
|    total_timesteps  | 23405    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-06 |
|    n_updates        | 5826     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.553    |
| time/               |          |
|    episodes         | 704      |
|    fps              | 950      |
|    time_elapsed     | 24       |
|    total_timesteps  | 23506    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.53e-07 |
|    n_updates        | 5851     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.55     |
| time/               |          |
|    episodes         | 708      |
|    fps              | 948      |
|    time_elapsed     | 24       |
|    total_timesteps  | 23710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.3e-07  |
|    n_updates        | 5902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.544    |
| time/               |          |
|    episodes         | 712      |
|    fps              | 945      |
|    time_elapsed     | 25       |
|    total_timesteps  | 24005    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.04e-08 |
|    n_updates        | 5976     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.542    |
| time/               |          |
|    episodes         | 716      |
|    fps              | 945      |
|    time_elapsed     | 25       |
|    total_timesteps  | 24094    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.55e-07 |
|    n_updates        | 5998     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.541    |
| time/               |          |
|    episodes         | 720      |
|    fps              | 945      |
|    time_elapsed     | 25       |
|    total_timesteps  | 24166    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.64e-08 |
|    n_updates        | 6016     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.537    |
| time/               |          |
|    episodes         | 724      |
|    fps              | 946      |
|    time_elapsed     | 25       |
|    total_timesteps  | 24392    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.78e-08 |
|    n_updates        | 6072     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.535    |
| time/               |          |
|    episodes         | 728      |
|    fps              | 946      |
|    time_elapsed     | 25       |
|    total_timesteps  | 24492    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.63e-07 |
|    n_updates        | 6097     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.531    |
| time/               |          |
|    episodes         | 732      |
|    fps              | 946      |
|    time_elapsed     | 26       |
|    total_timesteps  | 24706    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.98e-05 |
|    n_updates        | 6151     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.527    |
| time/               |          |
|    episodes         | 736      |
|    fps              | 945      |
|    time_elapsed     | 26       |
|    total_timesteps  | 24897    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00315  |
|    n_updates        | 6199     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.524    |
| time/               |          |
|    episodes         | 740      |
|    fps              | 944      |
|    time_elapsed     | 26       |
|    total_timesteps  | 25050    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.69e-07 |
|    n_updates        | 6237     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.521    |
| time/               |          |
|    episodes         | 744      |
|    fps              | 942      |
|    time_elapsed     | 26       |
|    total_timesteps  | 25201    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.28e-09 |
|    n_updates        | 6275     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.517    |
| time/               |          |
|    episodes         | 748      |
|    fps              | 941      |
|    time_elapsed     | 26       |
|    total_timesteps  | 25397    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.61e-09 |
|    n_updates        | 6324     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.514    |
| time/               |          |
|    episodes         | 752      |
|    fps              | 940      |
|    time_elapsed     | 27       |
|    total_timesteps  | 25566    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.55e-06 |
|    n_updates        | 6366     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.51     |
| time/               |          |
|    episodes         | 756      |
|    fps              | 940      |
|    time_elapsed     | 27       |
|    total_timesteps  | 25773    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.44e-07 |
|    n_updates        | 6418     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.507    |
| time/               |          |
|    episodes         | 760      |
|    fps              | 940      |
|    time_elapsed     | 27       |
|    total_timesteps  | 25929    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.98e-08 |
|    n_updates        | 6457     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.503    |
| time/               |          |
|    episodes         | 764      |
|    fps              | 937      |
|    time_elapsed     | 27       |
|    total_timesteps  | 26136    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.95e-08 |
|    n_updates        | 6508     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.499    |
| time/               |          |
|    episodes         | 768      |
|    fps              | 936      |
|    time_elapsed     | 28       |
|    total_timesteps  | 26394    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.83e-07 |
|    n_updates        | 6573     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.497    |
| time/               |          |
|    episodes         | 772      |
|    fps              | 935      |
|    time_elapsed     | 28       |
|    total_timesteps  | 26486    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.28e-08 |
|    n_updates        | 6596     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.492    |
| time/               |          |
|    episodes         | 776      |
|    fps              | 932      |
|    time_elapsed     | 28       |
|    total_timesteps  | 26741    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.27e-07 |
|    n_updates        | 6660     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.487    |
| time/               |          |
|    episodes         | 780      |
|    fps              | 930      |
|    time_elapsed     | 29       |
|    total_timesteps  | 26978    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.31e-07 |
|    n_updates        | 6719     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.483    |
| time/               |          |
|    episodes         | 784      |
|    fps              | 929      |
|    time_elapsed     | 29       |
|    total_timesteps  | 27191    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.47e-07 |
|    n_updates        | 6772     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.481    |
| time/               |          |
|    episodes         | 788      |
|    fps              | 928      |
|    time_elapsed     | 29       |
|    total_timesteps  | 27342    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00105  |
|    n_updates        | 6810     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.478    |
| time/               |          |
|    episodes         | 792      |
|    fps              | 927      |
|    time_elapsed     | 29       |
|    total_timesteps  | 27491    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.37e-07 |
|    n_updates        | 6847     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.475    |
| time/               |          |
|    episodes         | 796      |
|    fps              | 927      |
|    time_elapsed     | 29       |
|    total_timesteps  | 27628    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.29e-08 |
|    n_updates        | 6881     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.469    |
| time/               |          |
|    episodes         | 800      |
|    fps              | 925      |
|    time_elapsed     | 30       |
|    total_timesteps  | 27931    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.21e-07 |
|    n_updates        | 6957     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.465    |
| time/               |          |
|    episodes         | 804      |
|    fps              | 924      |
|    time_elapsed     | 30       |
|    total_timesteps  | 28151    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.8e-07  |
|    n_updates        | 7012     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.461    |
| time/               |          |
|    episodes         | 808      |
|    fps              | 922      |
|    time_elapsed     | 30       |
|    total_timesteps  | 28388    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.25e-08 |
|    n_updates        | 7071     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.458    |
| time/               |          |
|    episodes         | 812      |
|    fps              | 921      |
|    time_elapsed     | 30       |
|    total_timesteps  | 28532    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.19e-06 |
|    n_updates        | 7107     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.454    |
| time/               |          |
|    episodes         | 816      |
|    fps              | 919      |
|    time_elapsed     | 31       |
|    total_timesteps  | 28733    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.71e-07 |
|    n_updates        | 7158     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.449    |
| time/               |          |
|    episodes         | 820      |
|    fps              | 917      |
|    time_elapsed     | 31       |
|    total_timesteps  | 29016    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1e-08    |
|    n_updates        | 7228     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.446    |
| time/               |          |
|    episodes         | 824      |
|    fps              | 915      |
|    time_elapsed     | 31       |
|    total_timesteps  | 29171    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.26e-08 |
|    n_updates        | 7267     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.444    |
| time/               |          |
|    episodes         | 828      |
|    fps              | 915      |
|    time_elapsed     | 31       |
|    total_timesteps  | 29250    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.37e-07 |
|    n_updates        | 7287     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.441    |
| time/               |          |
|    episodes         | 832      |
|    fps              | 914      |
|    time_elapsed     | 32       |
|    total_timesteps  | 29437    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.67e-08 |
|    n_updates        | 7334     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.438    |
| time/               |          |
|    episodes         | 836      |
|    fps              | 914      |
|    time_elapsed     | 32       |
|    total_timesteps  | 29574    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 7368     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.433    |
| time/               |          |
|    episodes         | 840      |
|    fps              | 913      |
|    time_elapsed     | 32       |
|    total_timesteps  | 29845    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-07 |
|    n_updates        | 7436     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.431    |
| time/               |          |
|    episodes         | 844      |
|    fps              | 913      |
|    time_elapsed     | 32       |
|    total_timesteps  | 29966    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-07 |
|    n_updates        | 7466     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.428    |
| time/               |          |
|    episodes         | 848      |
|    fps              | 912      |
|    time_elapsed     | 32       |
|    total_timesteps  | 30101    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.81e-06 |
|    n_updates        | 7500     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.6     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.424    |
| time/               |          |
|    episodes         | 852      |
|    fps              | 911      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30324    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.33e-06 |
|    n_updates        | 7555     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.421    |
| time/               |          |
|    episodes         | 856      |
|    fps              | 911      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30455    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-07 |
|    n_updates        | 7588     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.4     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.419    |
| time/               |          |
|    episodes         | 860      |
|    fps              | 911      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30573    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.82e-06 |
|    n_updates        | 7618     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.417    |
| time/               |          |
|    episodes         | 864      |
|    fps              | 910      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30688    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-05 |
|    n_updates        | 7646     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.415    |
| time/               |          |
|    episodes         | 868      |
|    fps              | 909      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30804    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.55e-07 |
|    n_updates        | 7675     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.414    |
| time/               |          |
|    episodes         | 872      |
|    fps              | 909      |
|    time_elapsed     | 33       |
|    total_timesteps  | 30849    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.2e-06  |
|    n_updates        | 7687     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.411    |
| time/               |          |
|    episodes         | 876      |
|    fps              | 909      |
|    time_elapsed     | 34       |
|    total_timesteps  | 31025    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-06 |
|    n_updates        | 7731     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.406    |
| time/               |          |
|    episodes         | 880      |
|    fps              | 908      |
|    time_elapsed     | 34       |
|    total_timesteps  | 31248    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.85e-07 |
|    n_updates        | 7786     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.404    |
| time/               |          |
|    episodes         | 884      |
|    fps              | 908      |
|    time_elapsed     | 34       |
|    total_timesteps  | 31391    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.75e-07 |
|    n_updates        | 7822     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.402    |
| time/               |          |
|    episodes         | 888      |
|    fps              | 907      |
|    time_elapsed     | 34       |
|    total_timesteps  | 31484    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.68e-06 |
|    n_updates        | 7845     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.4      |
| time/               |          |
|    episodes         | 892      |
|    fps              | 906      |
|    time_elapsed     | 34       |
|    total_timesteps  | 31600    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00018  |
|    n_updates        | 7874     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.398    |
| time/               |          |
|    episodes         | 896      |
|    fps              | 905      |
|    time_elapsed     | 35       |
|    total_timesteps  | 31710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.04e-06 |
|    n_updates        | 7902     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.396    |
| time/               |          |
|    episodes         | 900      |
|    fps              | 905      |
|    time_elapsed     | 35       |
|    total_timesteps  | 31814    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00304  |
|    n_updates        | 7928     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.392    |
| time/               |          |
|    episodes         | 904      |
|    fps              | 904      |
|    time_elapsed     | 35       |
|    total_timesteps  | 32002    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.74e-06 |
|    n_updates        | 7975     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.4     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.39     |
| time/               |          |
|    episodes         | 908      |
|    fps              | 903      |
|    time_elapsed     | 35       |
|    total_timesteps  | 32126    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.25e-07 |
|    n_updates        | 8006     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.9     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.386    |
| time/               |          |
|    episodes         | 912      |
|    fps              | 902      |
|    time_elapsed     | 35       |
|    total_timesteps  | 32323    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.52e-06 |
|    n_updates        | 8055     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.7     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.384    |
| time/               |          |
|    episodes         | 916      |
|    fps              | 902      |
|    time_elapsed     | 35       |
|    total_timesteps  | 32402    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.62e-07 |
|    n_updates        | 8075     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.4     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.379    |
| time/               |          |
|    episodes         | 920      |
|    fps              | 901      |
|    time_elapsed     | 36       |
|    total_timesteps  | 32659    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.18e-06 |
|    n_updates        | 8139     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 36.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.376    |
| time/               |          |
|    episodes         | 924      |
|    fps              | 900      |
|    time_elapsed     | 36       |
|    total_timesteps  | 32850    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.81e-07 |
|    n_updates        | 8187     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.5     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.373    |
| time/               |          |
|    episodes         | 928      |
|    fps              | 899      |
|    time_elapsed     | 36       |
|    total_timesteps  | 32996    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-06 |
|    n_updates        | 8223     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.8     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.369    |
| time/               |          |
|    episodes         | 932      |
|    fps              | 898      |
|    time_elapsed     | 36       |
|    total_timesteps  | 33213    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.15e-05 |
|    n_updates        | 8278     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.366    |
| time/               |          |
|    episodes         | 936      |
|    fps              | 896      |
|    time_elapsed     | 37       |
|    total_timesteps  | 33391    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000343 |
|    n_updates        | 8322     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.3     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.362    |
| time/               |          |
|    episodes         | 940      |
|    fps              | 896      |
|    time_elapsed     | 37       |
|    total_timesteps  | 33577    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000623 |
|    n_updates        | 8369     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.4     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.358    |
| time/               |          |
|    episodes         | 944      |
|    fps              | 894      |
|    time_elapsed     | 37       |
|    total_timesteps  | 33805    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.41e-06 |
|    n_updates        | 8426     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.6     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.355    |
| time/               |          |
|    episodes         | 948      |
|    fps              | 893      |
|    time_elapsed     | 37       |
|    total_timesteps  | 33963    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.97e-07 |
|    n_updates        | 8465     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.353    |
| time/               |          |
|    episodes         | 952      |
|    fps              | 893      |
|    time_elapsed     | 38       |
|    total_timesteps  | 34040    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-07  |
|    n_updates        | 8484     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 37.9     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.349    |
| time/               |          |
|    episodes         | 956      |
|    fps              | 892      |
|    time_elapsed     | 38       |
|    total_timesteps  | 34240    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.08e-07 |
|    n_updates        | 8534     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.346    |
| time/               |          |
|    episodes         | 960      |
|    fps              | 892      |
|    time_elapsed     | 38       |
|    total_timesteps  | 34397    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.89e-07 |
|    n_updates        | 8574     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.342    |
| time/               |          |
|    episodes         | 964      |
|    fps              | 890      |
|    time_elapsed     | 38       |
|    total_timesteps  | 34610    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.65e-07 |
|    n_updates        | 8627     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.1     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.34     |
| time/               |          |
|    episodes         | 968      |
|    fps              | 890      |
|    time_elapsed     | 38       |
|    total_timesteps  | 34719    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.67e-07 |
|    n_updates        | 8654     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40       |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.338    |
| time/               |          |
|    episodes         | 972      |
|    fps              | 889      |
|    time_elapsed     | 39       |
|    total_timesteps  | 34852    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.21e-06 |
|    n_updates        | 8687     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.8     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.335    |
| time/               |          |
|    episodes         | 976      |
|    fps              | 888      |
|    time_elapsed     | 39       |
|    total_timesteps  | 35007    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.64e-07 |
|    n_updates        | 8726     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.7     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.333    |
| time/               |          |
|    episodes         | 980      |
|    fps              | 887      |
|    time_elapsed     | 39       |
|    total_timesteps  | 35119    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.3e-07  |
|    n_updates        | 8754     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.4     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.331    |
| time/               |          |
|    episodes         | 984      |
|    fps              | 886      |
|    time_elapsed     | 39       |
|    total_timesteps  | 35226    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.19e-07 |
|    n_updates        | 8781     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 38.9     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.328    |
| time/               |          |
|    episodes         | 988      |
|    fps              | 885      |
|    time_elapsed     | 39       |
|    total_timesteps  | 35370    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.64e-07 |
|    n_updates        | 8817     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.323    |
| time/               |          |
|    episodes         | 992      |
|    fps              | 884      |
|    time_elapsed     | 40       |
|    total_timesteps  | 35623    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.26e-07 |
|    n_updates        | 8880     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.1     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.319    |
| time/               |          |
|    episodes         | 996      |
|    fps              | 882      |
|    time_elapsed     | 40       |
|    total_timesteps  | 35821    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.68e-08 |
|    n_updates        | 8930     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.1     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.316    |
| time/               |          |
|    episodes         | 1000     |
|    fps              | 881      |
|    time_elapsed     | 40       |
|    total_timesteps  | 36020    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.67e-07 |
|    n_updates        | 8979     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.312    |
| time/               |          |
|    episodes         | 1004     |
|    fps              | 879      |
|    time_elapsed     | 41       |
|    total_timesteps  | 36229    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.76e-08 |
|    n_updates        | 9032     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.3     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.309    |
| time/               |          |
|    episodes         | 1008     |
|    fps              | 879      |
|    time_elapsed     | 41       |
|    total_timesteps  | 36354    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.67e-07 |
|    n_updates        | 9063     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.5     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.303    |
| time/               |          |
|    episodes         | 1012     |
|    fps              | 877      |
|    time_elapsed     | 41       |
|    total_timesteps  | 36678    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.43e-07 |
|    n_updates        | 9144     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.9     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.299    |
| time/               |          |
|    episodes         | 1016     |
|    fps              | 875      |
|    time_elapsed     | 42       |
|    total_timesteps  | 36890    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.38e-07 |
|    n_updates        | 9197     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.297    |
| time/               |          |
|    episodes         | 1020     |
|    fps              | 874      |
|    time_elapsed     | 42       |
|    total_timesteps  | 36981    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.11e-08 |
|    n_updates        | 9220     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.296    |
| time/               |          |
|    episodes         | 1024     |
|    fps              | 874      |
|    time_elapsed     | 42       |
|    total_timesteps  | 37052    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.46e-08 |
|    n_updates        | 9237     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.292    |
| time/               |          |
|    episodes         | 1028     |
|    fps              | 873      |
|    time_elapsed     | 42       |
|    total_timesteps  | 37253    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.29e-07 |
|    n_updates        | 9288     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.6     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.29     |
| time/               |          |
|    episodes         | 1032     |
|    fps              | 870      |
|    time_elapsed     | 42       |
|    total_timesteps  | 37374    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 9318     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.288    |
| time/               |          |
|    episodes         | 1036     |
|    fps              | 869      |
|    time_elapsed     | 43       |
|    total_timesteps  | 37474    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.91e-07 |
|    n_updates        | 9343     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.284    |
| time/               |          |
|    episodes         | 1040     |
|    fps              | 868      |
|    time_elapsed     | 43       |
|    total_timesteps  | 37710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.19e-07 |
|    n_updates        | 9402     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.7     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.28     |
| time/               |          |
|    episodes         | 1044     |
|    fps              | 866      |
|    time_elapsed     | 43       |
|    total_timesteps  | 37873    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.86e-07 |
|    n_updates        | 9443     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.277    |
| time/               |          |
|    episodes         | 1048     |
|    fps              | 866      |
|    time_elapsed     | 43       |
|    total_timesteps  | 38071    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.25e-07 |
|    n_updates        | 9492     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.3     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.275    |
| time/               |          |
|    episodes         | 1052     |
|    fps              | 865      |
|    time_elapsed     | 44       |
|    total_timesteps  | 38170    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.75e-07 |
|    n_updates        | 9517     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.272    |
| time/               |          |
|    episodes         | 1056     |
|    fps              | 865      |
|    time_elapsed     | 44       |
|    total_timesteps  | 38330    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.86e-07 |
|    n_updates        | 9557     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.2     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.27     |
| time/               |          |
|    episodes         | 1060     |
|    fps              | 864      |
|    time_elapsed     | 44       |
|    total_timesteps  | 38413    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.82e-07 |
|    n_updates        | 9578     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.267    |
| time/               |          |
|    episodes         | 1064     |
|    fps              | 863      |
|    time_elapsed     | 44       |
|    total_timesteps  | 38561    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.5e-08  |
|    n_updates        | 9615     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 39       |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.266    |
| time/               |          |
|    episodes         | 1068     |
|    fps              | 863      |
|    time_elapsed     | 44       |
|    total_timesteps  | 38624    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.28e-08 |
|    n_updates        | 9630     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.26     |
| time/               |          |
|    episodes         | 1072     |
|    fps              | 862      |
|    time_elapsed     | 45       |
|    total_timesteps  | 38936    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.72e-08 |
|    n_updates        | 9708     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.257    |
| time/               |          |
|    episodes         | 1076     |
|    fps              | 860      |
|    time_elapsed     | 45       |
|    total_timesteps  | 39131    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.14e-07 |
|    n_updates        | 9757     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.251    |
| time/               |          |
|    episodes         | 1080     |
|    fps              | 859      |
|    time_elapsed     | 45       |
|    total_timesteps  | 39440    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-06 |
|    n_updates        | 9834     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.5     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.246    |
| time/               |          |
|    episodes         | 1084     |
|    fps              | 857      |
|    time_elapsed     | 46       |
|    total_timesteps  | 39681    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.66e-07 |
|    n_updates        | 9895     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45.4     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.242    |
| time/               |          |
|    episodes         | 1088     |
|    fps              | 857      |
|    time_elapsed     | 46       |
|    total_timesteps  | 39907    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.31e-07 |
|    n_updates        | 9951     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.1     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.239    |
| time/               |          |
|    episodes         | 1092     |
|    fps              | 856      |
|    time_elapsed     | 46       |
|    total_timesteps  | 40033    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.06e-05 |
|    n_updates        | 9983     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43       |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.238    |
| time/               |          |
|    episodes         | 1096     |
|    fps              | 855      |
|    time_elapsed     | 46       |
|    total_timesteps  | 40125    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.26e-06 |
|    n_updates        | 10006    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 42.7     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.235    |
| time/               |          |
|    episodes         | 1100     |
|    fps              | 854      |
|    time_elapsed     | 47       |
|    total_timesteps  | 40287    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.33e-06 |
|    n_updates        | 10046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.6     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.233    |
| time/               |          |
|    episodes         | 1104     |
|    fps              | 854      |
|    time_elapsed     | 47       |
|    total_timesteps  | 40388    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000693 |
|    n_updates        | 10071    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 41.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.23     |
| time/               |          |
|    episodes         | 1108     |
|    fps              | 854      |
|    time_elapsed     | 47       |
|    total_timesteps  | 40543    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.55e-05 |
|    n_updates        | 10110    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.226    |
| time/               |          |
|    episodes         | 1112     |
|    fps              | 853      |
|    time_elapsed     | 47       |
|    total_timesteps  | 40714    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.53e-06 |
|    n_updates        | 10153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.223    |
| time/               |          |
|    episodes         | 1116     |
|    fps              | 853      |
|    time_elapsed     | 47       |
|    total_timesteps  | 40919    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-06 |
|    n_updates        | 10204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 40.2     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.221    |
| time/               |          |
|    episodes         | 1120     |
|    fps              | 852      |
|    time_elapsed     | 48       |
|    total_timesteps  | 41001    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-05  |
|    n_updates        | 10225    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 43.3     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.214    |
| time/               |          |
|    episodes         | 1124     |
|    fps              | 850      |
|    time_elapsed     | 48       |
|    total_timesteps  | 41379    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.36e-07 |
|    n_updates        | 10319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 44.4     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.208    |
| time/               |          |
|    episodes         | 1128     |
|    fps              | 849      |
|    time_elapsed     | 49       |
|    total_timesteps  | 41696    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-06 |
|    n_updates        | 10398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 45       |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.204    |
| time/               |          |
|    episodes         | 1132     |
|    fps              | 848      |
|    time_elapsed     | 49       |
|    total_timesteps  | 41875    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.3e-07  |
|    n_updates        | 10443    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 46.8     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.199    |
| time/               |          |
|    episodes         | 1136     |
|    fps              | 847      |
|    time_elapsed     | 49       |
|    total_timesteps  | 42151    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.05e-07 |
|    n_updates        | 10512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.9     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.193    |
| time/               |          |
|    episodes         | 1140     |
|    fps              | 846      |
|    time_elapsed     | 50       |
|    total_timesteps  | 42495    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-06 |
|    n_updates        | 10598    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.4     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.187    |
| time/               |          |
|    episodes         | 1144     |
|    fps              | 844      |
|    time_elapsed     | 50       |
|    total_timesteps  | 42809    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2e-06    |
|    n_updates        | 10677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.5     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.183    |
| time/               |          |
|    episodes         | 1148     |
|    fps              | 843      |
|    time_elapsed     | 51       |
|    total_timesteps  | 43023    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.7e-06  |
|    n_updates        | 10730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51.1     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.178    |
| time/               |          |
|    episodes         | 1152     |
|    fps              | 842      |
|    time_elapsed     | 51       |
|    total_timesteps  | 43283    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.95e-06 |
|    n_updates        | 10795    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51       |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.175    |
| time/               |          |
|    episodes         | 1156     |
|    fps              | 841      |
|    time_elapsed     | 51       |
|    total_timesteps  | 43428    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.98e-06 |
|    n_updates        | 10831    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.6     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.168    |
| time/               |          |
|    episodes         | 1160     |
|    fps              | 839      |
|    time_elapsed     | 52       |
|    total_timesteps  | 43773    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.79e-06 |
|    n_updates        | 10918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.162    |
| time/               |          |
|    episodes         | 1164     |
|    fps              | 838      |
|    time_elapsed     | 52       |
|    total_timesteps  | 44098    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.64e-07 |
|    n_updates        | 10999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.4     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.159    |
| time/               |          |
|    episodes         | 1168     |
|    fps              | 838      |
|    time_elapsed     | 52       |
|    total_timesteps  | 44265    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.05e-05 |
|    n_updates        | 11041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.152    |
| time/               |          |
|    episodes         | 1172     |
|    fps              | 836      |
|    time_elapsed     | 53       |
|    total_timesteps  | 44619    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.54e-06 |
|    n_updates        | 11129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.146    |
| time/               |          |
|    episodes         | 1176     |
|    fps              | 834      |
|    time_elapsed     | 53       |
|    total_timesteps  | 44943    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-06 |
|    n_updates        | 11210    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.138    |
| time/               |          |
|    episodes         | 1180     |
|    fps              | 834      |
|    time_elapsed     | 54       |
|    total_timesteps  | 45343    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-06  |
|    n_updates        | 11310    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.9     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.132    |
| time/               |          |
|    episodes         | 1184     |
|    fps              | 834      |
|    time_elapsed     | 54       |
|    total_timesteps  | 45666    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-05 |
|    n_updates        | 11391    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.125    |
| time/               |          |
|    episodes         | 1188     |
|    fps              | 832      |
|    time_elapsed     | 55       |
|    total_timesteps  | 46044    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.57e-06 |
|    n_updates        | 11485    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.12     |
| time/               |          |
|    episodes         | 1192     |
|    fps              | 831      |
|    time_elapsed     | 55       |
|    total_timesteps  | 46338    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-06 |
|    n_updates        | 11559    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.115    |
| time/               |          |
|    episodes         | 1196     |
|    fps              | 830      |
|    time_elapsed     | 56       |
|    total_timesteps  | 46599    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-06 |
|    n_updates        | 11624    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.109    |
| time/               |          |
|    episodes         | 1200     |
|    fps              | 829      |
|    time_elapsed     | 56       |
|    total_timesteps  | 46887    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-07 |
|    n_updates        | 11696    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.7     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.102    |
| time/               |          |
|    episodes         | 1204     |
|    fps              | 829      |
|    time_elapsed     | 56       |
|    total_timesteps  | 47257    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.85e-06 |
|    n_updates        | 11789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.0982   |
| time/               |          |
|    episodes         | 1208     |
|    fps              | 828      |
|    time_elapsed     | 57       |
|    total_timesteps  | 47461    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.14e-08 |
|    n_updates        | 11840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.0906   |
| time/               |          |
|    episodes         | 1212     |
|    fps              | 827      |
|    time_elapsed     | 57       |
|    total_timesteps  | 47861    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.94e-07 |
|    n_updates        | 11940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.084    |
| time/               |          |
|    episodes         | 1216     |
|    fps              | 826      |
|    time_elapsed     | 58       |
|    total_timesteps  | 48211    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.15e-08 |
|    n_updates        | 12027    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.0764   |
| time/               |          |
|    episodes         | 1220     |
|    fps              | 825      |
|    time_elapsed     | 58       |
|    total_timesteps  | 48611    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.36e-06 |
|    n_updates        | 12127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.0719   |
| time/               |          |
|    episodes         | 1224     |
|    fps              | 824      |
|    time_elapsed     | 59       |
|    total_timesteps  | 48846    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.67e-07 |
|    n_updates        | 12186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.0654   |
| time/               |          |
|    episodes         | 1228     |
|    fps              | 823      |
|    time_elapsed     | 59       |
|    total_timesteps  | 49187    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-07 |
|    n_updates        | 12271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.0604   |
| time/               |          |
|    episodes         | 1232     |
|    fps              | 822      |
|    time_elapsed     | 60       |
|    total_timesteps  | 49452    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.87e-07 |
|    n_updates        | 12337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.0546   |
| time/               |          |
|    episodes         | 1236     |
|    fps              | 822      |
|    time_elapsed     | 60       |
|    total_timesteps  | 49757    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.61e-05 |
|    n_updates        | 12414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1240     |
|    fps              | 821      |
|    time_elapsed     | 60       |
|    total_timesteps  | 50030    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.16e-05 |
|    n_updates        | 12482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1244     |
|    fps              | 821      |
|    time_elapsed     | 61       |
|    total_timesteps  | 50159    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.56e-06 |
|    n_updates        | 12514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1248     |
|    fps              | 821      |
|    time_elapsed     | 61       |
|    total_timesteps  | 50213    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.62e-05 |
|    n_updates        | 12528    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1252     |
|    fps              | 821      |
|    time_elapsed     | 61       |
|    total_timesteps  | 50382    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00429  |
|    n_updates        | 12570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1256     |
|    fps              | 820      |
|    time_elapsed     | 61       |
|    total_timesteps  | 50651    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.22e-06 |
|    n_updates        | 12637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1260     |
|    fps              | 820      |
|    time_elapsed     | 62       |
|    total_timesteps  | 50935    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.44e-06 |
|    n_updates        | 12708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1264     |
|    fps              | 819      |
|    time_elapsed     | 62       |
|    total_timesteps  | 51118    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00124  |
|    n_updates        | 12754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1268     |
|    fps              | 819      |
|    time_elapsed     | 62       |
|    total_timesteps  | 51258    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.75e-06 |
|    n_updates        | 12789    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1272     |
|    fps              | 819      |
|    time_elapsed     | 62       |
|    total_timesteps  | 51542    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.59e-06 |
|    n_updates        | 12860    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1276     |
|    fps              | 818      |
|    time_elapsed     | 63       |
|    total_timesteps  | 51662    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.41e-07 |
|    n_updates        | 12890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1280     |
|    fps              | 818      |
|    time_elapsed     | 63       |
|    total_timesteps  | 51840    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.33e-06 |
|    n_updates        | 12934    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1284     |
|    fps              | 817      |
|    time_elapsed     | 63       |
|    total_timesteps  | 52152    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.35e-06 |
|    n_updates        | 13012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.7     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1288     |
|    fps              | 816      |
|    time_elapsed     | 64       |
|    total_timesteps  | 52317    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.8e-06  |
|    n_updates        | 13054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1292     |
|    fps              | 816      |
|    time_elapsed     | 64       |
|    total_timesteps  | 52412    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00138  |
|    n_updates        | 13077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1296     |
|    fps              | 815      |
|    time_elapsed     | 64       |
|    total_timesteps  | 52475    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.27e-05 |
|    n_updates        | 13093    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.3     |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1300     |
|    fps              | 814      |
|    time_elapsed     | 64       |
|    total_timesteps  | 52715    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000193 |
|    n_updates        | 13153    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.5     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1304     |
|    fps              | 814      |
|    time_elapsed     | 64       |
|    total_timesteps  | 52806    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-05 |
|    n_updates        | 13176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57       |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1308     |
|    fps              | 812      |
|    time_elapsed     | 65       |
|    total_timesteps  | 53158    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00197  |
|    n_updates        | 13264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1312     |
|    fps              | 811      |
|    time_elapsed     | 65       |
|    total_timesteps  | 53431    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.11e-05 |
|    n_updates        | 13332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.7     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1316     |
|    fps              | 810      |
|    time_elapsed     | 66       |
|    total_timesteps  | 53680    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.83e-05 |
|    n_updates        | 13394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.2     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1320     |
|    fps              | 809      |
|    time_elapsed     | 66       |
|    total_timesteps  | 54034    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.93e-06 |
|    n_updates        | 13483    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.2     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1324     |
|    fps              | 808      |
|    time_elapsed     | 67       |
|    total_timesteps  | 54363    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.32e-06 |
|    n_updates        | 13565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.2     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1328     |
|    fps              | 807      |
|    time_elapsed     | 67       |
|    total_timesteps  | 54710    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.5e-06  |
|    n_updates        | 13652    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.6     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1332     |
|    fps              | 807      |
|    time_elapsed     | 68       |
|    total_timesteps  | 55009    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.88e-05 |
|    n_updates        | 13727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1336     |
|    fps              | 806      |
|    time_elapsed     | 68       |
|    total_timesteps  | 55374    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.72e-07 |
|    n_updates        | 13818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57       |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1340     |
|    fps              | 805      |
|    time_elapsed     | 69       |
|    total_timesteps  | 55725    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.54e-07 |
|    n_updates        | 13906    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1344     |
|    fps              | 804      |
|    time_elapsed     | 69       |
|    total_timesteps  | 56072    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000184 |
|    n_updates        | 13992    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1348     |
|    fps              | 803      |
|    time_elapsed     | 70       |
|    total_timesteps  | 56349    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.05e-06 |
|    n_updates        | 14062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62       |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1352     |
|    fps              | 802      |
|    time_elapsed     | 70       |
|    total_timesteps  | 56581    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 14120    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1356     |
|    fps              | 801      |
|    time_elapsed     | 71       |
|    total_timesteps  | 56911    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-06 |
|    n_updates        | 14202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.5     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1360     |
|    fps              | 798      |
|    time_elapsed     | 71       |
|    total_timesteps  | 57183    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.33e-05 |
|    n_updates        | 14270    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1364     |
|    fps              | 798      |
|    time_elapsed     | 72       |
|    total_timesteps  | 57515    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.79e-07 |
|    n_updates        | 14353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1368     |
|    fps              | 797      |
|    time_elapsed     | 72       |
|    total_timesteps  | 57755    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.84e-07 |
|    n_updates        | 14413    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1372     |
|    fps              | 796      |
|    time_elapsed     | 73       |
|    total_timesteps  | 58155    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.61e-07 |
|    n_updates        | 14513    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1376     |
|    fps              | 796      |
|    time_elapsed     | 73       |
|    total_timesteps  | 58546    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.9e-06  |
|    n_updates        | 14611    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1380     |
|    fps              | 794      |
|    time_elapsed     | 74       |
|    total_timesteps  | 58932    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.61e-06 |
|    n_updates        | 14707    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1384     |
|    fps              | 794      |
|    time_elapsed     | 74       |
|    total_timesteps  | 59119    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.22e-07 |
|    n_updates        | 14754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1388     |
|    fps              | 793      |
|    time_elapsed     | 74       |
|    total_timesteps  | 59400    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 14824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1392     |
|    fps              | 792      |
|    time_elapsed     | 75       |
|    total_timesteps  | 59713    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.91e-07 |
|    n_updates        | 14903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1396     |
|    fps              | 791      |
|    time_elapsed     | 75       |
|    total_timesteps  | 60051    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.15e-05 |
|    n_updates        | 14987    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1400     |
|    fps              | 790      |
|    time_elapsed     | 76       |
|    total_timesteps  | 60243    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00077  |
|    n_updates        | 15035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1404     |
|    fps              | 790      |
|    time_elapsed     | 76       |
|    total_timesteps  | 60300    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.64e-05 |
|    n_updates        | 15049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1408     |
|    fps              | 790      |
|    time_elapsed     | 76       |
|    total_timesteps  | 60460    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 15089    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1412     |
|    fps              | 789      |
|    time_elapsed     | 76       |
|    total_timesteps  | 60654    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000102 |
|    n_updates        | 15138    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.7     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1416     |
|    fps              | 788      |
|    time_elapsed     | 77       |
|    total_timesteps  | 60852    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-05  |
|    n_updates        | 15187    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.1     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1420     |
|    fps              | 788      |
|    time_elapsed     | 77       |
|    total_timesteps  | 60946    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.67e-05 |
|    n_updates        | 15211    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1424     |
|    fps              | 788      |
|    time_elapsed     | 77       |
|    total_timesteps  | 61136    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000334 |
|    n_updates        | 15258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1428     |
|    fps              | 787      |
|    time_elapsed     | 77       |
|    total_timesteps  | 61364    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.57e-05 |
|    n_updates        | 15315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1432     |
|    fps              | 787      |
|    time_elapsed     | 78       |
|    total_timesteps  | 61709    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000536 |
|    n_updates        | 15402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1436     |
|    fps              | 786      |
|    time_elapsed     | 78       |
|    total_timesteps  | 61955    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.85e-06 |
|    n_updates        | 15463    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1440     |
|    fps              | 785      |
|    time_elapsed     | 79       |
|    total_timesteps  | 62124    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.09e-06 |
|    n_updates        | 15505    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.8     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1444     |
|    fps              | 783      |
|    time_elapsed     | 79       |
|    total_timesteps  | 62350    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000124 |
|    n_updates        | 15562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1448     |
|    fps              | 781      |
|    time_elapsed     | 80       |
|    total_timesteps  | 62561    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.3e-05  |
|    n_updates        | 15615    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.7     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1452     |
|    fps              | 774      |
|    time_elapsed     | 81       |
|    total_timesteps  | 62752    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000224 |
|    n_updates        | 15662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.2     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1456     |
|    fps              | 773      |
|    time_elapsed     | 81       |
|    total_timesteps  | 62836    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.65e-06 |
|    n_updates        | 15683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.2     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1460     |
|    fps              | 773      |
|    time_elapsed     | 81       |
|    total_timesteps  | 63008    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.45e-06 |
|    n_updates        | 15726    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1464     |
|    fps              | 772      |
|    time_elapsed     | 81       |
|    total_timesteps  | 63319    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-06 |
|    n_updates        | 15804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1468     |
|    fps              | 771      |
|    time_elapsed     | 82       |
|    total_timesteps  | 63632    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000108 |
|    n_updates        | 15882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1472     |
|    fps              | 770      |
|    time_elapsed     | 83       |
|    total_timesteps  | 63953    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.47e-05 |
|    n_updates        | 15963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.3     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1476     |
|    fps              | 769      |
|    time_elapsed     | 83       |
|    total_timesteps  | 64176    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.93e-06 |
|    n_updates        | 16018    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55       |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1480     |
|    fps              | 769      |
|    time_elapsed     | 83       |
|    total_timesteps  | 64437    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 16084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.8     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1484     |
|    fps              | 768      |
|    time_elapsed     | 84       |
|    total_timesteps  | 64795    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.31e-05 |
|    n_updates        | 16173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1488     |
|    fps              | 768      |
|    time_elapsed     | 84       |
|    total_timesteps  | 65125    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-06  |
|    n_updates        | 16256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1492     |
|    fps              | 767      |
|    time_elapsed     | 85       |
|    total_timesteps  | 65432    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-06  |
|    n_updates        | 16332    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1496     |
|    fps              | 767      |
|    time_elapsed     | 85       |
|    total_timesteps  | 65703    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.03e-07 |
|    n_updates        | 16400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1500     |
|    fps              | 766      |
|    time_elapsed     | 86       |
|    total_timesteps  | 66056    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.3e-07  |
|    n_updates        | 16488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.9     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1504     |
|    fps              | 766      |
|    time_elapsed     | 86       |
|    total_timesteps  | 66293    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000339 |
|    n_updates        | 16548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1508     |
|    fps              | 765      |
|    time_elapsed     | 86       |
|    total_timesteps  | 66535    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000261 |
|    n_updates        | 16608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1512     |
|    fps              | 765      |
|    time_elapsed     | 87       |
|    total_timesteps  | 66703    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.26e-07 |
|    n_updates        | 16650    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1516     |
|    fps              | 765      |
|    time_elapsed     | 87       |
|    total_timesteps  | 66976    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-05 |
|    n_updates        | 16718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1520     |
|    fps              | 764      |
|    time_elapsed     | 88       |
|    total_timesteps  | 67376    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.95e-07 |
|    n_updates        | 16818    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1524     |
|    fps              | 764      |
|    time_elapsed     | 88       |
|    total_timesteps  | 67646    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-05 |
|    n_updates        | 16886    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1528     |
|    fps              | 763      |
|    time_elapsed     | 89       |
|    total_timesteps  | 67989    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 16972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1532     |
|    fps              | 763      |
|    time_elapsed     | 89       |
|    total_timesteps  | 68310    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.59e-07 |
|    n_updates        | 17052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.3     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1536     |
|    fps              | 762      |
|    time_elapsed     | 89       |
|    total_timesteps  | 68583    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-07 |
|    n_updates        | 17120    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1540     |
|    fps              | 762      |
|    time_elapsed     | 90       |
|    total_timesteps  | 68913    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.46e-07 |
|    n_updates        | 17203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1544     |
|    fps              | 762      |
|    time_elapsed     | 90       |
|    total_timesteps  | 69300    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.19e-06 |
|    n_updates        | 17299    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1548     |
|    fps              | 761      |
|    time_elapsed     | 91       |
|    total_timesteps  | 69561    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.17e-06 |
|    n_updates        | 17365    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1552     |
|    fps              | 761      |
|    time_elapsed     | 91       |
|    total_timesteps  | 69780    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.32e-05 |
|    n_updates        | 17419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1556     |
|    fps              | 761      |
|    time_elapsed     | 92       |
|    total_timesteps  | 70137    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.61e-05 |
|    n_updates        | 17509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1560     |
|    fps              | 760      |
|    time_elapsed     | 92       |
|    total_timesteps  | 70404    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.77e-05 |
|    n_updates        | 17575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1564     |
|    fps              | 760      |
|    time_elapsed     | 92       |
|    total_timesteps  | 70736    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.87e-06 |
|    n_updates        | 17658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1568     |
|    fps              | 760      |
|    time_elapsed     | 93       |
|    total_timesteps  | 71132    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.98e-06 |
|    n_updates        | 17757    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.9     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1572     |
|    fps              | 760      |
|    time_elapsed     | 93       |
|    total_timesteps  | 71441    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.44e-05 |
|    n_updates        | 17835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1576     |
|    fps              | 759      |
|    time_elapsed     | 94       |
|    total_timesteps  | 71841    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000243 |
|    n_updates        | 17935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1580     |
|    fps              | 759      |
|    time_elapsed     | 95       |
|    total_timesteps  | 72197    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000431 |
|    n_updates        | 18024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1584     |
|    fps              | 759      |
|    time_elapsed     | 95       |
|    total_timesteps  | 72518    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000554 |
|    n_updates        | 18104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1588     |
|    fps              | 759      |
|    time_elapsed     | 95       |
|    total_timesteps  | 72846    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000341 |
|    n_updates        | 18186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1592     |
|    fps              | 759      |
|    time_elapsed     | 96       |
|    total_timesteps  | 73100    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.9e-05  |
|    n_updates        | 18249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1596     |
|    fps              | 759      |
|    time_elapsed     | 96       |
|    total_timesteps  | 73405    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000131 |
|    n_updates        | 18326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1600     |
|    fps              | 759      |
|    time_elapsed     | 96       |
|    total_timesteps  | 73627    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-06 |
|    n_updates        | 18381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1604     |
|    fps              | 758      |
|    time_elapsed     | 97       |
|    total_timesteps  | 74027    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.72e-06 |
|    n_updates        | 18481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1608     |
|    fps              | 758      |
|    time_elapsed     | 98       |
|    total_timesteps  | 74417    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.37e-06 |
|    n_updates        | 18579    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1612     |
|    fps              | 758      |
|    time_elapsed     | 98       |
|    total_timesteps  | 74754    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.52e-05 |
|    n_updates        | 18663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1616     |
|    fps              | 758      |
|    time_elapsed     | 98       |
|    total_timesteps  | 74952    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-05 |
|    n_updates        | 18712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1620     |
|    fps              | 758      |
|    time_elapsed     | 99       |
|    total_timesteps  | 75097    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.53e-06 |
|    n_updates        | 18749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1624     |
|    fps              | 757      |
|    time_elapsed     | 99       |
|    total_timesteps  | 75388    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000583 |
|    n_updates        | 18821    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1628     |
|    fps              | 756      |
|    time_elapsed     | 99       |
|    total_timesteps  | 75694    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.85e-05 |
|    n_updates        | 18898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1632     |
|    fps              | 756      |
|    time_elapsed     | 100      |
|    total_timesteps  | 75933    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-05  |
|    n_updates        | 18958    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1636     |
|    fps              | 756      |
|    time_elapsed     | 100      |
|    total_timesteps  | 76163    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.89e-07 |
|    n_updates        | 19015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1640     |
|    fps              | 755      |
|    time_elapsed     | 101      |
|    total_timesteps  | 76549    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.15e-05 |
|    n_updates        | 19112    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1644     |
|    fps              | 755      |
|    time_elapsed     | 101      |
|    total_timesteps  | 76801    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.83e-05 |
|    n_updates        | 19175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1648     |
|    fps              | 755      |
|    time_elapsed     | 101      |
|    total_timesteps  | 77020    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.41e-06 |
|    n_updates        | 19229    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1652     |
|    fps              | 755      |
|    time_elapsed     | 102      |
|    total_timesteps  | 77163    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.42e-06 |
|    n_updates        | 19265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1656     |
|    fps              | 754      |
|    time_elapsed     | 102      |
|    total_timesteps  | 77366    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.66e-05 |
|    n_updates        | 19316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1660     |
|    fps              | 754      |
|    time_elapsed     | 102      |
|    total_timesteps  | 77669    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.62e-06 |
|    n_updates        | 19392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1664     |
|    fps              | 754      |
|    time_elapsed     | 103      |
|    total_timesteps  | 77855    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.23e-06 |
|    n_updates        | 19438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.9     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1668     |
|    fps              | 754      |
|    time_elapsed     | 103      |
|    total_timesteps  | 78023    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00167  |
|    n_updates        | 19480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1672     |
|    fps              | 754      |
|    time_elapsed     | 103      |
|    total_timesteps  | 78193    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.34e-06 |
|    n_updates        | 19523    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1676     |
|    fps              | 754      |
|    time_elapsed     | 103      |
|    total_timesteps  | 78383    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-06 |
|    n_updates        | 19570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1680     |
|    fps              | 754      |
|    time_elapsed     | 104      |
|    total_timesteps  | 78615    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.3e-06  |
|    n_updates        | 19628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1684     |
|    fps              | 754      |
|    time_elapsed     | 104      |
|    total_timesteps  | 78762    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.95e-05 |
|    n_updates        | 19665    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1688     |
|    fps              | 754      |
|    time_elapsed     | 104      |
|    total_timesteps  | 78892    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.49e-05 |
|    n_updates        | 19697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.9     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1692     |
|    fps              | 754      |
|    time_elapsed     | 104      |
|    total_timesteps  | 79187    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-06 |
|    n_updates        | 19771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1696     |
|    fps              | 754      |
|    time_elapsed     | 105      |
|    total_timesteps  | 79365    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.22e-06 |
|    n_updates        | 19816    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1700     |
|    fps              | 754      |
|    time_elapsed     | 105      |
|    total_timesteps  | 79504    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.45e-06 |
|    n_updates        | 19850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.4     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1704     |
|    fps              | 754      |
|    time_elapsed     | 105      |
|    total_timesteps  | 79770    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000438 |
|    n_updates        | 19917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1708     |
|    fps              | 754      |
|    time_elapsed     | 106      |
|    total_timesteps  | 80072    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00293  |
|    n_updates        | 19992    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.8     |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1712     |
|    fps              | 754      |
|    time_elapsed     | 106      |
|    total_timesteps  | 80233    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00206  |
|    n_updates        | 20033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.9     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1716     |
|    fps              | 754      |
|    time_elapsed     | 106      |
|    total_timesteps  | 80443    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00185  |
|    n_updates        | 20085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.7     |
|    ep_rew_mean      | 0.34     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1720     |
|    fps              | 754      |
|    time_elapsed     | 107      |
|    total_timesteps  | 80769    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000114 |
|    n_updates        | 20167    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.1     |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1724     |
|    fps              | 754      |
|    time_elapsed     | 107      |
|    total_timesteps  | 81096    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000283 |
|    n_updates        | 20248    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58       |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1728     |
|    fps              | 753      |
|    time_elapsed     | 108      |
|    total_timesteps  | 81496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.31e-05 |
|    n_updates        | 20348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.6     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1732     |
|    fps              | 752      |
|    time_elapsed     | 108      |
|    total_timesteps  | 81896    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000478 |
|    n_updates        | 20448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1736     |
|    fps              | 752      |
|    time_elapsed     | 109      |
|    total_timesteps  | 82296    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.39e-05 |
|    n_updates        | 20548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 0.27     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1740     |
|    fps              | 751      |
|    time_elapsed     | 109      |
|    total_timesteps  | 82696    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.41e-06 |
|    n_updates        | 20648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 0.27     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1744     |
|    fps              | 751      |
|    time_elapsed     | 110      |
|    total_timesteps  | 83096    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.15e-05 |
|    n_updates        | 20748    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1748     |
|    fps              | 750      |
|    time_elapsed     | 111      |
|    total_timesteps  | 83496    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.69e-05 |
|    n_updates        | 20848    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1752     |
|    fps              | 750      |
|    time_elapsed     | 111      |
|    total_timesteps  | 83896    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.63e-05 |
|    n_updates        | 20948    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1756     |
|    fps              | 750      |
|    time_elapsed     | 112      |
|    total_timesteps  | 84285    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.02e-05 |
|    n_updates        | 21046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1760     |
|    fps              | 750      |
|    time_elapsed     | 112      |
|    total_timesteps  | 84646    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.84e-06 |
|    n_updates        | 21136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1764     |
|    fps              | 748      |
|    time_elapsed     | 113      |
|    total_timesteps  | 85046    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.26e-06 |
|    n_updates        | 21236    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1768     |
|    fps              | 748      |
|    time_elapsed     | 114      |
|    total_timesteps  | 85446    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.94e-06 |
|    n_updates        | 21336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1772     |
|    fps              | 747      |
|    time_elapsed     | 114      |
|    total_timesteps  | 85846    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000159 |
|    n_updates        | 21436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.1     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1776     |
|    fps              | 747      |
|    time_elapsed     | 115      |
|    total_timesteps  | 86192    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000284 |
|    n_updates        | 21522    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1780     |
|    fps              | 747      |
|    time_elapsed     | 115      |
|    total_timesteps  | 86592    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.22e-06 |
|    n_updates        | 21622    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1784     |
|    fps              | 746      |
|    time_elapsed     | 116      |
|    total_timesteps  | 86992    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000139 |
|    n_updates        | 21722    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.1     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1788     |
|    fps              | 745      |
|    time_elapsed     | 117      |
|    total_timesteps  | 87304    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000525 |
|    n_updates        | 21800    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1792     |
|    fps              | 744      |
|    time_elapsed     | 117      |
|    total_timesteps  | 87704    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.43e-06 |
|    n_updates        | 21900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.9     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1796     |
|    fps              | 744      |
|    time_elapsed     | 118      |
|    total_timesteps  | 87954    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-06 |
|    n_updates        | 21963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.5     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1800     |
|    fps              | 743      |
|    time_elapsed     | 118      |
|    total_timesteps  | 88354    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000114 |
|    n_updates        | 22063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1804     |
|    fps              | 743      |
|    time_elapsed     | 119      |
|    total_timesteps  | 88732    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.52e-05 |
|    n_updates        | 22157    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1808     |
|    fps              | 742      |
|    time_elapsed     | 120      |
|    total_timesteps  | 89132    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.07e-06 |
|    n_updates        | 22257    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1812     |
|    fps              | 740      |
|    time_elapsed     | 120      |
|    total_timesteps  | 89532    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.37e-05 |
|    n_updates        | 22357    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1816     |
|    fps              | 740      |
|    time_elapsed     | 121      |
|    total_timesteps  | 89932    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-06 |
|    n_updates        | 22457    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1820     |
|    fps              | 740      |
|    time_elapsed     | 121      |
|    total_timesteps  | 90262    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000371 |
|    n_updates        | 22540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1824     |
|    fps              | 740      |
|    time_elapsed     | 122      |
|    total_timesteps  | 90662    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-05 |
|    n_updates        | 22640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1828     |
|    fps              | 739      |
|    time_elapsed     | 123      |
|    total_timesteps  | 91062    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000569 |
|    n_updates        | 22740    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1832     |
|    fps              | 739      |
|    time_elapsed     | 123      |
|    total_timesteps  | 91462    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000591 |
|    n_updates        | 22840    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1836     |
|    fps              | 738      |
|    time_elapsed     | 124      |
|    total_timesteps  | 91862    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000551 |
|    n_updates        | 22940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1840     |
|    fps              | 736      |
|    time_elapsed     | 125      |
|    total_timesteps  | 92262    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.99e-05 |
|    n_updates        | 23040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1844     |
|    fps              | 736      |
|    time_elapsed     | 125      |
|    total_timesteps  | 92662    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.95e-05 |
|    n_updates        | 23140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1848     |
|    fps              | 735      |
|    time_elapsed     | 126      |
|    total_timesteps  | 93041    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000266 |
|    n_updates        | 23235    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1852     |
|    fps              | 735      |
|    time_elapsed     | 127      |
|    total_timesteps  | 93441    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.26e-05 |
|    n_updates        | 23335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1856     |
|    fps              | 734      |
|    time_elapsed     | 127      |
|    total_timesteps  | 93841    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000132 |
|    n_updates        | 23435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1860     |
|    fps              | 733      |
|    time_elapsed     | 128      |
|    total_timesteps  | 94241    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.4e-06  |
|    n_updates        | 23535    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1864     |
|    fps              | 732      |
|    time_elapsed     | 129      |
|    total_timesteps  | 94556    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.11e-06 |
|    n_updates        | 23613    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1868     |
|    fps              | 732      |
|    time_elapsed     | 129      |
|    total_timesteps  | 94956    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.28e-06 |
|    n_updates        | 23713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1872     |
|    fps              | 732      |
|    time_elapsed     | 130      |
|    total_timesteps  | 95356    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 23813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1876     |
|    fps              | 731      |
|    time_elapsed     | 130      |
|    total_timesteps  | 95756    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.04e-06 |
|    n_updates        | 23913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1880     |
|    fps              | 731      |
|    time_elapsed     | 131      |
|    total_timesteps  | 96079    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-05 |
|    n_updates        | 23994    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1884     |
|    fps              | 731      |
|    time_elapsed     | 131      |
|    total_timesteps  | 96479    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.03e-06 |
|    n_updates        | 24094    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1888     |
|    fps              | 730      |
|    time_elapsed     | 132      |
|    total_timesteps  | 96814    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.52e-05 |
|    n_updates        | 24178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1892     |
|    fps              | 730      |
|    time_elapsed     | 133      |
|    total_timesteps  | 97156    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.42e-07 |
|    n_updates        | 24263    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1896     |
|    fps              | 729      |
|    time_elapsed     | 133      |
|    total_timesteps  | 97556    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.05e-06 |
|    n_updates        | 24363    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1900     |
|    fps              | 729      |
|    time_elapsed     | 134      |
|    total_timesteps  | 97900    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.3e-06  |
|    n_updates        | 24449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1904     |
|    fps              | 728      |
|    time_elapsed     | 134      |
|    total_timesteps  | 98238    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.63e-07 |
|    n_updates        | 24534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1908     |
|    fps              | 727      |
|    time_elapsed     | 135      |
|    total_timesteps  | 98638    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.55e-06 |
|    n_updates        | 24634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1912     |
|    fps              | 726      |
|    time_elapsed     | 136      |
|    total_timesteps  | 99038    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.9e-06  |
|    n_updates        | 24734    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1916     |
|    fps              | 726      |
|    time_elapsed     | 136      |
|    total_timesteps  | 99407    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000664 |
|    n_updates        | 24826    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1920     |
|    fps              | 726      |
|    time_elapsed     | 137      |
|    total_timesteps  | 99719    |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000106 |
|    n_updates        | 24904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1924     |
|    fps              | 725      |
|    time_elapsed     | 137      |
|    total_timesteps  | 100103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00164  |
|    n_updates        | 25000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1928     |
|    fps              | 724      |
|    time_elapsed     | 138      |
|    total_timesteps  | 100366   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000904 |
|    n_updates        | 25066    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1932     |
|    fps              | 724      |
|    time_elapsed     | 139      |
|    total_timesteps  | 100766   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000222 |
|    n_updates        | 25166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1936     |
|    fps              | 724      |
|    time_elapsed     | 139      |
|    total_timesteps  | 101166   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000364 |
|    n_updates        | 25266    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1940     |
|    fps              | 723      |
|    time_elapsed     | 140      |
|    total_timesteps  | 101566   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000309 |
|    n_updates        | 25366    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1944     |
|    fps              | 724      |
|    time_elapsed     | 140      |
|    total_timesteps  | 101838   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000201 |
|    n_updates        | 25434    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1948     |
|    fps              | 724      |
|    time_elapsed     | 141      |
|    total_timesteps  | 102238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000473 |
|    n_updates        | 25534    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1952     |
|    fps              | 724      |
|    time_elapsed     | 141      |
|    total_timesteps  | 102638   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.95e-06 |
|    n_updates        | 25634    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1956     |
|    fps              | 724      |
|    time_elapsed     | 142      |
|    total_timesteps  | 102967   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.45e-05 |
|    n_updates        | 25716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1960     |
|    fps              | 724      |
|    time_elapsed     | 142      |
|    total_timesteps  | 103297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-05 |
|    n_updates        | 25799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1964     |
|    fps              | 723      |
|    time_elapsed     | 143      |
|    total_timesteps  | 103697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.13e-05 |
|    n_updates        | 25899    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1968     |
|    fps              | 723      |
|    time_elapsed     | 143      |
|    total_timesteps  | 104097   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.9e-05  |
|    n_updates        | 25999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1972     |
|    fps              | 723      |
|    time_elapsed     | 144      |
|    total_timesteps  | 104428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00017  |
|    n_updates        | 26081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1976     |
|    fps              | 723      |
|    time_elapsed     | 144      |
|    total_timesteps  | 104828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.26e-05 |
|    n_updates        | 26181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1980     |
|    fps              | 723      |
|    time_elapsed     | 145      |
|    total_timesteps  | 105228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.85e-07 |
|    n_updates        | 26281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1984     |
|    fps              | 723      |
|    time_elapsed     | 146      |
|    total_timesteps  | 105628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000984 |
|    n_updates        | 26381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1988     |
|    fps              | 722      |
|    time_elapsed     | 146      |
|    total_timesteps  | 106028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.7e-06  |
|    n_updates        | 26481    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1992     |
|    fps              | 722      |
|    time_elapsed     | 147      |
|    total_timesteps  | 106428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.03e-07 |
|    n_updates        | 26581    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 1996     |
|    fps              | 722      |
|    time_elapsed     | 147      |
|    total_timesteps  | 106828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.65e-06 |
|    n_updates        | 26681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2000     |
|    fps              | 722      |
|    time_elapsed     | 148      |
|    total_timesteps  | 107228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-05 |
|    n_updates        | 26781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2004     |
|    fps              | 722      |
|    time_elapsed     | 149      |
|    total_timesteps  | 107628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00563  |
|    n_updates        | 26881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2008     |
|    fps              | 722      |
|    time_elapsed     | 149      |
|    total_timesteps  | 108028   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 26981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2012     |
|    fps              | 722      |
|    time_elapsed     | 150      |
|    total_timesteps  | 108428   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.81e-06 |
|    n_updates        | 27081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2016     |
|    fps              | 722      |
|    time_elapsed     | 150      |
|    total_timesteps  | 108828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.42e-07 |
|    n_updates        | 27181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2020     |
|    fps              | 722      |
|    time_elapsed     | 151      |
|    total_timesteps  | 109228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-06 |
|    n_updates        | 27281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2024     |
|    fps              | 722      |
|    time_elapsed     | 151      |
|    total_timesteps  | 109628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.64e-07 |
|    n_updates        | 27381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2028     |
|    fps              | 722      |
|    time_elapsed     | 152      |
|    total_timesteps  | 109933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.27e-06 |
|    n_updates        | 27458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2032     |
|    fps              | 722      |
|    time_elapsed     | 152      |
|    total_timesteps  | 110333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00246  |
|    n_updates        | 27558    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2036     |
|    fps              | 722      |
|    time_elapsed     | 153      |
|    total_timesteps  | 110733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000253 |
|    n_updates        | 27658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2040     |
|    fps              | 722      |
|    time_elapsed     | 153      |
|    total_timesteps  | 111133   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000304 |
|    n_updates        | 27758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2044     |
|    fps              | 722      |
|    time_elapsed     | 154      |
|    total_timesteps  | 111470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000527 |
|    n_updates        | 27842    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2048     |
|    fps              | 722      |
|    time_elapsed     | 154      |
|    total_timesteps  | 111865   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.59e-05 |
|    n_updates        | 27941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2052     |
|    fps              | 722      |
|    time_elapsed     | 155      |
|    total_timesteps  | 112265   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.54e-05 |
|    n_updates        | 28041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2056     |
|    fps              | 722      |
|    time_elapsed     | 155      |
|    total_timesteps  | 112505   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-06 |
|    n_updates        | 28101    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2060     |
|    fps              | 722      |
|    time_elapsed     | 156      |
|    total_timesteps  | 112738   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-05 |
|    n_updates        | 28159    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2064     |
|    fps              | 722      |
|    time_elapsed     | 156      |
|    total_timesteps  | 113082   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.04e-05 |
|    n_updates        | 28245    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2068     |
|    fps              | 722      |
|    time_elapsed     | 156      |
|    total_timesteps  | 113378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.2e-05  |
|    n_updates        | 28319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2072     |
|    fps              | 722      |
|    time_elapsed     | 157      |
|    total_timesteps  | 113718   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-05 |
|    n_updates        | 28404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2076     |
|    fps              | 722      |
|    time_elapsed     | 157      |
|    total_timesteps  | 114034   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.1e-06  |
|    n_updates        | 28483    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2080     |
|    fps              | 722      |
|    time_elapsed     | 158      |
|    total_timesteps  | 114416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.83e-06 |
|    n_updates        | 28578    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2084     |
|    fps              | 722      |
|    time_elapsed     | 158      |
|    total_timesteps  | 114782   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.11e-06 |
|    n_updates        | 28670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2088     |
|    fps              | 722      |
|    time_elapsed     | 159      |
|    total_timesteps  | 115077   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 28744    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2092     |
|    fps              | 722      |
|    time_elapsed     | 159      |
|    total_timesteps  | 115442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.96e-05 |
|    n_updates        | 28835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2096     |
|    fps              | 721      |
|    time_elapsed     | 160      |
|    total_timesteps  | 115686   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.68e-05 |
|    n_updates        | 28896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2100     |
|    fps              | 721      |
|    time_elapsed     | 160      |
|    total_timesteps  | 115958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.34e-06 |
|    n_updates        | 28964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2104     |
|    fps              | 721      |
|    time_elapsed     | 161      |
|    total_timesteps  | 116349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.28e-06 |
|    n_updates        | 29062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2108     |
|    fps              | 720      |
|    time_elapsed     | 161      |
|    total_timesteps  | 116680   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.1e-07  |
|    n_updates        | 29144    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2112     |
|    fps              | 720      |
|    time_elapsed     | 162      |
|    total_timesteps  | 117049   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.34e-07 |
|    n_updates        | 29237    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2116     |
|    fps              | 719      |
|    time_elapsed     | 162      |
|    total_timesteps  | 117264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.25e-06 |
|    n_updates        | 29290    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2120     |
|    fps              | 719      |
|    time_elapsed     | 163      |
|    total_timesteps  | 117528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.04e-06 |
|    n_updates        | 29356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2124     |
|    fps              | 718      |
|    time_elapsed     | 163      |
|    total_timesteps  | 117821   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-06 |
|    n_updates        | 29430    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2128     |
|    fps              | 718      |
|    time_elapsed     | 164      |
|    total_timesteps  | 118042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.47e-06 |
|    n_updates        | 29485    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2132     |
|    fps              | 718      |
|    time_elapsed     | 164      |
|    total_timesteps  | 118285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.95e-06 |
|    n_updates        | 29546    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2136     |
|    fps              | 718      |
|    time_elapsed     | 165      |
|    total_timesteps  | 118685   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000142 |
|    n_updates        | 29646    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2140     |
|    fps              | 717      |
|    time_elapsed     | 165      |
|    total_timesteps  | 118936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.78e-07 |
|    n_updates        | 29708    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2144     |
|    fps              | 717      |
|    time_elapsed     | 166      |
|    total_timesteps  | 119136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.42e-07 |
|    n_updates        | 29758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2148     |
|    fps              | 717      |
|    time_elapsed     | 166      |
|    total_timesteps  | 119372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-07 |
|    n_updates        | 29817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2152     |
|    fps              | 717      |
|    time_elapsed     | 166      |
|    total_timesteps  | 119612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.6e-06  |
|    n_updates        | 29877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2156     |
|    fps              | 716      |
|    time_elapsed     | 167      |
|    total_timesteps  | 119926   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.46e-07 |
|    n_updates        | 29956    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2160     |
|    fps              | 716      |
|    time_elapsed     | 167      |
|    total_timesteps  | 120326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00141  |
|    n_updates        | 30056    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2164     |
|    fps              | 716      |
|    time_elapsed     | 168      |
|    total_timesteps  | 120662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000355 |
|    n_updates        | 30140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2168     |
|    fps              | 716      |
|    time_elapsed     | 168      |
|    total_timesteps  | 121062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00019  |
|    n_updates        | 30240    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2172     |
|    fps              | 716      |
|    time_elapsed     | 169      |
|    total_timesteps  | 121383   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000134 |
|    n_updates        | 30320    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2176     |
|    fps              | 716      |
|    time_elapsed     | 169      |
|    total_timesteps  | 121711   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00011  |
|    n_updates        | 30402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2180     |
|    fps              | 716      |
|    time_elapsed     | 170      |
|    total_timesteps  | 121960   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.44e-05 |
|    n_updates        | 30464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2184     |
|    fps              | 716      |
|    time_elapsed     | 170      |
|    total_timesteps  | 122281   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.45e-05 |
|    n_updates        | 30545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2188     |
|    fps              | 716      |
|    time_elapsed     | 170      |
|    total_timesteps  | 122551   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-05 |
|    n_updates        | 30612    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2192     |
|    fps              | 716      |
|    time_elapsed     | 171      |
|    total_timesteps  | 122826   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.7e-05  |
|    n_updates        | 30681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2196     |
|    fps              | 716      |
|    time_elapsed     | 171      |
|    total_timesteps  | 123032   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.25e-05 |
|    n_updates        | 30732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2200     |
|    fps              | 716      |
|    time_elapsed     | 172      |
|    total_timesteps  | 123432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-05  |
|    n_updates        | 30832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2204     |
|    fps              | 716      |
|    time_elapsed     | 172      |
|    total_timesteps  | 123748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.05e-06 |
|    n_updates        | 30911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2208     |
|    fps              | 716      |
|    time_elapsed     | 172      |
|    total_timesteps  | 123967   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.28e-05 |
|    n_updates        | 30966    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2212     |
|    fps              | 716      |
|    time_elapsed     | 173      |
|    total_timesteps  | 124337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-06 |
|    n_updates        | 31059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2216     |
|    fps              | 716      |
|    time_elapsed     | 174      |
|    total_timesteps  | 124693   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000124 |
|    n_updates        | 31148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2220     |
|    fps              | 716      |
|    time_elapsed     | 174      |
|    total_timesteps  | 125025   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0171   |
|    n_updates        | 31231    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2224     |
|    fps              | 715      |
|    time_elapsed     | 175      |
|    total_timesteps  | 125378   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.41e-07 |
|    n_updates        | 31319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2228     |
|    fps              | 715      |
|    time_elapsed     | 175      |
|    total_timesteps  | 125778   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-07 |
|    n_updates        | 31419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2232     |
|    fps              | 713      |
|    time_elapsed     | 176      |
|    total_timesteps  | 126170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.43e-06 |
|    n_updates        | 31517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2236     |
|    fps              | 713      |
|    time_elapsed     | 177      |
|    total_timesteps  | 126554   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-06 |
|    n_updates        | 31613    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2240     |
|    fps              | 712      |
|    time_elapsed     | 177      |
|    total_timesteps  | 126881   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.31e-07 |
|    n_updates        | 31695    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2244     |
|    fps              | 712      |
|    time_elapsed     | 178      |
|    total_timesteps  | 127216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.68e-07 |
|    n_updates        | 31778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2248     |
|    fps              | 712      |
|    time_elapsed     | 179      |
|    total_timesteps  | 127608   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-06  |
|    n_updates        | 31876    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.7     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2252     |
|    fps              | 712      |
|    time_elapsed     | 179      |
|    total_timesteps  | 127977   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.28e-07 |
|    n_updates        | 31969    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2256     |
|    fps              | 712      |
|    time_elapsed     | 180      |
|    total_timesteps  | 128371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.87e-06 |
|    n_updates        | 32067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2260     |
|    fps              | 711      |
|    time_elapsed     | 180      |
|    total_timesteps  | 128746   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-05 |
|    n_updates        | 32161    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2264     |
|    fps              | 711      |
|    time_elapsed     | 181      |
|    total_timesteps  | 129115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-07 |
|    n_updates        | 32253    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84       |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2268     |
|    fps              | 711      |
|    time_elapsed     | 182      |
|    total_timesteps  | 129462   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.3e-07  |
|    n_updates        | 32340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.8     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2272     |
|    fps              | 710      |
|    time_elapsed     | 182      |
|    total_timesteps  | 129862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.95e-06 |
|    n_updates        | 32440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2276     |
|    fps              | 709      |
|    time_elapsed     | 183      |
|    total_timesteps  | 130127   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00795  |
|    n_updates        | 32506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84       |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2280     |
|    fps              | 709      |
|    time_elapsed     | 183      |
|    total_timesteps  | 130361   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00145  |
|    n_updates        | 32565    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.1     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2284     |
|    fps              | 709      |
|    time_elapsed     | 184      |
|    total_timesteps  | 130689   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00112  |
|    n_updates        | 32647    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2288     |
|    fps              | 709      |
|    time_elapsed     | 184      |
|    total_timesteps  | 131073   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.23e-05 |
|    n_updates        | 32743    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.7     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2292     |
|    fps              | 709      |
|    time_elapsed     | 185      |
|    total_timesteps  | 131397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000183 |
|    n_updates        | 32824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2296     |
|    fps              | 708      |
|    time_elapsed     | 185      |
|    total_timesteps  | 131714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.56e-05 |
|    n_updates        | 32903    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.8     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2300     |
|    fps              | 707      |
|    time_elapsed     | 186      |
|    total_timesteps  | 132011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-06 |
|    n_updates        | 32977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2304     |
|    fps              | 707      |
|    time_elapsed     | 186      |
|    total_timesteps  | 132238   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.88e-06 |
|    n_updates        | 33034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.9     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2308     |
|    fps              | 707      |
|    time_elapsed     | 187      |
|    total_timesteps  | 132553   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.07e-06 |
|    n_updates        | 33113    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2312     |
|    fps              | 707      |
|    time_elapsed     | 187      |
|    total_timesteps  | 132914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.47e-05 |
|    n_updates        | 33203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2316     |
|    fps              | 707      |
|    time_elapsed     | 188      |
|    total_timesteps  | 133225   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.93e-06 |
|    n_updates        | 33281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.4     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2320     |
|    fps              | 707      |
|    time_elapsed     | 188      |
|    total_timesteps  | 133569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-05 |
|    n_updates        | 33367    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.1     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2324     |
|    fps              | 707      |
|    time_elapsed     | 189      |
|    total_timesteps  | 133887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.77e-06 |
|    n_updates        | 33446    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2328     |
|    fps              | 707      |
|    time_elapsed     | 189      |
|    total_timesteps  | 134113   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.21e-05 |
|    n_updates        | 33503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2332     |
|    fps              | 707      |
|    time_elapsed     | 190      |
|    total_timesteps  | 134464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.58e-07 |
|    n_updates        | 33590    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2336     |
|    fps              | 707      |
|    time_elapsed     | 190      |
|    total_timesteps  | 134815   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.87e-07 |
|    n_updates        | 33678    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2340     |
|    fps              | 706      |
|    time_elapsed     | 191      |
|    total_timesteps  | 135203   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.31e-07 |
|    n_updates        | 33775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2344     |
|    fps              | 706      |
|    time_elapsed     | 191      |
|    total_timesteps  | 135532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.51e-08 |
|    n_updates        | 33857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2348     |
|    fps              | 705      |
|    time_elapsed     | 192      |
|    total_timesteps  | 135890   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.43e-06 |
|    n_updates        | 33947    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2352     |
|    fps              | 705      |
|    time_elapsed     | 192      |
|    total_timesteps  | 136240   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.39e-07 |
|    n_updates        | 34034    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2356     |
|    fps              | 705      |
|    time_elapsed     | 193      |
|    total_timesteps  | 136547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.18e-06 |
|    n_updates        | 34111    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2360     |
|    fps              | 705      |
|    time_elapsed     | 193      |
|    total_timesteps  | 136767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.43e-06 |
|    n_updates        | 34166    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2364     |
|    fps              | 705      |
|    time_elapsed     | 194      |
|    total_timesteps  | 136936   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.73e-07 |
|    n_updates        | 34208    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2368     |
|    fps              | 705      |
|    time_elapsed     | 194      |
|    total_timesteps  | 137251   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.83e-07 |
|    n_updates        | 34287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2372     |
|    fps              | 705      |
|    time_elapsed     | 195      |
|    total_timesteps  | 137570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.72e-06 |
|    n_updates        | 34367    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2376     |
|    fps              | 705      |
|    time_elapsed     | 195      |
|    total_timesteps  | 137854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.86e-06 |
|    n_updates        | 34438    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.5     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2380     |
|    fps              | 705      |
|    time_elapsed     | 195      |
|    total_timesteps  | 138112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.19e-06 |
|    n_updates        | 34502    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2384     |
|    fps              | 705      |
|    time_elapsed     | 195      |
|    total_timesteps  | 138264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.06e-07 |
|    n_updates        | 34540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.9     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2388     |
|    fps              | 705      |
|    time_elapsed     | 196      |
|    total_timesteps  | 138664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.87e-08 |
|    n_updates        | 34640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2392     |
|    fps              | 705      |
|    time_elapsed     | 197      |
|    total_timesteps  | 138951   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.23e-07 |
|    n_updates        | 34712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2396     |
|    fps              | 705      |
|    time_elapsed     | 197      |
|    total_timesteps  | 139310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.11e-06 |
|    n_updates        | 34802    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2400     |
|    fps              | 705      |
|    time_elapsed     | 198      |
|    total_timesteps  | 139654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-06 |
|    n_updates        | 34888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2404     |
|    fps              | 705      |
|    time_elapsed     | 198      |
|    total_timesteps  | 139964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.19e-07 |
|    n_updates        | 34965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2408     |
|    fps              | 705      |
|    time_elapsed     | 198      |
|    total_timesteps  | 140228   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00175  |
|    n_updates        | 35031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2412     |
|    fps              | 705      |
|    time_elapsed     | 199      |
|    total_timesteps  | 140434   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000388 |
|    n_updates        | 35083    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2416     |
|    fps              | 705      |
|    time_elapsed     | 199      |
|    total_timesteps  | 140667   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00026  |
|    n_updates        | 35141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2420     |
|    fps              | 704      |
|    time_elapsed     | 199      |
|    total_timesteps  | 140915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000111 |
|    n_updates        | 35203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2424     |
|    fps              | 704      |
|    time_elapsed     | 200      |
|    total_timesteps  | 141065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000125 |
|    n_updates        | 35241    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2428     |
|    fps              | 704      |
|    time_elapsed     | 200      |
|    total_timesteps  | 141355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.88e-05 |
|    n_updates        | 35313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2432     |
|    fps              | 704      |
|    time_elapsed     | 201      |
|    total_timesteps  | 141710   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.71e-06 |
|    n_updates        | 35402    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2436     |
|    fps              | 704      |
|    time_elapsed     | 201      |
|    total_timesteps  | 141950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-05  |
|    n_updates        | 35462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2440     |
|    fps              | 704      |
|    time_elapsed     | 201      |
|    total_timesteps  | 142296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.17e-05 |
|    n_updates        | 35548    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2444     |
|    fps              | 704      |
|    time_elapsed     | 202      |
|    total_timesteps  | 142537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.67e-05 |
|    n_updates        | 35609    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2448     |
|    fps              | 704      |
|    time_elapsed     | 202      |
|    total_timesteps  | 142890   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.35e-07 |
|    n_updates        | 35697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.4     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2452     |
|    fps              | 704      |
|    time_elapsed     | 203      |
|    total_timesteps  | 143183   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.31e-05 |
|    n_updates        | 35770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2456     |
|    fps              | 704      |
|    time_elapsed     | 203      |
|    total_timesteps  | 143444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.57e-07 |
|    n_updates        | 35835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2460     |
|    fps              | 704      |
|    time_elapsed     | 204      |
|    total_timesteps  | 143765   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.85e-06 |
|    n_updates        | 35916    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2464     |
|    fps              | 704      |
|    time_elapsed     | 204      |
|    total_timesteps  | 144029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.15e-07 |
|    n_updates        | 35982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2468     |
|    fps              | 704      |
|    time_elapsed     | 204      |
|    total_timesteps  | 144429   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-06  |
|    n_updates        | 36082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2472     |
|    fps              | 704      |
|    time_elapsed     | 205      |
|    total_timesteps  | 144542   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.56e-07 |
|    n_updates        | 36110    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2476     |
|    fps              | 704      |
|    time_elapsed     | 205      |
|    total_timesteps  | 144802   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.75e-06 |
|    n_updates        | 36175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2480     |
|    fps              | 704      |
|    time_elapsed     | 206      |
|    total_timesteps  | 145177   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.87e-07 |
|    n_updates        | 36269    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2484     |
|    fps              | 704      |
|    time_elapsed     | 206      |
|    total_timesteps  | 145420   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.08e-07 |
|    n_updates        | 36329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2488     |
|    fps              | 704      |
|    time_elapsed     | 206      |
|    total_timesteps  | 145626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.72e-08 |
|    n_updates        | 36381    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2492     |
|    fps              | 704      |
|    time_elapsed     | 207      |
|    total_timesteps  | 145992   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.77e-07 |
|    n_updates        | 36472    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2496     |
|    fps              | 703      |
|    time_elapsed     | 207      |
|    total_timesteps  | 146291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-07 |
|    n_updates        | 36547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2500     |
|    fps              | 703      |
|    time_elapsed     | 208      |
|    total_timesteps  | 146605   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.45e-06 |
|    n_updates        | 36626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2504     |
|    fps              | 703      |
|    time_elapsed     | 208      |
|    total_timesteps  | 146870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.92e-07 |
|    n_updates        | 36692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2508     |
|    fps              | 703      |
|    time_elapsed     | 209      |
|    total_timesteps  | 147216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.34e-07 |
|    n_updates        | 36778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2512     |
|    fps              | 703      |
|    time_elapsed     | 209      |
|    total_timesteps  | 147586   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.74e-06 |
|    n_updates        | 36871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2516     |
|    fps              | 703      |
|    time_elapsed     | 210      |
|    total_timesteps  | 147819   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.83e-07 |
|    n_updates        | 36929    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2520     |
|    fps              | 703      |
|    time_elapsed     | 210      |
|    total_timesteps  | 148130   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.32e-07 |
|    n_updates        | 37007    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2524     |
|    fps              | 703      |
|    time_elapsed     | 210      |
|    total_timesteps  | 148294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.23e-05 |
|    n_updates        | 37048    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2528     |
|    fps              | 703      |
|    time_elapsed     | 211      |
|    total_timesteps  | 148601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3e-08    |
|    n_updates        | 37125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2532     |
|    fps              | 703      |
|    time_elapsed     | 211      |
|    total_timesteps  | 148916   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-07 |
|    n_updates        | 37203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2536     |
|    fps              | 703      |
|    time_elapsed     | 212      |
|    total_timesteps  | 149169   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.81e-08 |
|    n_updates        | 37267    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2540     |
|    fps              | 703      |
|    time_elapsed     | 212      |
|    total_timesteps  | 149493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-07 |
|    n_updates        | 37348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2544     |
|    fps              | 703      |
|    time_elapsed     | 212      |
|    total_timesteps  | 149828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.44e-06 |
|    n_updates        | 37431    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2548     |
|    fps              | 703      |
|    time_elapsed     | 213      |
|    total_timesteps  | 150202   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00113  |
|    n_updates        | 37525    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2552     |
|    fps              | 703      |
|    time_elapsed     | 214      |
|    total_timesteps  | 150602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000175 |
|    n_updates        | 37625    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2556     |
|    fps              | 703      |
|    time_elapsed     | 214      |
|    total_timesteps  | 150873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000279 |
|    n_updates        | 37693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2560     |
|    fps              | 703      |
|    time_elapsed     | 214      |
|    total_timesteps  | 151210   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.33e-05 |
|    n_updates        | 37777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2564     |
|    fps              | 703      |
|    time_elapsed     | 215      |
|    total_timesteps  | 151531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.15e-05 |
|    n_updates        | 37857    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2568     |
|    fps              | 703      |
|    time_elapsed     | 215      |
|    total_timesteps  | 151867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.18e-06 |
|    n_updates        | 37941    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2572     |
|    fps              | 703      |
|    time_elapsed     | 216      |
|    total_timesteps  | 152267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.74e-06 |
|    n_updates        | 38041    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.1     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2576     |
|    fps              | 703      |
|    time_elapsed     | 216      |
|    total_timesteps  | 152609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.47e-07 |
|    n_updates        | 38127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2580     |
|    fps              | 703      |
|    time_elapsed     | 217      |
|    total_timesteps  | 152934   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.41e-07 |
|    n_updates        | 38208    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.8     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2584     |
|    fps              | 703      |
|    time_elapsed     | 217      |
|    total_timesteps  | 153296   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.43e-07 |
|    n_updates        | 38298    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.3     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2588     |
|    fps              | 703      |
|    time_elapsed     | 218      |
|    total_timesteps  | 153654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-06 |
|    n_updates        | 38388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2592     |
|    fps              | 703      |
|    time_elapsed     | 219      |
|    total_timesteps  | 154054   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.47e-08 |
|    n_updates        | 38488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.6     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2596     |
|    fps              | 702      |
|    time_elapsed     | 219      |
|    total_timesteps  | 154454   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.51e-07 |
|    n_updates        | 38588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2600     |
|    fps              | 702      |
|    time_elapsed     | 220      |
|    total_timesteps  | 154822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.97e-07 |
|    n_updates        | 38680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2604     |
|    fps              | 702      |
|    time_elapsed     | 220      |
|    total_timesteps  | 155106   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.39e-07 |
|    n_updates        | 38751    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2608     |
|    fps              | 702      |
|    time_elapsed     | 221      |
|    total_timesteps  | 155487   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-05 |
|    n_updates        | 38846    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2612     |
|    fps              | 702      |
|    time_elapsed     | 221      |
|    total_timesteps  | 155852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00159  |
|    n_updates        | 38937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.3     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2616     |
|    fps              | 702      |
|    time_elapsed     | 222      |
|    total_timesteps  | 156252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-07 |
|    n_updates        | 39037    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2620     |
|    fps              | 702      |
|    time_elapsed     | 223      |
|    total_timesteps  | 156649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.5e-07  |
|    n_updates        | 39137    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.5     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2624     |
|    fps              | 701      |
|    time_elapsed     | 223      |
|    total_timesteps  | 157049   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.57e-07 |
|    n_updates        | 39237    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.3     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2628     |
|    fps              | 701      |
|    time_elapsed     | 224      |
|    total_timesteps  | 157327   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.19e-06 |
|    n_updates        | 39306    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.4     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2632     |
|    fps              | 701      |
|    time_elapsed     | 224      |
|    total_timesteps  | 157654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.47e-07 |
|    n_updates        | 39388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2636     |
|    fps              | 702      |
|    time_elapsed     | 225      |
|    total_timesteps  | 158054   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.32e-07 |
|    n_updates        | 39488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2640     |
|    fps              | 702      |
|    time_elapsed     | 225      |
|    total_timesteps  | 158454   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.12e-07 |
|    n_updates        | 39588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.3     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2644     |
|    fps              | 702      |
|    time_elapsed     | 226      |
|    total_timesteps  | 158854   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.06e-06 |
|    n_updates        | 39688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2648     |
|    fps              | 702      |
|    time_elapsed     | 226      |
|    total_timesteps  | 159254   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.53e-07 |
|    n_updates        | 39788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2652     |
|    fps              | 702      |
|    time_elapsed     | 227      |
|    total_timesteps  | 159654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.06e-05 |
|    n_updates        | 39888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2656     |
|    fps              | 702      |
|    time_elapsed     | 227      |
|    total_timesteps  | 160054   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00217  |
|    n_updates        | 39988    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.3     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2660     |
|    fps              | 702      |
|    time_elapsed     | 228      |
|    total_timesteps  | 160441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000288 |
|    n_updates        | 40085    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2664     |
|    fps              | 702      |
|    time_elapsed     | 229      |
|    total_timesteps  | 160841   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-05 |
|    n_updates        | 40185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2668     |
|    fps              | 702      |
|    time_elapsed     | 229      |
|    total_timesteps  | 161226   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.29e-05 |
|    n_updates        | 40281    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.2     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2672     |
|    fps              | 702      |
|    time_elapsed     | 229      |
|    total_timesteps  | 161490   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.21e-05 |
|    n_updates        | 40347    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2676     |
|    fps              | 702      |
|    time_elapsed     | 230      |
|    total_timesteps  | 161773   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.75e-05 |
|    n_updates        | 40418    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2680     |
|    fps              | 702      |
|    time_elapsed     | 230      |
|    total_timesteps  | 162128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.41e-07 |
|    n_updates        | 40506    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2684     |
|    fps              | 702      |
|    time_elapsed     | 231      |
|    total_timesteps  | 162327   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.7e-06  |
|    n_updates        | 40556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.7     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2688     |
|    fps              | 702      |
|    time_elapsed     | 231      |
|    total_timesteps  | 162628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.29e-07 |
|    n_updates        | 40631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2692     |
|    fps              | 702      |
|    time_elapsed     | 231      |
|    total_timesteps  | 162899   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.68e-07 |
|    n_updates        | 40699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.9     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2696     |
|    fps              | 702      |
|    time_elapsed     | 232      |
|    total_timesteps  | 163143   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.56e-07 |
|    n_updates        | 40760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2700     |
|    fps              | 702      |
|    time_elapsed     | 232      |
|    total_timesteps  | 163403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.14e-06 |
|    n_updates        | 40825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.6     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2704     |
|    fps              | 702      |
|    time_elapsed     | 233      |
|    total_timesteps  | 163662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.73e-06 |
|    n_updates        | 40890    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.7     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2708     |
|    fps              | 702      |
|    time_elapsed     | 233      |
|    total_timesteps  | 163954   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.07e-05 |
|    n_updates        | 40963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2712     |
|    fps              | 702      |
|    time_elapsed     | 233      |
|    total_timesteps  | 164300   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.87e-08 |
|    n_updates        | 41049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2716     |
|    fps              | 702      |
|    time_elapsed     | 234      |
|    total_timesteps  | 164526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.19e-08 |
|    n_updates        | 41106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2720     |
|    fps              | 702      |
|    time_elapsed     | 234      |
|    total_timesteps  | 164824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.58e-07 |
|    n_updates        | 41180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2724     |
|    fps              | 702      |
|    time_elapsed     | 235      |
|    total_timesteps  | 165224   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-07 |
|    n_updates        | 41280    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2728     |
|    fps              | 701      |
|    time_elapsed     | 235      |
|    total_timesteps  | 165548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.46e-08 |
|    n_updates        | 41361    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2732     |
|    fps              | 701      |
|    time_elapsed     | 236      |
|    total_timesteps  | 165892   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-07 |
|    n_updates        | 41447    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2736     |
|    fps              | 701      |
|    time_elapsed     | 236      |
|    total_timesteps  | 166180   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.91e-07 |
|    n_updates        | 41519    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2740     |
|    fps              | 701      |
|    time_elapsed     | 237      |
|    total_timesteps  | 166580   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.69e-08 |
|    n_updates        | 41619    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2744     |
|    fps              | 701      |
|    time_elapsed     | 237      |
|    total_timesteps  | 166875   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00365  |
|    n_updates        | 41693    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2748     |
|    fps              | 701      |
|    time_elapsed     | 238      |
|    total_timesteps  | 167208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.97e-06 |
|    n_updates        | 41776    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.6     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2752     |
|    fps              | 701      |
|    time_elapsed     | 238      |
|    total_timesteps  | 167515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.89e-06 |
|    n_updates        | 41853    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2756     |
|    fps              | 701      |
|    time_elapsed     | 239      |
|    total_timesteps  | 167849   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.97e-07 |
|    n_updates        | 41937    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2760     |
|    fps              | 701      |
|    time_elapsed     | 239      |
|    total_timesteps  | 168141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.56e-09 |
|    n_updates        | 42010    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2764     |
|    fps              | 701      |
|    time_elapsed     | 240      |
|    total_timesteps  | 168448   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.35e-06 |
|    n_updates        | 42086    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2768     |
|    fps              | 701      |
|    time_elapsed     | 240      |
|    total_timesteps  | 168744   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-06 |
|    n_updates        | 42160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2772     |
|    fps              | 701      |
|    time_elapsed     | 241      |
|    total_timesteps  | 169086   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.57e-08 |
|    n_updates        | 42246    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2776     |
|    fps              | 701      |
|    time_elapsed     | 241      |
|    total_timesteps  | 169405   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.29e-08 |
|    n_updates        | 42326    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2780     |
|    fps              | 701      |
|    time_elapsed     | 242      |
|    total_timesteps  | 169762   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.68e-07 |
|    n_updates        | 42415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.1     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2784     |
|    fps              | 701      |
|    time_elapsed     | 242      |
|    total_timesteps  | 170136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00025  |
|    n_updates        | 42508    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.1     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2788     |
|    fps              | 701      |
|    time_elapsed     | 243      |
|    total_timesteps  | 170536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.22e-06 |
|    n_updates        | 42608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2792     |
|    fps              | 701      |
|    time_elapsed     | 243      |
|    total_timesteps  | 170896   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-06 |
|    n_updates        | 42698    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2796     |
|    fps              | 701      |
|    time_elapsed     | 244      |
|    total_timesteps  | 171226   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.35e-06 |
|    n_updates        | 42781    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2800     |
|    fps              | 701      |
|    time_elapsed     | 244      |
|    total_timesteps  | 171597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.11e-06 |
|    n_updates        | 42874    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2804     |
|    fps              | 701      |
|    time_elapsed     | 244      |
|    total_timesteps  | 171923   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.99e-05 |
|    n_updates        | 42955    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2808     |
|    fps              | 701      |
|    time_elapsed     | 245      |
|    total_timesteps  | 172261   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.06e-06 |
|    n_updates        | 43040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2812     |
|    fps              | 701      |
|    time_elapsed     | 245      |
|    total_timesteps  | 172610   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.36e-06 |
|    n_updates        | 43127    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.6     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2816     |
|    fps              | 701      |
|    time_elapsed     | 246      |
|    total_timesteps  | 172983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-06 |
|    n_updates        | 43220    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2820     |
|    fps              | 701      |
|    time_elapsed     | 246      |
|    total_timesteps  | 173314   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-05 |
|    n_updates        | 43303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2824     |
|    fps              | 701      |
|    time_elapsed     | 247      |
|    total_timesteps  | 173714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.09e-07 |
|    n_updates        | 43403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2828     |
|    fps              | 701      |
|    time_elapsed     | 247      |
|    total_timesteps  | 174000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.12e-06 |
|    n_updates        | 43474    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.7     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2832     |
|    fps              | 702      |
|    time_elapsed     | 248      |
|    total_timesteps  | 174357   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-06 |
|    n_updates        | 43564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.7     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2836     |
|    fps              | 702      |
|    time_elapsed     | 248      |
|    total_timesteps  | 174650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.72e-06 |
|    n_updates        | 43637    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.7     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2840     |
|    fps              | 702      |
|    time_elapsed     | 249      |
|    total_timesteps  | 174948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-05 |
|    n_updates        | 43711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.7     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2844     |
|    fps              | 702      |
|    time_elapsed     | 249      |
|    total_timesteps  | 175243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.45e-06 |
|    n_updates        | 43785    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2848     |
|    fps              | 702      |
|    time_elapsed     | 250      |
|    total_timesteps  | 175625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.98e-07 |
|    n_updates        | 43881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2852     |
|    fps              | 702      |
|    time_elapsed     | 250      |
|    total_timesteps  | 175964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.52e-07 |
|    n_updates        | 43965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0.14     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2856     |
|    fps              | 702      |
|    time_elapsed     | 250      |
|    total_timesteps  | 176264   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.84e-08 |
|    n_updates        | 44040    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.6     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2860     |
|    fps              | 702      |
|    time_elapsed     | 251      |
|    total_timesteps  | 176603   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.58e-07 |
|    n_updates        | 44125    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.6     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2864     |
|    fps              | 702      |
|    time_elapsed     | 251      |
|    total_timesteps  | 176905   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.23e-06 |
|    n_updates        | 44201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.6     |
|    ep_rew_mean      | 0.16     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2868     |
|    fps              | 702      |
|    time_elapsed     | 252      |
|    total_timesteps  | 177305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.98e-07 |
|    n_updates        | 44301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.9     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2872     |
|    fps              | 702      |
|    time_elapsed     | 252      |
|    total_timesteps  | 177678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.14e-07 |
|    n_updates        | 44394    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85       |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2876     |
|    fps              | 702      |
|    time_elapsed     | 253      |
|    total_timesteps  | 177907   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.08e-06 |
|    n_updates        | 44451    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.4     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2880     |
|    fps              | 702      |
|    time_elapsed     | 253      |
|    total_timesteps  | 178205   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.54e-07 |
|    n_updates        | 44526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84       |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2884     |
|    fps              | 702      |
|    time_elapsed     | 253      |
|    total_timesteps  | 178531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.64e-08 |
|    n_updates        | 44607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2888     |
|    fps              | 702      |
|    time_elapsed     | 254      |
|    total_timesteps  | 178843   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.04e-07 |
|    n_updates        | 44685    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2892     |
|    fps              | 703      |
|    time_elapsed     | 254      |
|    total_timesteps  | 179024   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.09e-07 |
|    n_updates        | 44730    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2896     |
|    fps              | 703      |
|    time_elapsed     | 255      |
|    total_timesteps  | 179290   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.75e-06 |
|    n_updates        | 44797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2900     |
|    fps              | 702      |
|    time_elapsed     | 255      |
|    total_timesteps  | 179570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.44e-07 |
|    n_updates        | 44867    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.9     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2904     |
|    fps              | 702      |
|    time_elapsed     | 255      |
|    total_timesteps  | 179917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.08e-07 |
|    n_updates        | 44954    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2908     |
|    fps              | 702      |
|    time_elapsed     | 256      |
|    total_timesteps  | 180041   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00037  |
|    n_updates        | 44985    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.1     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2912     |
|    fps              | 702      |
|    time_elapsed     | 256      |
|    total_timesteps  | 180424   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.25e-06 |
|    n_updates        | 45080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2916     |
|    fps              | 702      |
|    time_elapsed     | 257      |
|    total_timesteps  | 180774   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.86e-06 |
|    n_updates        | 45168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2920     |
|    fps              | 702      |
|    time_elapsed     | 257      |
|    total_timesteps  | 181094   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.34e-06 |
|    n_updates        | 45248    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2924     |
|    fps              | 702      |
|    time_elapsed     | 258      |
|    total_timesteps  | 181367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-06 |
|    n_updates        | 45316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2928     |
|    fps              | 702      |
|    time_elapsed     | 258      |
|    total_timesteps  | 181654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.23e-06 |
|    n_updates        | 45388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2932     |
|    fps              | 702      |
|    time_elapsed     | 258      |
|    total_timesteps  | 181966   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-05 |
|    n_updates        | 45466    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2936     |
|    fps              | 702      |
|    time_elapsed     | 259      |
|    total_timesteps  | 182174   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2e-05    |
|    n_updates        | 45518    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2940     |
|    fps              | 702      |
|    time_elapsed     | 259      |
|    total_timesteps  | 182400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.08e-06 |
|    n_updates        | 45574    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2944     |
|    fps              | 702      |
|    time_elapsed     | 260      |
|    total_timesteps  | 182693   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-06  |
|    n_updates        | 45648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2948     |
|    fps              | 702      |
|    time_elapsed     | 260      |
|    total_timesteps  | 182976   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.14e-05 |
|    n_updates        | 45718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2952     |
|    fps              | 702      |
|    time_elapsed     | 260      |
|    total_timesteps  | 183229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 45782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2956     |
|    fps              | 702      |
|    time_elapsed     | 261      |
|    total_timesteps  | 183558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.33e-06 |
|    n_updates        | 45864    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2960     |
|    fps              | 702      |
|    time_elapsed     | 261      |
|    total_timesteps  | 183792   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.02e-07 |
|    n_updates        | 45922    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2964     |
|    fps              | 701      |
|    time_elapsed     | 262      |
|    total_timesteps  | 184146   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.28e-06 |
|    n_updates        | 46011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71       |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2968     |
|    fps              | 701      |
|    time_elapsed     | 262      |
|    total_timesteps  | 184408   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.69e-07 |
|    n_updates        | 46076    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2972     |
|    fps              | 701      |
|    time_elapsed     | 263      |
|    total_timesteps  | 184808   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.09e-07 |
|    n_updates        | 46176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2976     |
|    fps              | 701      |
|    time_elapsed     | 263      |
|    total_timesteps  | 185121   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.21e-06 |
|    n_updates        | 46255    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2980     |
|    fps              | 701      |
|    time_elapsed     | 264      |
|    total_timesteps  | 185499   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-06 |
|    n_updates        | 46349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2984     |
|    fps              | 701      |
|    time_elapsed     | 264      |
|    total_timesteps  | 185695   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.03e-06 |
|    n_updates        | 46398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 0.27     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2988     |
|    fps              | 701      |
|    time_elapsed     | 265      |
|    total_timesteps  | 186031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.32e-07 |
|    n_updates        | 46482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0.27     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2992     |
|    fps              | 701      |
|    time_elapsed     | 265      |
|    total_timesteps  | 186328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.31e-07 |
|    n_updates        | 46556    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.2     |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 2996     |
|    fps              | 701      |
|    time_elapsed     | 266      |
|    total_timesteps  | 186609   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.63e-06 |
|    n_updates        | 46627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 0.28     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3000     |
|    fps              | 701      |
|    time_elapsed     | 266      |
|    total_timesteps  | 187009   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-07 |
|    n_updates        | 46727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3004     |
|    fps              | 701      |
|    time_elapsed     | 267      |
|    total_timesteps  | 187341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.42e-07 |
|    n_updates        | 46810    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3008     |
|    fps              | 701      |
|    time_elapsed     | 267      |
|    total_timesteps  | 187642   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.16e-07 |
|    n_updates        | 46885    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3012     |
|    fps              | 701      |
|    time_elapsed     | 268      |
|    total_timesteps  | 188004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.92e-07 |
|    n_updates        | 46975    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3016     |
|    fps              | 701      |
|    time_elapsed     | 268      |
|    total_timesteps  | 188337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.48e-07 |
|    n_updates        | 47059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3020     |
|    fps              | 701      |
|    time_elapsed     | 268      |
|    total_timesteps  | 188593   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.2e-07  |
|    n_updates        | 47123    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.2     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3024     |
|    fps              | 701      |
|    time_elapsed     | 269      |
|    total_timesteps  | 188785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-06 |
|    n_updates        | 47171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.31     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3028     |
|    fps              | 701      |
|    time_elapsed     | 269      |
|    total_timesteps  | 189119   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.26e-06 |
|    n_updates        | 47254    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0.33     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3032     |
|    fps              | 701      |
|    time_elapsed     | 270      |
|    total_timesteps  | 189419   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.28e-06 |
|    n_updates        | 47329    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3036     |
|    fps              | 701      |
|    time_elapsed     | 270      |
|    total_timesteps  | 189787   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.59e-08 |
|    n_updates        | 47421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 0.33     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3040     |
|    fps              | 701      |
|    time_elapsed     | 271      |
|    total_timesteps  | 190091   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000366 |
|    n_updates        | 47497    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0.32     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3044     |
|    fps              | 701      |
|    time_elapsed     | 271      |
|    total_timesteps  | 190393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.33e-06 |
|    n_updates        | 47573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 0.33     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3048     |
|    fps              | 701      |
|    time_elapsed     | 271      |
|    total_timesteps  | 190664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.36e-06 |
|    n_updates        | 47640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0.3      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3052     |
|    fps              | 701      |
|    time_elapsed     | 272      |
|    total_timesteps  | 190958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.58e-07 |
|    n_updates        | 47714    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.1     |
|    ep_rew_mean      | 0.29     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3056     |
|    fps              | 701      |
|    time_elapsed     | 272      |
|    total_timesteps  | 191172   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.08e-07 |
|    n_updates        | 47767    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3060     |
|    fps              | 701      |
|    time_elapsed     | 272      |
|    total_timesteps  | 191360   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.68e-07 |
|    n_updates        | 47814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3064     |
|    fps              | 701      |
|    time_elapsed     | 273      |
|    total_timesteps  | 191654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.8e-07  |
|    n_updates        | 47888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3068     |
|    fps              | 701      |
|    time_elapsed     | 273      |
|    total_timesteps  | 191873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-05 |
|    n_updates        | 47943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3072     |
|    fps              | 701      |
|    time_elapsed     | 274      |
|    total_timesteps  | 192151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.39e-06 |
|    n_updates        | 48012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3076     |
|    fps              | 700      |
|    time_elapsed     | 274      |
|    total_timesteps  | 192526   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.46e-07 |
|    n_updates        | 48106    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 0.26     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3080     |
|    fps              | 701      |
|    time_elapsed     | 275      |
|    total_timesteps  | 192874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.74e-07 |
|    n_updates        | 48193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3084     |
|    fps              | 701      |
|    time_elapsed     | 275      |
|    total_timesteps  | 193249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.34e-06 |
|    n_updates        | 48287    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 0.25     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3088     |
|    fps              | 701      |
|    time_elapsed     | 276      |
|    total_timesteps  | 193601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-05 |
|    n_updates        | 48375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 0.24     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3092     |
|    fps              | 701      |
|    time_elapsed     | 276      |
|    total_timesteps  | 193897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.96e-07 |
|    n_updates        | 48449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 0.22     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3096     |
|    fps              | 701      |
|    time_elapsed     | 276      |
|    total_timesteps  | 194160   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.14e-07 |
|    n_updates        | 48514    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0.23     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3100     |
|    fps              | 701      |
|    time_elapsed     | 277      |
|    total_timesteps  | 194460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.08e-06 |
|    n_updates        | 48589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 0.21     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3104     |
|    fps              | 701      |
|    time_elapsed     | 277      |
|    total_timesteps  | 194776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.33e-07 |
|    n_updates        | 48668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74       |
|    ep_rew_mean      | 0.2      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3108     |
|    fps              | 701      |
|    time_elapsed     | 278      |
|    total_timesteps  | 195042   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-06 |
|    n_updates        | 48735    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.4     |
|    ep_rew_mean      | 0.19     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3112     |
|    fps              | 701      |
|    time_elapsed     | 278      |
|    total_timesteps  | 195442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.49e-09 |
|    n_updates        | 48835    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3116     |
|    fps              | 701      |
|    time_elapsed     | 279      |
|    total_timesteps  | 195807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.01e-08 |
|    n_updates        | 48926    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0.18     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3120     |
|    fps              | 701      |
|    time_elapsed     | 279      |
|    total_timesteps  | 196170   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00034  |
|    n_updates        | 49017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0.17     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3124     |
|    fps              | 701      |
|    time_elapsed     | 280      |
|    total_timesteps  | 196570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.82e-07 |
|    n_updates        | 49117    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0.15     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3128     |
|    fps              | 701      |
|    time_elapsed     | 280      |
|    total_timesteps  | 196904   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.23e-07 |
|    n_updates        | 49200    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3132     |
|    fps              | 701      |
|    time_elapsed     | 281      |
|    total_timesteps  | 197256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.49e-07 |
|    n_updates        | 49288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3136     |
|    fps              | 701      |
|    time_elapsed     | 281      |
|    total_timesteps  | 197582   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.27e-07 |
|    n_updates        | 49370    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.3     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3140     |
|    fps              | 701      |
|    time_elapsed     | 281      |
|    total_timesteps  | 197920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.62e-07 |
|    n_updates        | 49454    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 0.13     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3144     |
|    fps              | 701      |
|    time_elapsed     | 282      |
|    total_timesteps  | 198231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-07 |
|    n_updates        | 49532    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3148     |
|    fps              | 702      |
|    time_elapsed     | 282      |
|    total_timesteps  | 198614   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.63e-07 |
|    n_updates        | 49628    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3152     |
|    fps              | 702      |
|    time_elapsed     | 283      |
|    total_timesteps  | 198922   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.45e-08 |
|    n_updates        | 49705    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3156     |
|    fps              | 702      |
|    time_elapsed     | 283      |
|    total_timesteps  | 199231   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.17e-08 |
|    n_updates        | 49782    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3160     |
|    fps              | 701      |
|    time_elapsed     | 284      |
|    total_timesteps  | 199525   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.87e-07 |
|    n_updates        | 49856    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0.11     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3164     |
|    fps              | 701      |
|    time_elapsed     | 284      |
|    total_timesteps  | 199873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.98e-08 |
|    n_updates        | 49943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3168     |
|    fps              | 701      |
|    time_elapsed     | 285      |
|    total_timesteps  | 200103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.63e-05 |
|    n_updates        | 50000    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 0.12     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3172     |
|    fps              | 701      |
|    time_elapsed     | 285      |
|    total_timesteps  | 200350   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9e-06    |
|    n_updates        | 50062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0.1      |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3176     |
|    fps              | 701      |
|    time_elapsed     | 285      |
|    total_timesteps  | 200581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.98e-06 |
|    n_updates        | 50120    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3180     |
|    fps              | 701      |
|    time_elapsed     | 286      |
|    total_timesteps  | 200873   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-06 |
|    n_updates        | 50193    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0.09     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3184     |
|    fps              | 701      |
|    time_elapsed     | 286      |
|    total_timesteps  | 201197   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.14e-07 |
|    n_updates        | 50274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3188     |
|    fps              | 702      |
|    time_elapsed     | 287      |
|    total_timesteps  | 201560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.39e-06 |
|    n_updates        | 50364    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 0.08     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3192     |
|    fps              | 702      |
|    time_elapsed     | 287      |
|    total_timesteps  | 201820   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-07 |
|    n_updates        | 50429    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 0.07     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3196     |
|    fps              | 702      |
|    time_elapsed     | 287      |
|    total_timesteps  | 202129   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3e-07    |
|    n_updates        | 50507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3200     |
|    fps              | 702      |
|    time_elapsed     | 288      |
|    total_timesteps  | 202482   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.23e-06 |
|    n_updates        | 50595    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 0.06     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3204     |
|    fps              | 702      |
|    time_elapsed     | 288      |
|    total_timesteps  | 202694   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.7e-07  |
|    n_updates        | 50648    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3208     |
|    fps              | 702      |
|    time_elapsed     | 288      |
|    total_timesteps  | 203027   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.48e-07 |
|    n_updates        | 50731    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.6     |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3212     |
|    fps              | 702      |
|    time_elapsed     | 289      |
|    total_timesteps  | 203299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.37e-06 |
|    n_updates        | 50799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0.05     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3216     |
|    fps              | 702      |
|    time_elapsed     | 289      |
|    total_timesteps  | 203503   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.94e-08 |
|    n_updates        | 50850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3220     |
|    fps              | 702      |
|    time_elapsed     | 290      |
|    total_timesteps  | 203861   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.61e-07 |
|    n_updates        | 50940    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.3     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3224     |
|    fps              | 703      |
|    time_elapsed     | 290      |
|    total_timesteps  | 204099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-06  |
|    n_updates        | 50999    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3228     |
|    fps              | 703      |
|    time_elapsed     | 290      |
|    total_timesteps  | 204285   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9e-08    |
|    n_updates        | 51046    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3232     |
|    fps              | 703      |
|    time_elapsed     | 290      |
|    total_timesteps  | 204548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-06 |
|    n_updates        | 51111    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3236     |
|    fps              | 702      |
|    time_elapsed     | 291      |
|    total_timesteps  | 204796   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.59e-07 |
|    n_updates        | 51173    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3240     |
|    fps              | 703      |
|    time_elapsed     | 291      |
|    total_timesteps  | 205196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.66e-08 |
|    n_updates        | 51273    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3244     |
|    fps              | 703      |
|    time_elapsed     | 292      |
|    total_timesteps  | 205456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-07 |
|    n_updates        | 51338    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3248     |
|    fps              | 703      |
|    time_elapsed     | 292      |
|    total_timesteps  | 205695   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.21e-07 |
|    n_updates        | 51398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3252     |
|    fps              | 703      |
|    time_elapsed     | 292      |
|    total_timesteps  | 205984   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.76e-07 |
|    n_updates        | 51470    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3256     |
|    fps              | 703      |
|    time_elapsed     | 293      |
|    total_timesteps  | 206211   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.52e-07 |
|    n_updates        | 51527    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3260     |
|    fps              | 703      |
|    time_elapsed     | 293      |
|    total_timesteps  | 206589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.89e-07 |
|    n_updates        | 51622    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3264     |
|    fps              | 703      |
|    time_elapsed     | 293      |
|    total_timesteps  | 206834   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-07 |
|    n_updates        | 51683    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3268     |
|    fps              | 703      |
|    time_elapsed     | 294      |
|    total_timesteps  | 207064   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.76e-08 |
|    n_updates        | 51740    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3272     |
|    fps              | 703      |
|    time_elapsed     | 294      |
|    total_timesteps  | 207397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.67e-06 |
|    n_updates        | 51824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3276     |
|    fps              | 703      |
|    time_elapsed     | 295      |
|    total_timesteps  | 207736   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.35e-06 |
|    n_updates        | 51908    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3280     |
|    fps              | 703      |
|    time_elapsed     | 295      |
|    total_timesteps  | 207997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-05 |
|    n_updates        | 51974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3284     |
|    fps              | 703      |
|    time_elapsed     | 295      |
|    total_timesteps  | 208247   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.76e-06 |
|    n_updates        | 52036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3288     |
|    fps              | 704      |
|    time_elapsed     | 296      |
|    total_timesteps  | 208597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.37e-08 |
|    n_updates        | 52124    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3292     |
|    fps              | 704      |
|    time_elapsed     | 296      |
|    total_timesteps  | 208910   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.04e-06 |
|    n_updates        | 52202    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3296     |
|    fps              | 704      |
|    time_elapsed     | 297      |
|    total_timesteps  | 209245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.07e-07 |
|    n_updates        | 52286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3300     |
|    fps              | 704      |
|    time_elapsed     | 297      |
|    total_timesteps  | 209512   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.09e-07 |
|    n_updates        | 52352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3304     |
|    fps              | 704      |
|    time_elapsed     | 297      |
|    total_timesteps  | 209788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.7e-08  |
|    n_updates        | 52421    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3308     |
|    fps              | 704      |
|    time_elapsed     | 298      |
|    total_timesteps  | 210045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000365 |
|    n_updates        | 52486    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3312     |
|    fps              | 704      |
|    time_elapsed     | 298      |
|    total_timesteps  | 210322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.37e-06 |
|    n_updates        | 52555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3316     |
|    fps              | 704      |
|    time_elapsed     | 298      |
|    total_timesteps  | 210450   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.53e-06 |
|    n_updates        | 52587    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3320     |
|    fps              | 704      |
|    time_elapsed     | 298      |
|    total_timesteps  | 210536   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000509 |
|    n_updates        | 52608    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3324     |
|    fps              | 704      |
|    time_elapsed     | 298      |
|    total_timesteps  | 210641   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.15e-07 |
|    n_updates        | 52635    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3328     |
|    fps              | 704      |
|    time_elapsed     | 299      |
|    total_timesteps  | 210845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 52686    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3332     |
|    fps              | 704      |
|    time_elapsed     | 299      |
|    total_timesteps  | 211187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-07 |
|    n_updates        | 52771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3336     |
|    fps              | 704      |
|    time_elapsed     | 299      |
|    total_timesteps  | 211372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-08 |
|    n_updates        | 52817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3340     |
|    fps              | 704      |
|    time_elapsed     | 300      |
|    total_timesteps  | 211581   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-07 |
|    n_updates        | 52870    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3344     |
|    fps              | 704      |
|    time_elapsed     | 300      |
|    total_timesteps  | 211845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.95e-07 |
|    n_updates        | 52936    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3348     |
|    fps              | 704      |
|    time_elapsed     | 300      |
|    total_timesteps  | 211983   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2e-07    |
|    n_updates        | 52970    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3352     |
|    fps              | 704      |
|    time_elapsed     | 301      |
|    total_timesteps  | 212164   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.71e-07 |
|    n_updates        | 53015    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3356     |
|    fps              | 704      |
|    time_elapsed     | 301      |
|    total_timesteps  | 212319   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.32e-07 |
|    n_updates        | 53054    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3360     |
|    fps              | 704      |
|    time_elapsed     | 301      |
|    total_timesteps  | 212494   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-07 |
|    n_updates        | 53098    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3364     |
|    fps              | 704      |
|    time_elapsed     | 301      |
|    total_timesteps  | 212842   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.55e-08 |
|    n_updates        | 53185    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3368     |
|    fps              | 705      |
|    time_elapsed     | 302      |
|    total_timesteps  | 213109   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.67e-07 |
|    n_updates        | 53252    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3372     |
|    fps              | 705      |
|    time_elapsed     | 302      |
|    total_timesteps  | 213415   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.27e-08 |
|    n_updates        | 53328    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3376     |
|    fps              | 705      |
|    time_elapsed     | 303      |
|    total_timesteps  | 213805   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.08e-09 |
|    n_updates        | 53426    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3380     |
|    fps              | 705      |
|    time_elapsed     | 303      |
|    total_timesteps  | 214078   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.85e-09 |
|    n_updates        | 53494    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3384     |
|    fps              | 705      |
|    time_elapsed     | 303      |
|    total_timesteps  | 214314   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.92e-09 |
|    n_updates        | 53553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3388     |
|    fps              | 705      |
|    time_elapsed     | 304      |
|    total_timesteps  | 214629   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.83e-08 |
|    n_updates        | 53632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3392     |
|    fps              | 705      |
|    time_elapsed     | 304      |
|    total_timesteps  | 214899   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.55e-09 |
|    n_updates        | 53699    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3396     |
|    fps              | 705      |
|    time_elapsed     | 304      |
|    total_timesteps  | 215134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.43e-07 |
|    n_updates        | 53758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3400     |
|    fps              | 705      |
|    time_elapsed     | 305      |
|    total_timesteps  | 215361   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.63e-09 |
|    n_updates        | 53815    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3404     |
|    fps              | 706      |
|    time_elapsed     | 305      |
|    total_timesteps  | 215654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.23e-08 |
|    n_updates        | 53888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3408     |
|    fps              | 706      |
|    time_elapsed     | 305      |
|    total_timesteps  | 215798   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-06 |
|    n_updates        | 53924    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3412     |
|    fps              | 706      |
|    time_elapsed     | 305      |
|    total_timesteps  | 216114   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.9e-08  |
|    n_updates        | 54003    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3416     |
|    fps              | 706      |
|    time_elapsed     | 306      |
|    total_timesteps  | 216451   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.07e-07 |
|    n_updates        | 54087    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3420     |
|    fps              | 706      |
|    time_elapsed     | 306      |
|    total_timesteps  | 216760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.42e-08 |
|    n_updates        | 54164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3424     |
|    fps              | 706      |
|    time_elapsed     | 307      |
|    total_timesteps  | 217125   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.02e-07 |
|    n_updates        | 54256    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3428     |
|    fps              | 706      |
|    time_elapsed     | 307      |
|    total_timesteps  | 217370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.42e-08 |
|    n_updates        | 54317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3432     |
|    fps              | 706      |
|    time_elapsed     | 307      |
|    total_timesteps  | 217593   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 54373    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3436     |
|    fps              | 706      |
|    time_elapsed     | 308      |
|    total_timesteps  | 217777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.99e-07 |
|    n_updates        | 54419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3440     |
|    fps              | 706      |
|    time_elapsed     | 308      |
|    total_timesteps  | 218081   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.34e-08 |
|    n_updates        | 54495    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3444     |
|    fps              | 706      |
|    time_elapsed     | 308      |
|    total_timesteps  | 218305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-06 |
|    n_updates        | 54551    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3448     |
|    fps              | 706      |
|    time_elapsed     | 309      |
|    total_timesteps  | 218507   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.02e-07 |
|    n_updates        | 54601    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3452     |
|    fps              | 706      |
|    time_elapsed     | 309      |
|    total_timesteps  | 218646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.95e-07 |
|    n_updates        | 54636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3456     |
|    fps              | 706      |
|    time_elapsed     | 309      |
|    total_timesteps  | 218864   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.71e-08 |
|    n_updates        | 54690    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3460     |
|    fps              | 706      |
|    time_elapsed     | 309      |
|    total_timesteps  | 219077   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-07  |
|    n_updates        | 54744    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3464     |
|    fps              | 706      |
|    time_elapsed     | 310      |
|    total_timesteps  | 219400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.2e-08  |
|    n_updates        | 54824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3468     |
|    fps              | 706      |
|    time_elapsed     | 310      |
|    total_timesteps  | 219601   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.72e-08 |
|    n_updates        | 54875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3472     |
|    fps              | 706      |
|    time_elapsed     | 310      |
|    total_timesteps  | 219774   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.28e-07 |
|    n_updates        | 54918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3476     |
|    fps              | 706      |
|    time_elapsed     | 311      |
|    total_timesteps  | 220024   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00023  |
|    n_updates        | 54980    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3480     |
|    fps              | 706      |
|    time_elapsed     | 311      |
|    total_timesteps  | 220243   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.9e-06  |
|    n_updates        | 55035    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3484     |
|    fps              | 706      |
|    time_elapsed     | 311      |
|    total_timesteps  | 220429   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.7e-06  |
|    n_updates        | 55082    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3488     |
|    fps              | 706      |
|    time_elapsed     | 312      |
|    total_timesteps  | 220702   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.73e-07 |
|    n_updates        | 55150    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3492     |
|    fps              | 706      |
|    time_elapsed     | 312      |
|    total_timesteps  | 221039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-07 |
|    n_updates        | 55234    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3496     |
|    fps              | 706      |
|    time_elapsed     | 313      |
|    total_timesteps  | 221280   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.97e-07 |
|    n_updates        | 55294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3500     |
|    fps              | 706      |
|    time_elapsed     | 313      |
|    total_timesteps  | 221447   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.08e-06 |
|    n_updates        | 55336    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3504     |
|    fps              | 707      |
|    time_elapsed     | 313      |
|    total_timesteps  | 221661   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.42e-08 |
|    n_updates        | 55390    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3508     |
|    fps              | 707      |
|    time_elapsed     | 313      |
|    total_timesteps  | 221831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.76e-08 |
|    n_updates        | 55432    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3512     |
|    fps              | 706      |
|    time_elapsed     | 314      |
|    total_timesteps  | 222020   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.21e-07 |
|    n_updates        | 55479    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3516     |
|    fps              | 706      |
|    time_elapsed     | 314      |
|    total_timesteps  | 222200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.04e-08 |
|    n_updates        | 55524    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3520     |
|    fps              | 706      |
|    time_elapsed     | 314      |
|    total_timesteps  | 222467   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-08 |
|    n_updates        | 55591    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3524     |
|    fps              | 707      |
|    time_elapsed     | 315      |
|    total_timesteps  | 222755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.83e-07 |
|    n_updates        | 55663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3528     |
|    fps              | 707      |
|    time_elapsed     | 315      |
|    total_timesteps  | 222831   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.32e-07 |
|    n_updates        | 55682    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3532     |
|    fps              | 707      |
|    time_elapsed     | 315      |
|    total_timesteps  | 222998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.98e-08 |
|    n_updates        | 55724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3536     |
|    fps              | 707      |
|    time_elapsed     | 315      |
|    total_timesteps  | 223186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.08e-08 |
|    n_updates        | 55771    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3540     |
|    fps              | 707      |
|    time_elapsed     | 316      |
|    total_timesteps  | 223491   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-08 |
|    n_updates        | 55847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3544     |
|    fps              | 707      |
|    time_elapsed     | 316      |
|    total_timesteps  | 223654   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-08 |
|    n_updates        | 55888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3548     |
|    fps              | 707      |
|    time_elapsed     | 316      |
|    total_timesteps  | 223877   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-08 |
|    n_updates        | 55944    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3552     |
|    fps              | 707      |
|    time_elapsed     | 316      |
|    total_timesteps  | 224017   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-08 |
|    n_updates        | 55979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3556     |
|    fps              | 707      |
|    time_elapsed     | 317      |
|    total_timesteps  | 224179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.32e-09 |
|    n_updates        | 56019    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3560     |
|    fps              | 707      |
|    time_elapsed     | 317      |
|    total_timesteps  | 224340   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-08 |
|    n_updates        | 56059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3564     |
|    fps              | 707      |
|    time_elapsed     | 317      |
|    total_timesteps  | 224500   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.2e-09  |
|    n_updates        | 56099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3568     |
|    fps              | 707      |
|    time_elapsed     | 317      |
|    total_timesteps  | 224684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.84e-09 |
|    n_updates        | 56145    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3572     |
|    fps              | 707      |
|    time_elapsed     | 317      |
|    total_timesteps  | 224825   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.93e-08 |
|    n_updates        | 56181    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3576     |
|    fps              | 707      |
|    time_elapsed     | 318      |
|    total_timesteps  | 224969   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.06e-08 |
|    n_updates        | 56217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3580     |
|    fps              | 707      |
|    time_elapsed     | 318      |
|    total_timesteps  | 225218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.56e-09 |
|    n_updates        | 56279    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3584     |
|    fps              | 707      |
|    time_elapsed     | 318      |
|    total_timesteps  | 225365   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.68e-07 |
|    n_updates        | 56316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3588     |
|    fps              | 706      |
|    time_elapsed     | 319      |
|    total_timesteps  | 225659   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.5e-08  |
|    n_updates        | 56389    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3592     |
|    fps              | 706      |
|    time_elapsed     | 319      |
|    total_timesteps  | 225860   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-07 |
|    n_updates        | 56439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3596     |
|    fps              | 706      |
|    time_elapsed     | 319      |
|    total_timesteps  | 226089   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.53e-07 |
|    n_updates        | 56497    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3600     |
|    fps              | 706      |
|    time_elapsed     | 320      |
|    total_timesteps  | 226300   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.11e-08 |
|    n_updates        | 56549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3604     |
|    fps              | 706      |
|    time_elapsed     | 320      |
|    total_timesteps  | 226548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.43e-08 |
|    n_updates        | 56611    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3608     |
|    fps              | 706      |
|    time_elapsed     | 320      |
|    total_timesteps  | 226736   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.64e-07 |
|    n_updates        | 56658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3612     |
|    fps              | 706      |
|    time_elapsed     | 321      |
|    total_timesteps  | 226950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.61e-07 |
|    n_updates        | 56712    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3616     |
|    fps              | 706      |
|    time_elapsed     | 321      |
|    total_timesteps  | 227141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.79e-07 |
|    n_updates        | 56760    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3620     |
|    fps              | 706      |
|    time_elapsed     | 321      |
|    total_timesteps  | 227391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.82e-07 |
|    n_updates        | 56822    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 47.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3624     |
|    fps              | 706      |
|    time_elapsed     | 321      |
|    total_timesteps  | 227547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.66e-07 |
|    n_updates        | 56861    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.4     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3628     |
|    fps              | 706      |
|    time_elapsed     | 322      |
|    total_timesteps  | 227772   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.15e-07 |
|    n_updates        | 56917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.9     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3632     |
|    fps              | 706      |
|    time_elapsed     | 322      |
|    total_timesteps  | 227989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.92e-08 |
|    n_updates        | 56972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3636     |
|    fps              | 707      |
|    time_elapsed     | 322      |
|    total_timesteps  | 228111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.04e-08 |
|    n_updates        | 57002    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3640     |
|    fps              | 707      |
|    time_elapsed     | 322      |
|    total_timesteps  | 228300   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.79e-07 |
|    n_updates        | 57049    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3644     |
|    fps              | 707      |
|    time_elapsed     | 323      |
|    total_timesteps  | 228558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.91e-07 |
|    n_updates        | 57114    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 48.7     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3648     |
|    fps              | 707      |
|    time_elapsed     | 323      |
|    total_timesteps  | 228744   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-07 |
|    n_updates        | 57160    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 49.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3652     |
|    fps              | 707      |
|    time_elapsed     | 323      |
|    total_timesteps  | 228932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.63e-07 |
|    n_updates        | 57207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 50.7     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3656     |
|    fps              | 706      |
|    time_elapsed     | 324      |
|    total_timesteps  | 229248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.03e-07 |
|    n_updates        | 57286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51       |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3660     |
|    fps              | 707      |
|    time_elapsed     | 324      |
|    total_timesteps  | 229442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.84e-07 |
|    n_updates        | 57335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52       |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3664     |
|    fps              | 707      |
|    time_elapsed     | 324      |
|    total_timesteps  | 229703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.74e-06 |
|    n_updates        | 57400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 51       |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3668     |
|    fps              | 707      |
|    time_elapsed     | 324      |
|    total_timesteps  | 229779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.35e-06 |
|    n_updates        | 57419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 52.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3672     |
|    fps              | 707      |
|    time_elapsed     | 325      |
|    total_timesteps  | 230062   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000199 |
|    n_updates        | 57490    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3676     |
|    fps              | 706      |
|    time_elapsed     | 325      |
|    total_timesteps  | 230393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.3e-06  |
|    n_updates        | 57573    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3680     |
|    fps              | 706      |
|    time_elapsed     | 326      |
|    total_timesteps  | 230630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.29e-07 |
|    n_updates        | 57632    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3684     |
|    fps              | 706      |
|    time_elapsed     | 326      |
|    total_timesteps  | 231030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 57732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3688     |
|    fps              | 706      |
|    time_elapsed     | 327      |
|    total_timesteps  | 231268   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-07 |
|    n_updates        | 57791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3692     |
|    fps              | 706      |
|    time_elapsed     | 327      |
|    total_timesteps  | 231474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.37e-07 |
|    n_updates        | 57843    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3696     |
|    fps              | 706      |
|    time_elapsed     | 327      |
|    total_timesteps  | 231707   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.58e-07 |
|    n_updates        | 57901    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3700     |
|    fps              | 706      |
|    time_elapsed     | 328      |
|    total_timesteps  | 231949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.46e-07 |
|    n_updates        | 57962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3704     |
|    fps              | 706      |
|    time_elapsed     | 328      |
|    total_timesteps  | 232310   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-07 |
|    n_updates        | 58052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.3     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3708     |
|    fps              | 706      |
|    time_elapsed     | 329      |
|    total_timesteps  | 232664   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.58e-07 |
|    n_updates        | 58140    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3712     |
|    fps              | 706      |
|    time_elapsed     | 329      |
|    total_timesteps  | 232975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.19e-07 |
|    n_updates        | 58218    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3716     |
|    fps              | 706      |
|    time_elapsed     | 330      |
|    total_timesteps  | 233353   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.24e-08 |
|    n_updates        | 58313    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3720     |
|    fps              | 706      |
|    time_elapsed     | 330      |
|    total_timesteps  | 233612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.95e-07 |
|    n_updates        | 58377    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3724     |
|    fps              | 707      |
|    time_elapsed     | 330      |
|    total_timesteps  | 233848   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.41e-08 |
|    n_updates        | 58436    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3728     |
|    fps              | 707      |
|    time_elapsed     | 331      |
|    total_timesteps  | 234104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-08 |
|    n_updates        | 58500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3732     |
|    fps              | 707      |
|    time_elapsed     | 331      |
|    total_timesteps  | 234304   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.54e-08 |
|    n_updates        | 58550    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3736     |
|    fps              | 707      |
|    time_elapsed     | 331      |
|    total_timesteps  | 234541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.17e-09 |
|    n_updates        | 58610    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3740     |
|    fps              | 707      |
|    time_elapsed     | 332      |
|    total_timesteps  | 234850   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-07 |
|    n_updates        | 58687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3744     |
|    fps              | 707      |
|    time_elapsed     | 332      |
|    total_timesteps  | 235179   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-08 |
|    n_updates        | 58769    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3748     |
|    fps              | 707      |
|    time_elapsed     | 332      |
|    total_timesteps  | 235291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.78e-07 |
|    n_updates        | 58797    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3752     |
|    fps              | 707      |
|    time_elapsed     | 333      |
|    total_timesteps  | 235550   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-08 |
|    n_updates        | 58862    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3756     |
|    fps              | 707      |
|    time_elapsed     | 333      |
|    total_timesteps  | 235810   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.37e-08 |
|    n_updates        | 58927    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3760     |
|    fps              | 707      |
|    time_elapsed     | 333      |
|    total_timesteps  | 235999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-08 |
|    n_updates        | 58974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3764     |
|    fps              | 707      |
|    time_elapsed     | 333      |
|    total_timesteps  | 236233   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.3e-08  |
|    n_updates        | 59033    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3768     |
|    fps              | 707      |
|    time_elapsed     | 334      |
|    total_timesteps  | 236498   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.36e-08 |
|    n_updates        | 59099    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3772     |
|    fps              | 707      |
|    time_elapsed     | 334      |
|    total_timesteps  | 236814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-06 |
|    n_updates        | 59178    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3776     |
|    fps              | 707      |
|    time_elapsed     | 335      |
|    total_timesteps  | 237085   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-06 |
|    n_updates        | 59246    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3780     |
|    fps              | 707      |
|    time_elapsed     | 335      |
|    total_timesteps  | 237410   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.89e-07 |
|    n_updates        | 59327    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3784     |
|    fps              | 707      |
|    time_elapsed     | 335      |
|    total_timesteps  | 237691   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.19e-07 |
|    n_updates        | 59397    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3788     |
|    fps              | 707      |
|    time_elapsed     | 336      |
|    total_timesteps  | 237933   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.19e-07 |
|    n_updates        | 59458    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3792     |
|    fps              | 707      |
|    time_elapsed     | 336      |
|    total_timesteps  | 238267   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.9e-07  |
|    n_updates        | 59541    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3796     |
|    fps              | 707      |
|    time_elapsed     | 337      |
|    total_timesteps  | 238436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-07 |
|    n_updates        | 59583    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3800     |
|    fps              | 707      |
|    time_elapsed     | 337      |
|    total_timesteps  | 238699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-07  |
|    n_updates        | 59649    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3804     |
|    fps              | 707      |
|    time_elapsed     | 337      |
|    total_timesteps  | 238981   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.49e-07 |
|    n_updates        | 59720    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3808     |
|    fps              | 707      |
|    time_elapsed     | 338      |
|    total_timesteps  | 239323   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.21e-07 |
|    n_updates        | 59805    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66       |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3812     |
|    fps              | 707      |
|    time_elapsed     | 338      |
|    total_timesteps  | 239570   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.87e-06 |
|    n_updates        | 59867    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3816     |
|    fps              | 707      |
|    time_elapsed     | 339      |
|    total_timesteps  | 239970   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.11e-07 |
|    n_updates        | 59967    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3820     |
|    fps              | 707      |
|    time_elapsed     | 339      |
|    total_timesteps  | 240187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-05 |
|    n_updates        | 60021    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3824     |
|    fps              | 707      |
|    time_elapsed     | 339      |
|    total_timesteps  | 240464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.41e-07 |
|    n_updates        | 60090    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3828     |
|    fps              | 707      |
|    time_elapsed     | 340      |
|    total_timesteps  | 240724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.72e-06 |
|    n_updates        | 60155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3832     |
|    fps              | 708      |
|    time_elapsed     | 340      |
|    total_timesteps  | 240993   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.94e-07 |
|    n_updates        | 60223    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3836     |
|    fps              | 708      |
|    time_elapsed     | 340      |
|    total_timesteps  | 241273   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.69e-08 |
|    n_updates        | 60293    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3840     |
|    fps              | 708      |
|    time_elapsed     | 341      |
|    total_timesteps  | 241605   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.1e-08  |
|    n_updates        | 60376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3844     |
|    fps              | 708      |
|    time_elapsed     | 341      |
|    total_timesteps  | 241858   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.34e-07 |
|    n_updates        | 60439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3848     |
|    fps              | 708      |
|    time_elapsed     | 341      |
|    total_timesteps  | 242207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.35e-08 |
|    n_updates        | 60526    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3852     |
|    fps              | 708      |
|    time_elapsed     | 342      |
|    total_timesteps  | 242375   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 60568    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3856     |
|    fps              | 708      |
|    time_elapsed     | 342      |
|    total_timesteps  | 242472   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.59e-08 |
|    n_updates        | 60592    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3860     |
|    fps              | 708      |
|    time_elapsed     | 342      |
|    total_timesteps  | 242735   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.39e-08 |
|    n_updates        | 60658    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3864     |
|    fps              | 708      |
|    time_elapsed     | 342      |
|    total_timesteps  | 243001   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.11e-08 |
|    n_updates        | 60725    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3868     |
|    fps              | 708      |
|    time_elapsed     | 343      |
|    total_timesteps  | 243214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.95e-08 |
|    n_updates        | 60778    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3872     |
|    fps              | 708      |
|    time_elapsed     | 343      |
|    total_timesteps  | 243455   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.63e-08 |
|    n_updates        | 60838    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3876     |
|    fps              | 708      |
|    time_elapsed     | 343      |
|    total_timesteps  | 243750   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.55e-07 |
|    n_updates        | 60912    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3880     |
|    fps              | 708      |
|    time_elapsed     | 344      |
|    total_timesteps  | 243950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-07 |
|    n_updates        | 60962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3884     |
|    fps              | 708      |
|    time_elapsed     | 344      |
|    total_timesteps  | 244070   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.65e-08 |
|    n_updates        | 60992    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.2     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3888     |
|    fps              | 708      |
|    time_elapsed     | 344      |
|    total_timesteps  | 244354   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.46e-08 |
|    n_updates        | 61063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3892     |
|    fps              | 708      |
|    time_elapsed     | 344      |
|    total_timesteps  | 244576   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.04e-08 |
|    n_updates        | 61118    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 0.04     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3896     |
|    fps              | 709      |
|    time_elapsed     | 345      |
|    total_timesteps  | 244790   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-07 |
|    n_updates        | 61172    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.3     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3900     |
|    fps              | 709      |
|    time_elapsed     | 345      |
|    total_timesteps  | 244932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.4e-08  |
|    n_updates        | 61207    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0.03     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3904     |
|    fps              | 709      |
|    time_elapsed     | 345      |
|    total_timesteps  | 245187   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.19e-08 |
|    n_updates        | 61271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.5     |
|    ep_rew_mean      | 0.02     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3908     |
|    fps              | 709      |
|    time_elapsed     | 345      |
|    total_timesteps  | 245373   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.42e-08 |
|    n_updates        | 61318    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3912     |
|    fps              | 709      |
|    time_elapsed     | 346      |
|    total_timesteps  | 245652   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.01e-08 |
|    n_updates        | 61387    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3916     |
|    fps              | 709      |
|    time_elapsed     | 346      |
|    total_timesteps  | 245806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.22e-08 |
|    n_updates        | 61426    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3920     |
|    fps              | 709      |
|    time_elapsed     | 346      |
|    total_timesteps  | 245923   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.19e-08 |
|    n_updates        | 61455    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3924     |
|    fps              | 709      |
|    time_elapsed     | 347      |
|    total_timesteps  | 246221   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.3e-07  |
|    n_updates        | 61530    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3928     |
|    fps              | 709      |
|    time_elapsed     | 347      |
|    total_timesteps  | 246531   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.29e-07 |
|    n_updates        | 61607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3932     |
|    fps              | 709      |
|    time_elapsed     | 347      |
|    total_timesteps  | 246817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.23e-07 |
|    n_updates        | 61679    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3936     |
|    fps              | 709      |
|    time_elapsed     | 347      |
|    total_timesteps  | 246974   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.64e-07 |
|    n_updates        | 61718    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3940     |
|    fps              | 709      |
|    time_elapsed     | 348      |
|    total_timesteps  | 247195   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-07  |
|    n_updates        | 61773    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3944     |
|    fps              | 709      |
|    time_elapsed     | 348      |
|    total_timesteps  | 247402   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.71e-07 |
|    n_updates        | 61825    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3948     |
|    fps              | 709      |
|    time_elapsed     | 348      |
|    total_timesteps  | 247740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-06 |
|    n_updates        | 61909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3952     |
|    fps              | 710      |
|    time_elapsed     | 349      |
|    total_timesteps  | 247943   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.21e-07 |
|    n_updates        | 61960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3956     |
|    fps              | 710      |
|    time_elapsed     | 349      |
|    total_timesteps  | 248230   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.98e-05 |
|    n_updates        | 62032    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3960     |
|    fps              | 710      |
|    time_elapsed     | 349      |
|    total_timesteps  | 248502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.51e-07 |
|    n_updates        | 62100    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3964     |
|    fps              | 710      |
|    time_elapsed     | 350      |
|    total_timesteps  | 248728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.6e-07  |
|    n_updates        | 62156    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3968     |
|    fps              | 710      |
|    time_elapsed     | 350      |
|    total_timesteps  | 249052   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 62237    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3972     |
|    fps              | 710      |
|    time_elapsed     | 350      |
|    total_timesteps  | 249232   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.41e-07 |
|    n_updates        | 62282    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3976     |
|    fps              | 710      |
|    time_elapsed     | 351      |
|    total_timesteps  | 249403   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.03e-07 |
|    n_updates        | 62325    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3980     |
|    fps              | 710      |
|    time_elapsed     | 351      |
|    total_timesteps  | 249697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.66e-06 |
|    n_updates        | 62399    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3984     |
|    fps              | 710      |
|    time_elapsed     | 351      |
|    total_timesteps  | 250006   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00012  |
|    n_updates        | 62476    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3988     |
|    fps              | 710      |
|    time_elapsed     | 352      |
|    total_timesteps  | 250382   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.4e-06  |
|    n_updates        | 62570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3992     |
|    fps              | 710      |
|    time_elapsed     | 352      |
|    total_timesteps  | 250682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000133 |
|    n_updates        | 62645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 3996     |
|    fps              | 710      |
|    time_elapsed     | 353      |
|    total_timesteps  | 250963   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.61e-07 |
|    n_updates        | 62715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4000     |
|    fps              | 710      |
|    time_elapsed     | 353      |
|    total_timesteps  | 251273   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.67e-07 |
|    n_updates        | 62793    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4004     |
|    fps              | 710      |
|    time_elapsed     | 353      |
|    total_timesteps  | 251560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.88e-07 |
|    n_updates        | 62864    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4008     |
|    fps              | 710      |
|    time_elapsed     | 354      |
|    total_timesteps  | 251771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-08  |
|    n_updates        | 62917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4012     |
|    fps              | 710      |
|    time_elapsed     | 354      |
|    total_timesteps  | 252031   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.71e-07 |
|    n_updates        | 62982    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4016     |
|    fps              | 710      |
|    time_elapsed     | 354      |
|    total_timesteps  | 252342   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.26e-08 |
|    n_updates        | 63060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4020     |
|    fps              | 710      |
|    time_elapsed     | 355      |
|    total_timesteps  | 252625   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.27e-08 |
|    n_updates        | 63131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4024     |
|    fps              | 710      |
|    time_elapsed     | 355      |
|    total_timesteps  | 252775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1e-07    |
|    n_updates        | 63168    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4028     |
|    fps              | 710      |
|    time_elapsed     | 355      |
|    total_timesteps  | 253010   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.11e-08 |
|    n_updates        | 63227    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4032     |
|    fps              | 710      |
|    time_elapsed     | 356      |
|    total_timesteps  | 253301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.26e-08 |
|    n_updates        | 63300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4036     |
|    fps              | 710      |
|    time_elapsed     | 356      |
|    total_timesteps  | 253504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.58e-08 |
|    n_updates        | 63350    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4040     |
|    fps              | 710      |
|    time_elapsed     | 356      |
|    total_timesteps  | 253760   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-07 |
|    n_updates        | 63414    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4044     |
|    fps              | 710      |
|    time_elapsed     | 357      |
|    total_timesteps  | 253973   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.97e-08 |
|    n_updates        | 63468    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4048     |
|    fps              | 710      |
|    time_elapsed     | 357      |
|    total_timesteps  | 254151   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.53e-08 |
|    n_updates        | 63512    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4052     |
|    fps              | 710      |
|    time_elapsed     | 358      |
|    total_timesteps  | 254388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-08 |
|    n_updates        | 63571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4056     |
|    fps              | 710      |
|    time_elapsed     | 358      |
|    total_timesteps  | 254633   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.9e-07  |
|    n_updates        | 63633    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4060     |
|    fps              | 710      |
|    time_elapsed     | 358      |
|    total_timesteps  | 254892   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.53e-07 |
|    n_updates        | 63697    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4064     |
|    fps              | 710      |
|    time_elapsed     | 359      |
|    total_timesteps  | 255134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.32e-06 |
|    n_updates        | 63758    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4068     |
|    fps              | 710      |
|    time_elapsed     | 359      |
|    total_timesteps  | 255280   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.58e-07 |
|    n_updates        | 63794    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4072     |
|    fps              | 710      |
|    time_elapsed     | 359      |
|    total_timesteps  | 255535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.76e-07 |
|    n_updates        | 63858    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4076     |
|    fps              | 709      |
|    time_elapsed     | 360      |
|    total_timesteps  | 255844   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.8e-07  |
|    n_updates        | 63935    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4080     |
|    fps              | 709      |
|    time_elapsed     | 360      |
|    total_timesteps  | 256089   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-07 |
|    n_updates        | 63997    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4084     |
|    fps              | 709      |
|    time_elapsed     | 361      |
|    total_timesteps  | 256372   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-07 |
|    n_updates        | 64067    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4088     |
|    fps              | 709      |
|    time_elapsed     | 361      |
|    total_timesteps  | 256696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-06 |
|    n_updates        | 64148    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4092     |
|    fps              | 709      |
|    time_elapsed     | 362      |
|    total_timesteps  | 256989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.32e-07 |
|    n_updates        | 64222    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4096     |
|    fps              | 709      |
|    time_elapsed     | 362      |
|    total_timesteps  | 257306   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.97e-07 |
|    n_updates        | 64301    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4100     |
|    fps              | 709      |
|    time_elapsed     | 362      |
|    total_timesteps  | 257452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.96e-07 |
|    n_updates        | 64337    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4104     |
|    fps              | 709      |
|    time_elapsed     | 363      |
|    total_timesteps  | 257672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.97e-07 |
|    n_updates        | 64392    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4108     |
|    fps              | 709      |
|    time_elapsed     | 363      |
|    total_timesteps  | 258053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.28e-07 |
|    n_updates        | 64488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4112     |
|    fps              | 708      |
|    time_elapsed     | 364      |
|    total_timesteps  | 258275   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.79e-07 |
|    n_updates        | 64543    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4116     |
|    fps              | 708      |
|    time_elapsed     | 364      |
|    total_timesteps  | 258530   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.38e-07 |
|    n_updates        | 64607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4120     |
|    fps              | 708      |
|    time_elapsed     | 365      |
|    total_timesteps  | 258796   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.38e-07 |
|    n_updates        | 64673    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4124     |
|    fps              | 708      |
|    time_elapsed     | 365      |
|    total_timesteps  | 259111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8e-07    |
|    n_updates        | 64752    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4128     |
|    fps              | 708      |
|    time_elapsed     | 366      |
|    total_timesteps  | 259452   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.33e-07 |
|    n_updates        | 64837    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4132     |
|    fps              | 708      |
|    time_elapsed     | 366      |
|    total_timesteps  | 259756   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.5e-06  |
|    n_updates        | 64913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4136     |
|    fps              | 708      |
|    time_elapsed     | 366      |
|    total_timesteps  | 260000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.6e-07  |
|    n_updates        | 64974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4140     |
|    fps              | 708      |
|    time_elapsed     | 367      |
|    total_timesteps  | 260312   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.47e-06 |
|    n_updates        | 65052    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4144     |
|    fps              | 708      |
|    time_elapsed     | 367      |
|    total_timesteps  | 260556   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.38e-07 |
|    n_updates        | 65113    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4148     |
|    fps              | 708      |
|    time_elapsed     | 367      |
|    total_timesteps  | 260763   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.15e-07 |
|    n_updates        | 65165    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4152     |
|    fps              | 708      |
|    time_elapsed     | 368      |
|    total_timesteps  | 260921   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.75e-08 |
|    n_updates        | 65205    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4156     |
|    fps              | 708      |
|    time_elapsed     | 368      |
|    total_timesteps  | 261203   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-07 |
|    n_updates        | 65275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4160     |
|    fps              | 708      |
|    time_elapsed     | 369      |
|    total_timesteps  | 261461   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.61e-09 |
|    n_updates        | 65340    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4164     |
|    fps              | 708      |
|    time_elapsed     | 369      |
|    total_timesteps  | 261740   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.36e-08 |
|    n_updates        | 65409    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4168     |
|    fps              | 708      |
|    time_elapsed     | 369      |
|    total_timesteps  | 262063   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.17e-08 |
|    n_updates        | 65490    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4172     |
|    fps              | 708      |
|    time_elapsed     | 370      |
|    total_timesteps  | 262458   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.69e-08 |
|    n_updates        | 65589    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4176     |
|    fps              | 708      |
|    time_elapsed     | 370      |
|    total_timesteps  | 262605   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.17e-08 |
|    n_updates        | 65626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4180     |
|    fps              | 708      |
|    time_elapsed     | 371      |
|    total_timesteps  | 262840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.87e-07 |
|    n_updates        | 65684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4184     |
|    fps              | 708      |
|    time_elapsed     | 371      |
|    total_timesteps  | 263160   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.55e-08 |
|    n_updates        | 65764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4188     |
|    fps              | 708      |
|    time_elapsed     | 372      |
|    total_timesteps  | 263504   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.23e-08 |
|    n_updates        | 65850    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4192     |
|    fps              | 707      |
|    time_elapsed     | 372      |
|    total_timesteps  | 263874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.89e-07 |
|    n_updates        | 65943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4196     |
|    fps              | 707      |
|    time_elapsed     | 372      |
|    total_timesteps  | 264000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.74e-08 |
|    n_updates        | 65974    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4200     |
|    fps              | 707      |
|    time_elapsed     | 373      |
|    total_timesteps  | 264276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.69e-08 |
|    n_updates        | 66043    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4204     |
|    fps              | 707      |
|    time_elapsed     | 373      |
|    total_timesteps  | 264421   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.12e-07 |
|    n_updates        | 66080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4208     |
|    fps              | 707      |
|    time_elapsed     | 374      |
|    total_timesteps  | 264644   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.02e-07 |
|    n_updates        | 66135    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4212     |
|    fps              | 707      |
|    time_elapsed     | 374      |
|    total_timesteps  | 264885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.03e-07 |
|    n_updates        | 66196    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4216     |
|    fps              | 707      |
|    time_elapsed     | 374      |
|    total_timesteps  | 265200   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.15e-08 |
|    n_updates        | 66274    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4220     |
|    fps              | 707      |
|    time_elapsed     | 375      |
|    total_timesteps  | 265433   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-07 |
|    n_updates        | 66333    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4224     |
|    fps              | 707      |
|    time_elapsed     | 375      |
|    total_timesteps  | 265723   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-07 |
|    n_updates        | 66405    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4228     |
|    fps              | 707      |
|    time_elapsed     | 375      |
|    total_timesteps  | 265959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.86e-07 |
|    n_updates        | 66464    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4232     |
|    fps              | 707      |
|    time_elapsed     | 376      |
|    total_timesteps  | 266116   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-06 |
|    n_updates        | 66503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4236     |
|    fps              | 707      |
|    time_elapsed     | 376      |
|    total_timesteps  | 266330   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.2e-07  |
|    n_updates        | 66557    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4240     |
|    fps              | 707      |
|    time_elapsed     | 376      |
|    total_timesteps  | 266605   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.85e-06 |
|    n_updates        | 66626    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4244     |
|    fps              | 707      |
|    time_elapsed     | 377      |
|    total_timesteps  | 266779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.31e-07 |
|    n_updates        | 66669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4248     |
|    fps              | 707      |
|    time_elapsed     | 377      |
|    total_timesteps  | 267051   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.26e-07 |
|    n_updates        | 66737    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4252     |
|    fps              | 707      |
|    time_elapsed     | 377      |
|    total_timesteps  | 267318   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-06 |
|    n_updates        | 66804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4256     |
|    fps              | 707      |
|    time_elapsed     | 378      |
|    total_timesteps  | 267630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.45e-07 |
|    n_updates        | 66882    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4260     |
|    fps              | 707      |
|    time_elapsed     | 378      |
|    total_timesteps  | 268027   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.62e-07 |
|    n_updates        | 66981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4264     |
|    fps              | 707      |
|    time_elapsed     | 379      |
|    total_timesteps  | 268219   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.36e-07 |
|    n_updates        | 67029    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4268     |
|    fps              | 707      |
|    time_elapsed     | 379      |
|    total_timesteps  | 268522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-06 |
|    n_updates        | 67105    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4272     |
|    fps              | 707      |
|    time_elapsed     | 379      |
|    total_timesteps  | 268807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.43e-06 |
|    n_updates        | 67176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4276     |
|    fps              | 707      |
|    time_elapsed     | 380      |
|    total_timesteps  | 269070   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.37e-07 |
|    n_updates        | 67242    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4280     |
|    fps              | 707      |
|    time_elapsed     | 380      |
|    total_timesteps  | 269301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.65e-07 |
|    n_updates        | 67300    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4284     |
|    fps              | 707      |
|    time_elapsed     | 381      |
|    total_timesteps  | 269512   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.46e-06 |
|    n_updates        | 67352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4288     |
|    fps              | 707      |
|    time_elapsed     | 381      |
|    total_timesteps  | 269696   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.69e-07 |
|    n_updates        | 67398    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4292     |
|    fps              | 707      |
|    time_elapsed     | 381      |
|    total_timesteps  | 269897   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.12e-06 |
|    n_updates        | 67449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4296     |
|    fps              | 706      |
|    time_elapsed     | 382      |
|    total_timesteps  | 270117   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.33e-06 |
|    n_updates        | 67504    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4300     |
|    fps              | 706      |
|    time_elapsed     | 382      |
|    total_timesteps  | 270517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.49e-07 |
|    n_updates        | 67604    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4304     |
|    fps              | 706      |
|    time_elapsed     | 382      |
|    total_timesteps  | 270720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.4e-07  |
|    n_updates        | 67654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4308     |
|    fps              | 706      |
|    time_elapsed     | 383      |
|    total_timesteps  | 270852   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.3e-08  |
|    n_updates        | 67687    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4312     |
|    fps              | 706      |
|    time_elapsed     | 383      |
|    total_timesteps  | 271004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.46e-08 |
|    n_updates        | 67725    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4316     |
|    fps              | 706      |
|    time_elapsed     | 383      |
|    total_timesteps  | 271060   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.88e-07 |
|    n_updates        | 67739    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4320     |
|    fps              | 706      |
|    time_elapsed     | 383      |
|    total_timesteps  | 271335   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.16e-08 |
|    n_updates        | 67808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4324     |
|    fps              | 706      |
|    time_elapsed     | 384      |
|    total_timesteps  | 271588   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-08 |
|    n_updates        | 67871    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4328     |
|    fps              | 706      |
|    time_elapsed     | 384      |
|    total_timesteps  | 271835   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.2e-08  |
|    n_updates        | 67933    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4332     |
|    fps              | 706      |
|    time_elapsed     | 385      |
|    total_timesteps  | 272160   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.46e-08 |
|    n_updates        | 68014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 60.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4336     |
|    fps              | 706      |
|    time_elapsed     | 385      |
|    total_timesteps  | 272393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.78e-08 |
|    n_updates        | 68073    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4340     |
|    fps              | 706      |
|    time_elapsed     | 385      |
|    total_timesteps  | 272560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.79e-08 |
|    n_updates        | 68114    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4344     |
|    fps              | 706      |
|    time_elapsed     | 386      |
|    total_timesteps  | 272759   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.08e-08 |
|    n_updates        | 68164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 58.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4348     |
|    fps              | 706      |
|    time_elapsed     | 386      |
|    total_timesteps  | 272890   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.9e-08  |
|    n_updates        | 68197    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4352     |
|    fps              | 706      |
|    time_elapsed     | 386      |
|    total_timesteps  | 273037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.74e-08 |
|    n_updates        | 68234    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4356     |
|    fps              | 706      |
|    time_elapsed     | 386      |
|    total_timesteps  | 273245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.73e-08 |
|    n_updates        | 68286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 53.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4360     |
|    fps              | 706      |
|    time_elapsed     | 387      |
|    total_timesteps  | 273396   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.59e-07 |
|    n_updates        | 68323    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4364     |
|    fps              | 706      |
|    time_elapsed     | 387      |
|    total_timesteps  | 273646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.06e-07 |
|    n_updates        | 68386    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4368     |
|    fps              | 706      |
|    time_elapsed     | 387      |
|    total_timesteps  | 273987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.31e-06 |
|    n_updates        | 68471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4372     |
|    fps              | 706      |
|    time_elapsed     | 388      |
|    total_timesteps  | 274218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.66e-07 |
|    n_updates        | 68529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4376     |
|    fps              | 706      |
|    time_elapsed     | 388      |
|    total_timesteps  | 274527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.39e-07 |
|    n_updates        | 68606    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 54.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4380     |
|    fps              | 706      |
|    time_elapsed     | 389      |
|    total_timesteps  | 274776   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.88e-07 |
|    n_updates        | 68668    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 55.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4384     |
|    fps              | 706      |
|    time_elapsed     | 389      |
|    total_timesteps  | 275082   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.74e-07 |
|    n_updates        | 68745    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4388     |
|    fps              | 706      |
|    time_elapsed     | 389      |
|    total_timesteps  | 275360   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.98e-07 |
|    n_updates        | 68814    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4392     |
|    fps              | 705      |
|    time_elapsed     | 390      |
|    total_timesteps  | 275676   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.47e-07 |
|    n_updates        | 68893    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4396     |
|    fps              | 705      |
|    time_elapsed     | 390      |
|    total_timesteps  | 275874   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.15e-07 |
|    n_updates        | 68943    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 56.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4400     |
|    fps              | 705      |
|    time_elapsed     | 391      |
|    total_timesteps  | 276167   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.63e-07 |
|    n_updates        | 69016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4404     |
|    fps              | 705      |
|    time_elapsed     | 391      |
|    total_timesteps  | 276427   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.05e-07 |
|    n_updates        | 69081    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 57.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4408     |
|    fps              | 705      |
|    time_elapsed     | 391      |
|    total_timesteps  | 276621   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.93e-07 |
|    n_updates        | 69130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 59       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4412     |
|    fps              | 705      |
|    time_elapsed     | 392      |
|    total_timesteps  | 276906   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.15e-07 |
|    n_updates        | 69201    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4416     |
|    fps              | 705      |
|    time_elapsed     | 392      |
|    total_timesteps  | 277269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.8e-07  |
|    n_updates        | 69292    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4420     |
|    fps              | 705      |
|    time_elapsed     | 393      |
|    total_timesteps  | 277444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.71e-07 |
|    n_updates        | 69335    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4424     |
|    fps              | 705      |
|    time_elapsed     | 393      |
|    total_timesteps  | 277844   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.72e-07 |
|    n_updates        | 69435    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4428     |
|    fps              | 705      |
|    time_elapsed     | 393      |
|    total_timesteps  | 278044   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.93e-06 |
|    n_updates        | 69485    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4432     |
|    fps              | 705      |
|    time_elapsed     | 394      |
|    total_timesteps  | 278290   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.59e-07 |
|    n_updates        | 69547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 61.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4436     |
|    fps              | 705      |
|    time_elapsed     | 394      |
|    total_timesteps  | 278509   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.18e-07 |
|    n_updates        | 69602    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4440     |
|    fps              | 705      |
|    time_elapsed     | 394      |
|    total_timesteps  | 278777   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.52e-06 |
|    n_updates        | 69669    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 62.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4444     |
|    fps              | 705      |
|    time_elapsed     | 395      |
|    total_timesteps  | 279038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.24e-07 |
|    n_updates        | 69734    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 63.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4448     |
|    fps              | 705      |
|    time_elapsed     | 395      |
|    total_timesteps  | 279266   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-06 |
|    n_updates        | 69791    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 64.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4452     |
|    fps              | 705      |
|    time_elapsed     | 395      |
|    total_timesteps  | 279465   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.25e-07 |
|    n_updates        | 69841    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4456     |
|    fps              | 705      |
|    time_elapsed     | 396      |
|    total_timesteps  | 279796   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.49e-07 |
|    n_updates        | 69923    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4460     |
|    fps              | 705      |
|    time_elapsed     | 396      |
|    total_timesteps  | 279943   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.23e-07 |
|    n_updates        | 69960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4464     |
|    fps              | 705      |
|    time_elapsed     | 397      |
|    total_timesteps  | 280256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-05  |
|    n_updates        | 70038    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4468     |
|    fps              | 705      |
|    time_elapsed     | 397      |
|    total_timesteps  | 280648   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.26e-07 |
|    n_updates        | 70136    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4472     |
|    fps              | 705      |
|    time_elapsed     | 398      |
|    total_timesteps  | 281000   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.33e-08 |
|    n_updates        | 70224    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4476     |
|    fps              | 705      |
|    time_elapsed     | 398      |
|    total_timesteps  | 281362   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.62e-08 |
|    n_updates        | 70315    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4480     |
|    fps              | 705      |
|    time_elapsed     | 399      |
|    total_timesteps  | 281762   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.44e-08 |
|    n_updates        | 70415    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4484     |
|    fps              | 705      |
|    time_elapsed     | 399      |
|    total_timesteps  | 282162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-07 |
|    n_updates        | 70515    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4488     |
|    fps              | 705      |
|    time_elapsed     | 400      |
|    total_timesteps  | 282562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.82e-08 |
|    n_updates        | 70615    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4492     |
|    fps              | 705      |
|    time_elapsed     | 401      |
|    total_timesteps  | 282962   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.02e-07 |
|    n_updates        | 70715    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4496     |
|    fps              | 705      |
|    time_elapsed     | 401      |
|    total_timesteps  | 283333   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.56e-07 |
|    n_updates        | 70808    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4500     |
|    fps              | 705      |
|    time_elapsed     | 402      |
|    total_timesteps  | 283627   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.91e-07 |
|    n_updates        | 70881    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4504     |
|    fps              | 705      |
|    time_elapsed     | 402      |
|    total_timesteps  | 284027   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.18e-07 |
|    n_updates        | 70981    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4508     |
|    fps              | 705      |
|    time_elapsed     | 402      |
|    total_timesteps  | 284292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.61e-07 |
|    n_updates        | 71047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4512     |
|    fps              | 705      |
|    time_elapsed     | 403      |
|    total_timesteps  | 284692   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.73e-06 |
|    n_updates        | 71147    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4516     |
|    fps              | 705      |
|    time_elapsed     | 403      |
|    total_timesteps  | 285045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.68e-07 |
|    n_updates        | 71236    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4520     |
|    fps              | 705      |
|    time_elapsed     | 404      |
|    total_timesteps  | 285337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.43e-06 |
|    n_updates        | 71309    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4524     |
|    fps              | 705      |
|    time_elapsed     | 404      |
|    total_timesteps  | 285607   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.78e-07 |
|    n_updates        | 71376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4528     |
|    fps              | 705      |
|    time_elapsed     | 405      |
|    total_timesteps  | 285894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.25e-07 |
|    n_updates        | 71448    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4532     |
|    fps              | 705      |
|    time_elapsed     | 405      |
|    total_timesteps  | 286292   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.85e-07 |
|    n_updates        | 71547    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4536     |
|    fps              | 705      |
|    time_elapsed     | 406      |
|    total_timesteps  | 286628   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.97e-07 |
|    n_updates        | 71631    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4540     |
|    fps              | 705      |
|    time_elapsed     | 406      |
|    total_timesteps  | 286853   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.15e-07 |
|    n_updates        | 71688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4544     |
|    fps              | 705      |
|    time_elapsed     | 406      |
|    total_timesteps  | 287099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.56e-07 |
|    n_updates        | 71749    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4548     |
|    fps              | 705      |
|    time_elapsed     | 407      |
|    total_timesteps  | 287432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.78e-07 |
|    n_updates        | 71832    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4552     |
|    fps              | 705      |
|    time_elapsed     | 407      |
|    total_timesteps  | 287761   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.05e-07 |
|    n_updates        | 71915    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4556     |
|    fps              | 705      |
|    time_elapsed     | 408      |
|    total_timesteps  | 288122   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.13e-07 |
|    n_updates        | 72005    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4560     |
|    fps              | 705      |
|    time_elapsed     | 408      |
|    total_timesteps  | 288423   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-07 |
|    n_updates        | 72080    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4564     |
|    fps              | 705      |
|    time_elapsed     | 409      |
|    total_timesteps  | 288823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.73e-07 |
|    n_updates        | 72180    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4568     |
|    fps              | 705      |
|    time_elapsed     | 409      |
|    total_timesteps  | 289136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.85e-07 |
|    n_updates        | 72258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4572     |
|    fps              | 705      |
|    time_elapsed     | 410      |
|    total_timesteps  | 289515   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.72e-07 |
|    n_updates        | 72353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4576     |
|    fps              | 705      |
|    time_elapsed     | 411      |
|    total_timesteps  | 289814   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-06 |
|    n_updates        | 72428    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4580     |
|    fps              | 705      |
|    time_elapsed     | 411      |
|    total_timesteps  | 290132   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.95e-06 |
|    n_updates        | 72507    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4584     |
|    fps              | 705      |
|    time_elapsed     | 411      |
|    total_timesteps  | 290532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.16e-07 |
|    n_updates        | 72607    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4588     |
|    fps              | 705      |
|    time_elapsed     | 412      |
|    total_timesteps  | 290920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.51e-07 |
|    n_updates        | 72704    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4592     |
|    fps              | 705      |
|    time_elapsed     | 413      |
|    total_timesteps  | 291320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.03e-07 |
|    n_updates        | 72804    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4596     |
|    fps              | 705      |
|    time_elapsed     | 413      |
|    total_timesteps  | 291720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.38e-07 |
|    n_updates        | 72904    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4600     |
|    fps              | 705      |
|    time_elapsed     | 414      |
|    total_timesteps  | 292120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.01e-08 |
|    n_updates        | 73004    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4604     |
|    fps              | 705      |
|    time_elapsed     | 414      |
|    total_timesteps  | 292520   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.18e-07 |
|    n_updates        | 73104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4608     |
|    fps              | 705      |
|    time_elapsed     | 415      |
|    total_timesteps  | 292920   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.01e-08 |
|    n_updates        | 73204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4612     |
|    fps              | 705      |
|    time_elapsed     | 415      |
|    total_timesteps  | 293320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.45e-07 |
|    n_updates        | 73304    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4616     |
|    fps              | 705      |
|    time_elapsed     | 416      |
|    total_timesteps  | 293720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.99e-07 |
|    n_updates        | 73404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4620     |
|    fps              | 705      |
|    time_elapsed     | 416      |
|    total_timesteps  | 294039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.48e-06 |
|    n_updates        | 73484    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4624     |
|    fps              | 705      |
|    time_elapsed     | 417      |
|    total_timesteps  | 294439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.78e-07 |
|    n_updates        | 73584    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4628     |
|    fps              | 705      |
|    time_elapsed     | 418      |
|    total_timesteps  | 294839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 73684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4632     |
|    fps              | 704      |
|    time_elapsed     | 418      |
|    total_timesteps  | 295239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.44e-07 |
|    n_updates        | 73784    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4636     |
|    fps              | 704      |
|    time_elapsed     | 419      |
|    total_timesteps  | 295639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.28e-07 |
|    n_updates        | 73884    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4640     |
|    fps              | 704      |
|    time_elapsed     | 419      |
|    total_timesteps  | 296039   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.25e-07 |
|    n_updates        | 73984    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4644     |
|    fps              | 704      |
|    time_elapsed     | 420      |
|    total_timesteps  | 296439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.48e-07 |
|    n_updates        | 74084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4648     |
|    fps              | 704      |
|    time_elapsed     | 421      |
|    total_timesteps  | 296839   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.4e-07  |
|    n_updates        | 74184    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4652     |
|    fps              | 704      |
|    time_elapsed     | 421      |
|    total_timesteps  | 297239   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-06 |
|    n_updates        | 74284    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4656     |
|    fps              | 704      |
|    time_elapsed     | 422      |
|    total_timesteps  | 297639   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.99e-06 |
|    n_updates        | 74384    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4660     |
|    fps              | 704      |
|    time_elapsed     | 422      |
|    total_timesteps  | 297994   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.2e-07  |
|    n_updates        | 74473    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4664     |
|    fps              | 705      |
|    time_elapsed     | 423      |
|    total_timesteps  | 298355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.92e-06 |
|    n_updates        | 74563    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4668     |
|    fps              | 705      |
|    time_elapsed     | 423      |
|    total_timesteps  | 298755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.56e-07 |
|    n_updates        | 74663    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4672     |
|    fps              | 705      |
|    time_elapsed     | 424      |
|    total_timesteps  | 299155   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.93e-07 |
|    n_updates        | 74763    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4676     |
|    fps              | 705      |
|    time_elapsed     | 424      |
|    total_timesteps  | 299555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.22e-07 |
|    n_updates        | 74863    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4680     |
|    fps              | 705      |
|    time_elapsed     | 425      |
|    total_timesteps  | 299955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.9e-06  |
|    n_updates        | 74963    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4684     |
|    fps              | 705      |
|    time_elapsed     | 425      |
|    total_timesteps  | 300339   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-06 |
|    n_updates        | 75059    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4688     |
|    fps              | 705      |
|    time_elapsed     | 426      |
|    total_timesteps  | 300733   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.27e-07 |
|    n_updates        | 75158    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4692     |
|    fps              | 705      |
|    time_elapsed     | 426      |
|    total_timesteps  | 301098   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.47e-07 |
|    n_updates        | 75249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4696     |
|    fps              | 705      |
|    time_elapsed     | 427      |
|    total_timesteps  | 301498   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.13e-08 |
|    n_updates        | 75349    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4700     |
|    fps              | 705      |
|    time_elapsed     | 428      |
|    total_timesteps  | 301898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.25e-08 |
|    n_updates        | 75449    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4704     |
|    fps              | 705      |
|    time_elapsed     | 428      |
|    total_timesteps  | 302298   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.81e-08 |
|    n_updates        | 75549    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4708     |
|    fps              | 705      |
|    time_elapsed     | 429      |
|    total_timesteps  | 302646   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-07 |
|    n_updates        | 75636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4712     |
|    fps              | 705      |
|    time_elapsed     | 429      |
|    total_timesteps  | 303029   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.36e-08 |
|    n_updates        | 75732    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4716     |
|    fps              | 705      |
|    time_elapsed     | 430      |
|    total_timesteps  | 303423   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.35e-07 |
|    n_updates        | 75830    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4720     |
|    fps              | 705      |
|    time_elapsed     | 430      |
|    total_timesteps  | 303823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.74e-07 |
|    n_updates        | 75930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4724     |
|    fps              | 705      |
|    time_elapsed     | 431      |
|    total_timesteps  | 304223   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 76030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4728     |
|    fps              | 705      |
|    time_elapsed     | 431      |
|    total_timesteps  | 304486   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.14e-06 |
|    n_updates        | 76096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4732     |
|    fps              | 705      |
|    time_elapsed     | 432      |
|    total_timesteps  | 304830   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.88e-06 |
|    n_updates        | 76182    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4736     |
|    fps              | 705      |
|    time_elapsed     | 432      |
|    total_timesteps  | 305185   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.93e-07 |
|    n_updates        | 76271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4740     |
|    fps              | 705      |
|    time_elapsed     | 433      |
|    total_timesteps  | 305585   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.43e-07 |
|    n_updates        | 76371    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4744     |
|    fps              | 705      |
|    time_elapsed     | 433      |
|    total_timesteps  | 305985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.08e-07 |
|    n_updates        | 76471    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4748     |
|    fps              | 705      |
|    time_elapsed     | 434      |
|    total_timesteps  | 306385   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.88e-08 |
|    n_updates        | 76571    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4752     |
|    fps              | 705      |
|    time_elapsed     | 434      |
|    total_timesteps  | 306785   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.55e-07 |
|    n_updates        | 76671    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4756     |
|    fps              | 705      |
|    time_elapsed     | 435      |
|    total_timesteps  | 307176   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.07e-07 |
|    n_updates        | 76768    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4760     |
|    fps              | 705      |
|    time_elapsed     | 436      |
|    total_timesteps  | 307569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-06 |
|    n_updates        | 76867    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4764     |
|    fps              | 705      |
|    time_elapsed     | 436      |
|    total_timesteps  | 307941   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.39e-07 |
|    n_updates        | 76960    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4768     |
|    fps              | 705      |
|    time_elapsed     | 437      |
|    total_timesteps  | 308341   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.31e-07 |
|    n_updates        | 77060    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4772     |
|    fps              | 705      |
|    time_elapsed     | 437      |
|    total_timesteps  | 308699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.43e-07 |
|    n_updates        | 77149    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4776     |
|    fps              | 705      |
|    time_elapsed     | 438      |
|    total_timesteps  | 309099   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.4e-06  |
|    n_updates        | 77249    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4780     |
|    fps              | 705      |
|    time_elapsed     | 438      |
|    total_timesteps  | 309484   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.07e-07 |
|    n_updates        | 77345    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4784     |
|    fps              | 704      |
|    time_elapsed     | 439      |
|    total_timesteps  | 309833   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-06 |
|    n_updates        | 77433    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4788     |
|    fps              | 704      |
|    time_elapsed     | 440      |
|    total_timesteps  | 310167   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.88e-06 |
|    n_updates        | 77516    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4792     |
|    fps              | 704      |
|    time_elapsed     | 440      |
|    total_timesteps  | 310567   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.15e-07 |
|    n_updates        | 77616    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4796     |
|    fps              | 704      |
|    time_elapsed     | 441      |
|    total_timesteps  | 310953   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.5e-07  |
|    n_updates        | 77713    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4800     |
|    fps              | 704      |
|    time_elapsed     | 441      |
|    total_timesteps  | 311249   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.21e-07 |
|    n_updates        | 77787    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4804     |
|    fps              | 704      |
|    time_elapsed     | 442      |
|    total_timesteps  | 311589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.83e-07 |
|    n_updates        | 77872    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4808     |
|    fps              | 704      |
|    time_elapsed     | 442      |
|    total_timesteps  | 311989   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.87e-07 |
|    n_updates        | 77972    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4812     |
|    fps              | 704      |
|    time_elapsed     | 443      |
|    total_timesteps  | 312389   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.64e-08 |
|    n_updates        | 78072    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4816     |
|    fps              | 704      |
|    time_elapsed     | 443      |
|    total_timesteps  | 312724   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.4e-08  |
|    n_updates        | 78155    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4820     |
|    fps              | 704      |
|    time_elapsed     | 444      |
|    total_timesteps  | 312979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.38e-07 |
|    n_updates        | 78219    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4824     |
|    fps              | 703      |
|    time_elapsed     | 445      |
|    total_timesteps  | 313379   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-07 |
|    n_updates        | 78319    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4828     |
|    fps              | 703      |
|    time_elapsed     | 445      |
|    total_timesteps  | 313779   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-07  |
|    n_updates        | 78419    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4832     |
|    fps              | 703      |
|    time_elapsed     | 446      |
|    total_timesteps  | 314103   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.24e-07 |
|    n_updates        | 78500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4836     |
|    fps              | 703      |
|    time_elapsed     | 447      |
|    total_timesteps  | 314477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.36e-07 |
|    n_updates        | 78594    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4840     |
|    fps              | 703      |
|    time_elapsed     | 447      |
|    total_timesteps  | 314828   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-06 |
|    n_updates        | 78681    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4844     |
|    fps              | 702      |
|    time_elapsed     | 448      |
|    total_timesteps  | 315218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.59e-06 |
|    n_updates        | 78779    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4848     |
|    fps              | 702      |
|    time_elapsed     | 448      |
|    total_timesteps  | 315564   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.75e-06 |
|    n_updates        | 78865    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4852     |
|    fps              | 702      |
|    time_elapsed     | 449      |
|    total_timesteps  | 315964   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.16e-07 |
|    n_updates        | 78965    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4856     |
|    fps              | 702      |
|    time_elapsed     | 450      |
|    total_timesteps  | 316354   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.04e-07 |
|    n_updates        | 79063    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4860     |
|    fps              | 702      |
|    time_elapsed     | 450      |
|    total_timesteps  | 316754   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-06 |
|    n_updates        | 79163    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4864     |
|    fps              | 702      |
|    time_elapsed     | 451      |
|    total_timesteps  | 317135   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-06 |
|    n_updates        | 79258    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4868     |
|    fps              | 702      |
|    time_elapsed     | 451      |
|    total_timesteps  | 317535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.91e-06 |
|    n_updates        | 79358    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4872     |
|    fps              | 702      |
|    time_elapsed     | 452      |
|    total_timesteps  | 317859   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.27e-06 |
|    n_updates        | 79439    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4876     |
|    fps              | 702      |
|    time_elapsed     | 452      |
|    total_timesteps  | 318218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.65e-07 |
|    n_updates        | 79529    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4880     |
|    fps              | 702      |
|    time_elapsed     | 453      |
|    total_timesteps  | 318618   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.81e-07 |
|    n_updates        | 79629    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4884     |
|    fps              | 702      |
|    time_elapsed     | 454      |
|    total_timesteps  | 319018   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.73e-07 |
|    n_updates        | 79729    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4888     |
|    fps              | 702      |
|    time_elapsed     | 454      |
|    total_timesteps  | 319355   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.78e-07 |
|    n_updates        | 79813    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4892     |
|    fps              | 702      |
|    time_elapsed     | 455      |
|    total_timesteps  | 319755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-07 |
|    n_updates        | 79913    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4896     |
|    fps              | 702      |
|    time_elapsed     | 455      |
|    total_timesteps  | 320155   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.31e-05 |
|    n_updates        | 80013    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4900     |
|    fps              | 702      |
|    time_elapsed     | 456      |
|    total_timesteps  | 320517   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.22e-06 |
|    n_updates        | 80104    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4904     |
|    fps              | 702      |
|    time_elapsed     | 456      |
|    total_timesteps  | 320917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.72e-07 |
|    n_updates        | 80204    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4908     |
|    fps              | 702      |
|    time_elapsed     | 457      |
|    total_timesteps  | 321317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-08 |
|    n_updates        | 80304    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4912     |
|    fps              | 702      |
|    time_elapsed     | 457      |
|    total_timesteps  | 321717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.14e-07 |
|    n_updates        | 80404    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4916     |
|    fps              | 702      |
|    time_elapsed     | 458      |
|    total_timesteps  | 322056   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.14e-08 |
|    n_updates        | 80488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4920     |
|    fps              | 702      |
|    time_elapsed     | 459      |
|    total_timesteps  | 322456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.83e-08 |
|    n_updates        | 80588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4924     |
|    fps              | 702      |
|    time_elapsed     | 459      |
|    total_timesteps  | 322856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.58e-09 |
|    n_updates        | 80688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4928     |
|    fps              | 702      |
|    time_elapsed     | 460      |
|    total_timesteps  | 323256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.78e-08 |
|    n_updates        | 80788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4932     |
|    fps              | 702      |
|    time_elapsed     | 460      |
|    total_timesteps  | 323656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.93e-08 |
|    n_updates        | 80888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4936     |
|    fps              | 702      |
|    time_elapsed     | 461      |
|    total_timesteps  | 324056   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.77e-07 |
|    n_updates        | 80988    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4940     |
|    fps              | 702      |
|    time_elapsed     | 461      |
|    total_timesteps  | 324456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.45e-07 |
|    n_updates        | 81088    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4944     |
|    fps              | 702      |
|    time_elapsed     | 462      |
|    total_timesteps  | 324856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.46e-07 |
|    n_updates        | 81188    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4948     |
|    fps              | 702      |
|    time_elapsed     | 462      |
|    total_timesteps  | 325256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.9e-07  |
|    n_updates        | 81288    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4952     |
|    fps              | 702      |
|    time_elapsed     | 463      |
|    total_timesteps  | 325656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.77e-07 |
|    n_updates        | 81388    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4956     |
|    fps              | 702      |
|    time_elapsed     | 463      |
|    total_timesteps  | 326056   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.47e-06 |
|    n_updates        | 81488    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4960     |
|    fps              | 702      |
|    time_elapsed     | 464      |
|    total_timesteps  | 326456   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.74e-06 |
|    n_updates        | 81588    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4964     |
|    fps              | 702      |
|    time_elapsed     | 465      |
|    total_timesteps  | 326856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.7e-06  |
|    n_updates        | 81688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4968     |
|    fps              | 702      |
|    time_elapsed     | 465      |
|    total_timesteps  | 327256   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.96e-06 |
|    n_updates        | 81788    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4972     |
|    fps              | 702      |
|    time_elapsed     | 466      |
|    total_timesteps  | 327656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-06 |
|    n_updates        | 81888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4976     |
|    fps              | 702      |
|    time_elapsed     | 466      |
|    total_timesteps  | 328045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.73e-07 |
|    n_updates        | 81986    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4980     |
|    fps              | 702      |
|    time_elapsed     | 467      |
|    total_timesteps  | 328445   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.9e-07  |
|    n_updates        | 82086    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4984     |
|    fps              | 702      |
|    time_elapsed     | 467      |
|    total_timesteps  | 328845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.3e-07  |
|    n_updates        | 82186    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4988     |
|    fps              | 702      |
|    time_elapsed     | 468      |
|    total_timesteps  | 329245   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.73e-06 |
|    n_updates        | 82286    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4992     |
|    fps              | 702      |
|    time_elapsed     | 468      |
|    total_timesteps  | 329477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-06  |
|    n_updates        | 82344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 4996     |
|    fps              | 702      |
|    time_elapsed     | 469      |
|    total_timesteps  | 329797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.21e-07 |
|    n_updates        | 82424    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5000     |
|    fps              | 702      |
|    time_elapsed     | 469      |
|    total_timesteps  | 330145   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.65e-06 |
|    n_updates        | 82511    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5004     |
|    fps              | 702      |
|    time_elapsed     | 470      |
|    total_timesteps  | 330545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.18e-07 |
|    n_updates        | 82611    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5008     |
|    fps              | 702      |
|    time_elapsed     | 470      |
|    total_timesteps  | 330945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.63e-07 |
|    n_updates        | 82711    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5012     |
|    fps              | 702      |
|    time_elapsed     | 471      |
|    total_timesteps  | 331345   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.54e-08 |
|    n_updates        | 82811    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5016     |
|    fps              | 702      |
|    time_elapsed     | 472      |
|    total_timesteps  | 331745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-07  |
|    n_updates        | 82911    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5020     |
|    fps              | 702      |
|    time_elapsed     | 472      |
|    total_timesteps  | 332145   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.02e-08 |
|    n_updates        | 83011    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5024     |
|    fps              | 702      |
|    time_elapsed     | 473      |
|    total_timesteps  | 332545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.57e-08 |
|    n_updates        | 83111    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5028     |
|    fps              | 702      |
|    time_elapsed     | 473      |
|    total_timesteps  | 332913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.76e-08 |
|    n_updates        | 83203    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5032     |
|    fps              | 702      |
|    time_elapsed     | 474      |
|    total_timesteps  | 333313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.46e-08 |
|    n_updates        | 83303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5036     |
|    fps              | 702      |
|    time_elapsed     | 475      |
|    total_timesteps  | 333713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.42e-07 |
|    n_updates        | 83403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5040     |
|    fps              | 702      |
|    time_elapsed     | 475      |
|    total_timesteps  | 334113   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.17e-07 |
|    n_updates        | 83503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5044     |
|    fps              | 702      |
|    time_elapsed     | 476      |
|    total_timesteps  | 334513   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.14e-06 |
|    n_updates        | 83603    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5048     |
|    fps              | 702      |
|    time_elapsed     | 476      |
|    total_timesteps  | 334913   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.89e-07 |
|    n_updates        | 83703    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5052     |
|    fps              | 702      |
|    time_elapsed     | 477      |
|    total_timesteps  | 335313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.3e-06  |
|    n_updates        | 83803    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5056     |
|    fps              | 702      |
|    time_elapsed     | 477      |
|    total_timesteps  | 335604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.9e-06  |
|    n_updates        | 83875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5060     |
|    fps              | 702      |
|    time_elapsed     | 478      |
|    total_timesteps  | 336004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.69e-07 |
|    n_updates        | 83975    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5064     |
|    fps              | 702      |
|    time_elapsed     | 478      |
|    total_timesteps  | 336404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.21e-07 |
|    n_updates        | 84075    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5068     |
|    fps              | 702      |
|    time_elapsed     | 479      |
|    total_timesteps  | 336804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.13e-07 |
|    n_updates        | 84175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5072     |
|    fps              | 702      |
|    time_elapsed     | 480      |
|    total_timesteps  | 337204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-07 |
|    n_updates        | 84275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5076     |
|    fps              | 702      |
|    time_elapsed     | 480      |
|    total_timesteps  | 337604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.41e-07 |
|    n_updates        | 84375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5080     |
|    fps              | 702      |
|    time_elapsed     | 481      |
|    total_timesteps  | 338004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 84475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5084     |
|    fps              | 702      |
|    time_elapsed     | 481      |
|    total_timesteps  | 338404   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.45e-07 |
|    n_updates        | 84575    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5088     |
|    fps              | 701      |
|    time_elapsed     | 482      |
|    total_timesteps  | 338804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.34e-06 |
|    n_updates        | 84675    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5092     |
|    fps              | 701      |
|    time_elapsed     | 483      |
|    total_timesteps  | 339204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.13e-07 |
|    n_updates        | 84775    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5096     |
|    fps              | 701      |
|    time_elapsed     | 483      |
|    total_timesteps  | 339604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.3e-06  |
|    n_updates        | 84875    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5100     |
|    fps              | 701      |
|    time_elapsed     | 484      |
|    total_timesteps  | 339949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-06 |
|    n_updates        | 84962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5104     |
|    fps              | 701      |
|    time_elapsed     | 484      |
|    total_timesteps  | 340349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 85062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5108     |
|    fps              | 701      |
|    time_elapsed     | 485      |
|    total_timesteps  | 340749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.77e-07 |
|    n_updates        | 85162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5112     |
|    fps              | 701      |
|    time_elapsed     | 486      |
|    total_timesteps  | 341149   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.96e-08 |
|    n_updates        | 85262    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5116     |
|    fps              | 701      |
|    time_elapsed     | 486      |
|    total_timesteps  | 341549   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.13e-08 |
|    n_updates        | 85362    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5120     |
|    fps              | 701      |
|    time_elapsed     | 487      |
|    total_timesteps  | 341949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.07e-08 |
|    n_updates        | 85462    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5124     |
|    fps              | 701      |
|    time_elapsed     | 487      |
|    total_timesteps  | 342349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-07 |
|    n_updates        | 85562    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5128     |
|    fps              | 701      |
|    time_elapsed     | 488      |
|    total_timesteps  | 342749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-07 |
|    n_updates        | 85662    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5132     |
|    fps              | 702      |
|    time_elapsed     | 488      |
|    total_timesteps  | 343149   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.73e-07 |
|    n_updates        | 85762    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5136     |
|    fps              | 702      |
|    time_elapsed     | 489      |
|    total_timesteps  | 343549   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.32e-07 |
|    n_updates        | 85862    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5140     |
|    fps              | 702      |
|    time_elapsed     | 489      |
|    total_timesteps  | 343949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.82e-08 |
|    n_updates        | 85962    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5144     |
|    fps              | 701      |
|    time_elapsed     | 490      |
|    total_timesteps  | 344349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.41e-08 |
|    n_updates        | 86062    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 98.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5148     |
|    fps              | 701      |
|    time_elapsed     | 491      |
|    total_timesteps  | 344749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.77e-07 |
|    n_updates        | 86162    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5152     |
|    fps              | 701      |
|    time_elapsed     | 491      |
|    total_timesteps  | 345023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.1e-07  |
|    n_updates        | 86230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5156     |
|    fps              | 701      |
|    time_elapsed     | 491      |
|    total_timesteps  | 345313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.16e-06 |
|    n_updates        | 86303    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5160     |
|    fps              | 702      |
|    time_elapsed     | 492      |
|    total_timesteps  | 345713   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-06 |
|    n_updates        | 86403    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 97.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5164     |
|    fps              | 702      |
|    time_elapsed     | 492      |
|    total_timesteps  | 346113   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.6e-06  |
|    n_updates        | 86503    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5168     |
|    fps              | 702      |
|    time_elapsed     | 493      |
|    total_timesteps  | 346412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.78e-07 |
|    n_updates        | 86577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5172     |
|    fps              | 701      |
|    time_elapsed     | 494      |
|    total_timesteps  | 346812   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.15e-07 |
|    n_updates        | 86677    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5176     |
|    fps              | 701      |
|    time_elapsed     | 494      |
|    total_timesteps  | 347212   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.9e-07  |
|    n_updates        | 86777    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5180     |
|    fps              | 701      |
|    time_elapsed     | 495      |
|    total_timesteps  | 347612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.71e-07 |
|    n_updates        | 86877    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5184     |
|    fps              | 701      |
|    time_elapsed     | 495      |
|    total_timesteps  | 348012   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.87e-06 |
|    n_updates        | 86977    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5188     |
|    fps              | 701      |
|    time_elapsed     | 496      |
|    total_timesteps  | 348412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.55e-07 |
|    n_updates        | 87077    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5192     |
|    fps              | 701      |
|    time_elapsed     | 496      |
|    total_timesteps  | 348807   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.34e-07 |
|    n_updates        | 87176    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5196     |
|    fps              | 701      |
|    time_elapsed     | 497      |
|    total_timesteps  | 349207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.85e-07 |
|    n_updates        | 87276    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5200     |
|    fps              | 701      |
|    time_elapsed     | 498      |
|    total_timesteps  | 349607   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-06 |
|    n_updates        | 87376    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5204     |
|    fps              | 701      |
|    time_elapsed     | 498      |
|    total_timesteps  | 350007   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.27e-05 |
|    n_updates        | 87476    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5208     |
|    fps              | 701      |
|    time_elapsed     | 499      |
|    total_timesteps  | 350358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.76e-06 |
|    n_updates        | 87564    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5212     |
|    fps              | 701      |
|    time_elapsed     | 499      |
|    total_timesteps  | 350758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-07 |
|    n_updates        | 87664    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5216     |
|    fps              | 701      |
|    time_elapsed     | 500      |
|    total_timesteps  | 351158   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-07 |
|    n_updates        | 87764    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5220     |
|    fps              | 701      |
|    time_elapsed     | 501      |
|    total_timesteps  | 351558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.2e-08  |
|    n_updates        | 87864    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5224     |
|    fps              | 701      |
|    time_elapsed     | 501      |
|    total_timesteps  | 351958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.29e-07 |
|    n_updates        | 87964    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5228     |
|    fps              | 701      |
|    time_elapsed     | 502      |
|    total_timesteps  | 352358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.28e-07 |
|    n_updates        | 88064    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5232     |
|    fps              | 701      |
|    time_elapsed     | 502      |
|    total_timesteps  | 352758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.77e-08 |
|    n_updates        | 88164    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5236     |
|    fps              | 701      |
|    time_elapsed     | 503      |
|    total_timesteps  | 353158   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.42e-07 |
|    n_updates        | 88264    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5240     |
|    fps              | 701      |
|    time_elapsed     | 503      |
|    total_timesteps  | 353527   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.06e-07 |
|    n_updates        | 88356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5244     |
|    fps              | 701      |
|    time_elapsed     | 504      |
|    total_timesteps  | 353862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.54e-06 |
|    n_updates        | 88440    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5248     |
|    fps              | 701      |
|    time_elapsed     | 504      |
|    total_timesteps  | 354262   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.6e-07  |
|    n_updates        | 88540    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5252     |
|    fps              | 701      |
|    time_elapsed     | 505      |
|    total_timesteps  | 354662   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.32e-06 |
|    n_updates        | 88640    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5256     |
|    fps              | 701      |
|    time_elapsed     | 505      |
|    total_timesteps  | 354959   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.02e-07 |
|    n_updates        | 88714    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5260     |
|    fps              | 701      |
|    time_elapsed     | 506      |
|    total_timesteps  | 355272   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.47e-07 |
|    n_updates        | 88792    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5264     |
|    fps              | 701      |
|    time_elapsed     | 506      |
|    total_timesteps  | 355672   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.93e-07 |
|    n_updates        | 88892    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5268     |
|    fps              | 701      |
|    time_elapsed     | 507      |
|    total_timesteps  | 356072   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.9e-07  |
|    n_updates        | 88992    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5272     |
|    fps              | 701      |
|    time_elapsed     | 507      |
|    total_timesteps  | 356472   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.12e-07 |
|    n_updates        | 89092    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5276     |
|    fps              | 701      |
|    time_elapsed     | 508      |
|    total_timesteps  | 356788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.83e-07 |
|    n_updates        | 89171    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5280     |
|    fps              | 701      |
|    time_elapsed     | 508      |
|    total_timesteps  | 357188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9e-07    |
|    n_updates        | 89271    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5284     |
|    fps              | 701      |
|    time_elapsed     | 509      |
|    total_timesteps  | 357514   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.68e-06 |
|    n_updates        | 89353    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5288     |
|    fps              | 701      |
|    time_elapsed     | 509      |
|    total_timesteps  | 357914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.49e-07 |
|    n_updates        | 89453    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5292     |
|    fps              | 702      |
|    time_elapsed     | 510      |
|    total_timesteps  | 358314   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.48e-07 |
|    n_updates        | 89553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5296     |
|    fps              | 702      |
|    time_elapsed     | 510      |
|    total_timesteps  | 358714   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.8e-06  |
|    n_updates        | 89653    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5300     |
|    fps              | 702      |
|    time_elapsed     | 511      |
|    total_timesteps  | 359114   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.79e-06 |
|    n_updates        | 89753    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5304     |
|    fps              | 702      |
|    time_elapsed     | 512      |
|    total_timesteps  | 359491   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-06  |
|    n_updates        | 89847    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5308     |
|    fps              | 702      |
|    time_elapsed     | 512      |
|    total_timesteps  | 359823   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-06 |
|    n_updates        | 89930    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5312     |
|    fps              | 702      |
|    time_elapsed     | 513      |
|    total_timesteps  | 360223   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.61e-06 |
|    n_updates        | 90030    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5316     |
|    fps              | 702      |
|    time_elapsed     | 513      |
|    total_timesteps  | 360623   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.26e-07 |
|    n_updates        | 90130    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5320     |
|    fps              | 702      |
|    time_elapsed     | 514      |
|    total_timesteps  | 361023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.05e-07 |
|    n_updates        | 90230    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5324     |
|    fps              | 702      |
|    time_elapsed     | 514      |
|    total_timesteps  | 361371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.78e-08 |
|    n_updates        | 90317    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5328     |
|    fps              | 701      |
|    time_elapsed     | 515      |
|    total_timesteps  | 361771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.35e-08 |
|    n_updates        | 90417    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5332     |
|    fps              | 701      |
|    time_elapsed     | 515      |
|    total_timesteps  | 362171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-07 |
|    n_updates        | 90517    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5336     |
|    fps              | 701      |
|    time_elapsed     | 516      |
|    total_timesteps  | 362571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.49e-08 |
|    n_updates        | 90617    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5340     |
|    fps              | 701      |
|    time_elapsed     | 517      |
|    total_timesteps  | 362971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.69e-08 |
|    n_updates        | 90717    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5344     |
|    fps              | 701      |
|    time_elapsed     | 517      |
|    total_timesteps  | 363371   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.06e-08 |
|    n_updates        | 90817    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5348     |
|    fps              | 701      |
|    time_elapsed     | 518      |
|    total_timesteps  | 363771   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.71e-08 |
|    n_updates        | 90917    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5352     |
|    fps              | 701      |
|    time_elapsed     | 519      |
|    total_timesteps  | 364171   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.92e-07 |
|    n_updates        | 91017    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5356     |
|    fps              | 701      |
|    time_elapsed     | 519      |
|    total_timesteps  | 364571   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.64e-06 |
|    n_updates        | 91117    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5360     |
|    fps              | 701      |
|    time_elapsed     | 520      |
|    total_timesteps  | 364953   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.89e-06 |
|    n_updates        | 91213    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5364     |
|    fps              | 701      |
|    time_elapsed     | 520      |
|    total_timesteps  | 365260   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.08e-06 |
|    n_updates        | 91289    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5368     |
|    fps              | 701      |
|    time_elapsed     | 521      |
|    total_timesteps  | 365602   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.66e-07 |
|    n_updates        | 91375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5372     |
|    fps              | 701      |
|    time_elapsed     | 521      |
|    total_timesteps  | 366002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.11e-07 |
|    n_updates        | 91475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5376     |
|    fps              | 701      |
|    time_elapsed     | 522      |
|    total_timesteps  | 366320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.02e-07 |
|    n_updates        | 91554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5380     |
|    fps              | 701      |
|    time_elapsed     | 523      |
|    total_timesteps  | 366720   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.27e-07 |
|    n_updates        | 91654    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 96.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5384     |
|    fps              | 700      |
|    time_elapsed     | 523      |
|    total_timesteps  | 367120   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.42e-06 |
|    n_updates        | 91754    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5388     |
|    fps              | 700      |
|    time_elapsed     | 524      |
|    total_timesteps  | 367460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.46e-06 |
|    n_updates        | 91839    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5392     |
|    fps              | 700      |
|    time_elapsed     | 524      |
|    total_timesteps  | 367860   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.03e-07 |
|    n_updates        | 91939    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5396     |
|    fps              | 700      |
|    time_elapsed     | 525      |
|    total_timesteps  | 368226   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-07 |
|    n_updates        | 92031    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5400     |
|    fps              | 700      |
|    time_elapsed     | 526      |
|    total_timesteps  | 368626   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.73e-07 |
|    n_updates        | 92131    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5404     |
|    fps              | 700      |
|    time_elapsed     | 526      |
|    total_timesteps  | 368971   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.91e-08 |
|    n_updates        | 92217    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5408     |
|    fps              | 700      |
|    time_elapsed     | 527      |
|    total_timesteps  | 369214   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.82e-07 |
|    n_updates        | 92278    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5412     |
|    fps              | 700      |
|    time_elapsed     | 527      |
|    total_timesteps  | 369547   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 92361    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5416     |
|    fps              | 699      |
|    time_elapsed     | 528      |
|    total_timesteps  | 369947   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-06 |
|    n_updates        | 92461    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5420     |
|    fps              | 699      |
|    time_elapsed     | 529      |
|    total_timesteps  | 370284   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.94e-07 |
|    n_updates        | 92545    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5424     |
|    fps              | 699      |
|    time_elapsed     | 529      |
|    total_timesteps  | 370657   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.03e-07 |
|    n_updates        | 92639    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5428     |
|    fps              | 699      |
|    time_elapsed     | 529      |
|    total_timesteps  | 370927   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.32e-07 |
|    n_updates        | 92706    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5432     |
|    fps              | 699      |
|    time_elapsed     | 530      |
|    total_timesteps  | 371287   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-06  |
|    n_updates        | 92796    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5436     |
|    fps              | 699      |
|    time_elapsed     | 530      |
|    total_timesteps  | 371550   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.71e-08 |
|    n_updates        | 92862    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5440     |
|    fps              | 699      |
|    time_elapsed     | 531      |
|    total_timesteps  | 371881   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-07 |
|    n_updates        | 92945    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5444     |
|    fps              | 699      |
|    time_elapsed     | 531      |
|    total_timesteps  | 372248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.85e-08 |
|    n_updates        | 93036    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5448     |
|    fps              | 699      |
|    time_elapsed     | 532      |
|    total_timesteps  | 372619   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-07 |
|    n_updates        | 93129    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5452     |
|    fps              | 699      |
|    time_elapsed     | 533      |
|    total_timesteps  | 372949   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.8e-08  |
|    n_updates        | 93212    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5456     |
|    fps              | 699      |
|    time_elapsed     | 533      |
|    total_timesteps  | 373349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.55e-07 |
|    n_updates        | 93312    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5460     |
|    fps              | 699      |
|    time_elapsed     | 534      |
|    total_timesteps  | 373624   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.81e-07 |
|    n_updates        | 93380    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5464     |
|    fps              | 699      |
|    time_elapsed     | 534      |
|    total_timesteps  | 374024   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.06e-07 |
|    n_updates        | 93480    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5468     |
|    fps              | 699      |
|    time_elapsed     | 535      |
|    total_timesteps  | 374322   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-07 |
|    n_updates        | 93555    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5472     |
|    fps              | 699      |
|    time_elapsed     | 535      |
|    total_timesteps  | 374722   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.26e-07 |
|    n_updates        | 93655    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5476     |
|    fps              | 699      |
|    time_elapsed     | 536      |
|    total_timesteps  | 374997   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.93e-07 |
|    n_updates        | 93724    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5480     |
|    fps              | 699      |
|    time_elapsed     | 536      |
|    total_timesteps  | 375397   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.62e-06 |
|    n_updates        | 93824    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5484     |
|    fps              | 699      |
|    time_elapsed     | 537      |
|    total_timesteps  | 375774   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.68e-07 |
|    n_updates        | 93918    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5488     |
|    fps              | 699      |
|    time_elapsed     | 538      |
|    total_timesteps  | 376160   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1e-06    |
|    n_updates        | 94014    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5492     |
|    fps              | 698      |
|    time_elapsed     | 538      |
|    total_timesteps  | 376440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.68e-07 |
|    n_updates        | 94084    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5496     |
|    fps              | 698      |
|    time_elapsed     | 539      |
|    total_timesteps  | 376778   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.7e-07  |
|    n_updates        | 94169    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5500     |
|    fps              | 698      |
|    time_elapsed     | 539      |
|    total_timesteps  | 377161   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-07 |
|    n_updates        | 94265    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5504     |
|    fps              | 698      |
|    time_elapsed     | 540      |
|    total_timesteps  | 377532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.28e-07 |
|    n_updates        | 94357    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5508     |
|    fps              | 698      |
|    time_elapsed     | 540      |
|    total_timesteps  | 377932   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-06 |
|    n_updates        | 94457    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5512     |
|    fps              | 698      |
|    time_elapsed     | 541      |
|    total_timesteps  | 378320   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-06 |
|    n_updates        | 94554    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5516     |
|    fps              | 698      |
|    time_elapsed     | 541      |
|    total_timesteps  | 378681   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-06  |
|    n_updates        | 94645    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5520     |
|    fps              | 698      |
|    time_elapsed     | 542      |
|    total_timesteps  | 379011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.03e-07 |
|    n_updates        | 94727    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5524     |
|    fps              | 698      |
|    time_elapsed     | 542      |
|    total_timesteps  | 379349   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.91e-06 |
|    n_updates        | 94812    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5528     |
|    fps              | 698      |
|    time_elapsed     | 543      |
|    total_timesteps  | 379694   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.28e-07 |
|    n_updates        | 94898    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5532     |
|    fps              | 698      |
|    time_elapsed     | 543      |
|    total_timesteps  | 380094   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-05 |
|    n_updates        | 94998    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5536     |
|    fps              | 698      |
|    time_elapsed     | 544      |
|    total_timesteps  | 380494   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.74e-07 |
|    n_updates        | 95098    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5540     |
|    fps              | 698      |
|    time_elapsed     | 544      |
|    total_timesteps  | 380804   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.86e-07 |
|    n_updates        | 95175    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5544     |
|    fps              | 698      |
|    time_elapsed     | 545      |
|    total_timesteps  | 381204   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.32e-08 |
|    n_updates        | 95275    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5548     |
|    fps              | 698      |
|    time_elapsed     | 546      |
|    total_timesteps  | 381604   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.56e-07 |
|    n_updates        | 95375    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5552     |
|    fps              | 698      |
|    time_elapsed     | 546      |
|    total_timesteps  | 382004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.9e-08  |
|    n_updates        | 95475    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5556     |
|    fps              | 698      |
|    time_elapsed     | 547      |
|    total_timesteps  | 382384   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.14e-08 |
|    n_updates        | 95570    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5560     |
|    fps              | 698      |
|    time_elapsed     | 547      |
|    total_timesteps  | 382784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.31e-08 |
|    n_updates        | 95670    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5564     |
|    fps              | 698      |
|    time_elapsed     | 548      |
|    total_timesteps  | 383184   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.51e-08 |
|    n_updates        | 95770    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5568     |
|    fps              | 698      |
|    time_elapsed     | 548      |
|    total_timesteps  | 383545   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-07 |
|    n_updates        | 95861    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5572     |
|    fps              | 698      |
|    time_elapsed     | 549      |
|    total_timesteps  | 383945   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.12e-07 |
|    n_updates        | 95961    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5576     |
|    fps              | 698      |
|    time_elapsed     | 549      |
|    total_timesteps  | 384289   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.21e-07 |
|    n_updates        | 96047    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5580     |
|    fps              | 698      |
|    time_elapsed     | 550      |
|    total_timesteps  | 384665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.68e-07 |
|    n_updates        | 96141    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5584     |
|    fps              | 698      |
|    time_elapsed     | 550      |
|    total_timesteps  | 385065   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.42e-07 |
|    n_updates        | 96241    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5588     |
|    fps              | 698      |
|    time_elapsed     | 551      |
|    total_timesteps  | 385367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.43e-07 |
|    n_updates        | 96316    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5592     |
|    fps              | 698      |
|    time_elapsed     | 551      |
|    total_timesteps  | 385767   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.08e-06 |
|    n_updates        | 96416    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5596     |
|    fps              | 698      |
|    time_elapsed     | 552      |
|    total_timesteps  | 386137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-06 |
|    n_updates        | 96509    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5600     |
|    fps              | 698      |
|    time_elapsed     | 553      |
|    total_timesteps  | 386537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.62e-07 |
|    n_updates        | 96609    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5604     |
|    fps              | 698      |
|    time_elapsed     | 553      |
|    total_timesteps  | 386937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.94e-07 |
|    n_updates        | 96709    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5608     |
|    fps              | 698      |
|    time_elapsed     | 554      |
|    total_timesteps  | 387337   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.53e-07 |
|    n_updates        | 96809    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5612     |
|    fps              | 698      |
|    time_elapsed     | 554      |
|    total_timesteps  | 387737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.55e-07 |
|    n_updates        | 96909    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5616     |
|    fps              | 698      |
|    time_elapsed     | 555      |
|    total_timesteps  | 388137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.13e-07 |
|    n_updates        | 97009    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5620     |
|    fps              | 698      |
|    time_elapsed     | 555      |
|    total_timesteps  | 388537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.9e-07  |
|    n_updates        | 97109    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5624     |
|    fps              | 698      |
|    time_elapsed     | 556      |
|    total_timesteps  | 388937   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.14e-06 |
|    n_updates        | 97209    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5628     |
|    fps              | 698      |
|    time_elapsed     | 556      |
|    total_timesteps  | 389278   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.09e-07 |
|    n_updates        | 97294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5632     |
|    fps              | 698      |
|    time_elapsed     | 557      |
|    total_timesteps  | 389631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.24e-07 |
|    n_updates        | 97382    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5636     |
|    fps              | 698      |
|    time_elapsed     | 558      |
|    total_timesteps  | 390030   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-05 |
|    n_updates        | 97482    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 95.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5640     |
|    fps              | 698      |
|    time_elapsed     | 558      |
|    total_timesteps  | 390315   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-06 |
|    n_updates        | 97553    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5644     |
|    fps              | 698      |
|    time_elapsed     | 558      |
|    total_timesteps  | 390648   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.35e-07 |
|    n_updates        | 97636    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5648     |
|    fps              | 698      |
|    time_elapsed     | 559      |
|    total_timesteps  | 390967   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.41e-08 |
|    n_updates        | 97716    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5652     |
|    fps              | 699      |
|    time_elapsed     | 559      |
|    total_timesteps  | 391367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.03e-08 |
|    n_updates        | 97816    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5656     |
|    fps              | 699      |
|    time_elapsed     | 560      |
|    total_timesteps  | 391687   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.88e-08 |
|    n_updates        | 97896    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5660     |
|    fps              | 699      |
|    time_elapsed     | 560      |
|    total_timesteps  | 392087   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.74e-08 |
|    n_updates        | 97996    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5664     |
|    fps              | 699      |
|    time_elapsed     | 561      |
|    total_timesteps  | 392487   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.75e-08 |
|    n_updates        | 98096    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5668     |
|    fps              | 699      |
|    time_elapsed     | 561      |
|    total_timesteps  | 392887   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.02e-07 |
|    n_updates        | 98196    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5672     |
|    fps              | 699      |
|    time_elapsed     | 562      |
|    total_timesteps  | 393279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-07 |
|    n_updates        | 98294    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5676     |
|    fps              | 699      |
|    time_elapsed     | 562      |
|    total_timesteps  | 393617   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.56e-07 |
|    n_updates        | 98379    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5680     |
|    fps              | 699      |
|    time_elapsed     | 563      |
|    total_timesteps  | 394015   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.2e-07  |
|    n_updates        | 98478    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5684     |
|    fps              | 699      |
|    time_elapsed     | 563      |
|    total_timesteps  | 394368   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.9e-07  |
|    n_updates        | 98566    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5688     |
|    fps              | 699      |
|    time_elapsed     | 564      |
|    total_timesteps  | 394588   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.21e-07 |
|    n_updates        | 98621    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5692     |
|    fps              | 699      |
|    time_elapsed     | 564      |
|    total_timesteps  | 394988   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.42e-07 |
|    n_updates        | 98721    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5696     |
|    fps              | 699      |
|    time_elapsed     | 565      |
|    total_timesteps  | 395299   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.22e-06 |
|    n_updates        | 98799    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5700     |
|    fps              | 699      |
|    time_elapsed     | 565      |
|    total_timesteps  | 395656   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.61e-06 |
|    n_updates        | 98888    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5704     |
|    fps              | 699      |
|    time_elapsed     | 566      |
|    total_timesteps  | 395987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.2e-07  |
|    n_updates        | 98971    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5708     |
|    fps              | 699      |
|    time_elapsed     | 566      |
|    total_timesteps  | 396331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.61e-07 |
|    n_updates        | 99057    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5712     |
|    fps              | 699      |
|    time_elapsed     | 567      |
|    total_timesteps  | 396657   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.01e-07 |
|    n_updates        | 99139    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5716     |
|    fps              | 699      |
|    time_elapsed     | 567      |
|    total_timesteps  | 397057   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-07 |
|    n_updates        | 99239    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5720     |
|    fps              | 699      |
|    time_elapsed     | 567      |
|    total_timesteps  | 397324   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.01e-07 |
|    n_updates        | 99305    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5724     |
|    fps              | 699      |
|    time_elapsed     | 568      |
|    total_timesteps  | 397704   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.64e-07 |
|    n_updates        | 99400    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5728     |
|    fps              | 699      |
|    time_elapsed     | 569      |
|    total_timesteps  | 398104   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.2e-07  |
|    n_updates        | 99500    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5732     |
|    fps              | 699      |
|    time_elapsed     | 569      |
|    total_timesteps  | 398412   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.07e-07 |
|    n_updates        | 99577    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5736     |
|    fps              | 699      |
|    time_elapsed     | 569      |
|    total_timesteps  | 398612   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.32e-07 |
|    n_updates        | 99627    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5740     |
|    fps              | 699      |
|    time_elapsed     | 570      |
|    total_timesteps  | 398993   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.33e-06 |
|    n_updates        | 99723    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5744     |
|    fps              | 699      |
|    time_elapsed     | 571      |
|    total_timesteps  | 399393   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.56e-06 |
|    n_updates        | 99823    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5748     |
|    fps              | 699      |
|    time_elapsed     | 571      |
|    total_timesteps  | 399703   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.47e-06 |
|    n_updates        | 99900    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5752     |
|    fps              | 698      |
|    time_elapsed     | 572      |
|    total_timesteps  | 400019   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.08e-05 |
|    n_updates        | 99979    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5756     |
|    fps              | 698      |
|    time_elapsed     | 573      |
|    total_timesteps  | 400374   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.18e-06 |
|    n_updates        | 100068   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5760     |
|    fps              | 698      |
|    time_elapsed     | 573      |
|    total_timesteps  | 400712   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.75e-07 |
|    n_updates        | 100152   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5764     |
|    fps              | 698      |
|    time_elapsed     | 574      |
|    total_timesteps  | 401093   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.77e-07 |
|    n_updates        | 100248   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5768     |
|    fps              | 698      |
|    time_elapsed     | 574      |
|    total_timesteps  | 401440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-06  |
|    n_updates        | 100334   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5772     |
|    fps              | 698      |
|    time_elapsed     | 575      |
|    total_timesteps  | 401840   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.7e-08  |
|    n_updates        | 100434   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5776     |
|    fps              | 698      |
|    time_elapsed     | 576      |
|    total_timesteps  | 402240   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.97e-08 |
|    n_updates        | 100534   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5780     |
|    fps              | 698      |
|    time_elapsed     | 576      |
|    total_timesteps  | 402640   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.91e-07 |
|    n_updates        | 100634   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5784     |
|    fps              | 698      |
|    time_elapsed     | 577      |
|    total_timesteps  | 403005   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.27e-07 |
|    n_updates        | 100726   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5788     |
|    fps              | 697      |
|    time_elapsed     | 577      |
|    total_timesteps  | 403388   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.35e-07 |
|    n_updates        | 100821   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5792     |
|    fps              | 697      |
|    time_elapsed     | 578      |
|    total_timesteps  | 403788   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.58e-07 |
|    n_updates        | 100921   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5796     |
|    fps              | 697      |
|    time_elapsed     | 579      |
|    total_timesteps  | 404188   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.4e-07  |
|    n_updates        | 101021   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5800     |
|    fps              | 697      |
|    time_elapsed     | 579      |
|    total_timesteps  | 404588   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.35e-07 |
|    n_updates        | 101121   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5804     |
|    fps              | 697      |
|    time_elapsed     | 580      |
|    total_timesteps  | 404894   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.06e-06 |
|    n_updates        | 101198   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5808     |
|    fps              | 697      |
|    time_elapsed     | 580      |
|    total_timesteps  | 405244   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.76e-07 |
|    n_updates        | 101285   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5812     |
|    fps              | 697      |
|    time_elapsed     | 581      |
|    total_timesteps  | 405606   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.31e-06 |
|    n_updates        | 101376   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 89.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5816     |
|    fps              | 697      |
|    time_elapsed     | 581      |
|    total_timesteps  | 406002   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.57e-07 |
|    n_updates        | 101475   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5820     |
|    fps              | 697      |
|    time_elapsed     | 582      |
|    total_timesteps  | 406358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-06 |
|    n_updates        | 101564   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5824     |
|    fps              | 697      |
|    time_elapsed     | 583      |
|    total_timesteps  | 406758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.15e-07 |
|    n_updates        | 101664   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5828     |
|    fps              | 697      |
|    time_elapsed     | 583      |
|    total_timesteps  | 407158   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.28e-07 |
|    n_updates        | 101764   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5832     |
|    fps              | 697      |
|    time_elapsed     | 584      |
|    total_timesteps  | 407558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.37e-07 |
|    n_updates        | 101864   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5836     |
|    fps              | 697      |
|    time_elapsed     | 584      |
|    total_timesteps  | 407958   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.22e-07 |
|    n_updates        | 101964   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5840     |
|    fps              | 697      |
|    time_elapsed     | 585      |
|    total_timesteps  | 408288   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.87e-07 |
|    n_updates        | 102046   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5844     |
|    fps              | 697      |
|    time_elapsed     | 586      |
|    total_timesteps  | 408688   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-06 |
|    n_updates        | 102146   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5848     |
|    fps              | 697      |
|    time_elapsed     | 586      |
|    total_timesteps  | 409088   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.72e-06 |
|    n_updates        | 102246   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5852     |
|    fps              | 696      |
|    time_elapsed     | 587      |
|    total_timesteps  | 409462   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.66e-07 |
|    n_updates        | 102340   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5856     |
|    fps              | 696      |
|    time_elapsed     | 588      |
|    total_timesteps  | 409862   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.23e-07 |
|    n_updates        | 102440   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 94.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5860     |
|    fps              | 696      |
|    time_elapsed     | 588      |
|    total_timesteps  | 410123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-05 |
|    n_updates        | 102505   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5864     |
|    fps              | 696      |
|    time_elapsed     | 589      |
|    total_timesteps  | 410443   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.5e-07  |
|    n_updates        | 102585   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 93.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5868     |
|    fps              | 696      |
|    time_elapsed     | 589      |
|    total_timesteps  | 410775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.01e-07 |
|    n_updates        | 102668   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 92.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5872     |
|    fps              | 696      |
|    time_elapsed     | 590      |
|    total_timesteps  | 411102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.36e-08 |
|    n_updates        | 102750   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 91.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5876     |
|    fps              | 696      |
|    time_elapsed     | 590      |
|    total_timesteps  | 411400   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.25e-08 |
|    n_updates        | 102824   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 90.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5880     |
|    fps              | 696      |
|    time_elapsed     | 591      |
|    total_timesteps  | 411706   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.43e-08 |
|    n_updates        | 102901   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 88.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5884     |
|    fps              | 696      |
|    time_elapsed     | 591      |
|    total_timesteps  | 411886   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.39e-08 |
|    n_updates        | 102946   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 87.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5888     |
|    fps              | 696      |
|    time_elapsed     | 591      |
|    total_timesteps  | 412141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.1e-07  |
|    n_updates        | 103010   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 86.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5892     |
|    fps              | 696      |
|    time_elapsed     | 592      |
|    total_timesteps  | 412464   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.99e-08 |
|    n_updates        | 103090   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 85.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5896     |
|    fps              | 696      |
|    time_elapsed     | 592      |
|    total_timesteps  | 412715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.81e-08 |
|    n_updates        | 103153   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5900     |
|    fps              | 696      |
|    time_elapsed     | 592      |
|    total_timesteps  | 413069   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.52e-08 |
|    n_updates        | 103242   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5904     |
|    fps              | 696      |
|    time_elapsed     | 593      |
|    total_timesteps  | 413370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.31e-08 |
|    n_updates        | 103317   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5908     |
|    fps              | 696      |
|    time_elapsed     | 593      |
|    total_timesteps  | 413699   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-07 |
|    n_updates        | 103399   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5912     |
|    fps              | 696      |
|    time_elapsed     | 594      |
|    total_timesteps  | 413923   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.29e-07 |
|    n_updates        | 103455   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5916     |
|    fps              | 696      |
|    time_elapsed     | 594      |
|    total_timesteps  | 414229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.03e-06 |
|    n_updates        | 103532   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5920     |
|    fps              | 696      |
|    time_elapsed     | 594      |
|    total_timesteps  | 414398   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.66e-07 |
|    n_updates        | 103574   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5924     |
|    fps              | 696      |
|    time_elapsed     | 595      |
|    total_timesteps  | 414586   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.68e-07 |
|    n_updates        | 103621   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5928     |
|    fps              | 696      |
|    time_elapsed     | 595      |
|    total_timesteps  | 414955   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.82e-07 |
|    n_updates        | 103713   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5932     |
|    fps              | 696      |
|    time_elapsed     | 595      |
|    total_timesteps  | 415209   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.31e-07 |
|    n_updates        | 103777   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5936     |
|    fps              | 696      |
|    time_elapsed     | 596      |
|    total_timesteps  | 415537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.72e-07 |
|    n_updates        | 103859   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5940     |
|    fps              | 696      |
|    time_elapsed     | 596      |
|    total_timesteps  | 415857   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.41e-07 |
|    n_updates        | 103939   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5944     |
|    fps              | 696      |
|    time_elapsed     | 597      |
|    total_timesteps  | 416162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.77e-07 |
|    n_updates        | 104015   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5948     |
|    fps              | 696      |
|    time_elapsed     | 597      |
|    total_timesteps  | 416436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.83e-07 |
|    n_updates        | 104083   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5952     |
|    fps              | 696      |
|    time_elapsed     | 598      |
|    total_timesteps  | 416758   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.5e-07  |
|    n_updates        | 104164   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5956     |
|    fps              | 696      |
|    time_elapsed     | 598      |
|    total_timesteps  | 417115   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.32e-07 |
|    n_updates        | 104253   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5960     |
|    fps              | 696      |
|    time_elapsed     | 598      |
|    total_timesteps  | 417335   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.39e-07 |
|    n_updates        | 104308   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5964     |
|    fps              | 696      |
|    time_elapsed     | 599      |
|    total_timesteps  | 417645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.05e-07 |
|    n_updates        | 104386   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5968     |
|    fps              | 696      |
|    time_elapsed     | 599      |
|    total_timesteps  | 417962   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.02e-06 |
|    n_updates        | 104465   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5972     |
|    fps              | 696      |
|    time_elapsed     | 600      |
|    total_timesteps  | 418207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.1e-07  |
|    n_updates        | 104526   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5976     |
|    fps              | 696      |
|    time_elapsed     | 600      |
|    total_timesteps  | 418442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.2e-07  |
|    n_updates        | 104585   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5980     |
|    fps              | 696      |
|    time_elapsed     | 601      |
|    total_timesteps  | 418732   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.82e-07 |
|    n_updates        | 104657   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5984     |
|    fps              | 696      |
|    time_elapsed     | 601      |
|    total_timesteps  | 418975   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.26e-06 |
|    n_updates        | 104718   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5988     |
|    fps              | 696      |
|    time_elapsed     | 601      |
|    total_timesteps  | 419136   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.48e-06 |
|    n_updates        | 104758   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5992     |
|    fps              | 696      |
|    time_elapsed     | 602      |
|    total_timesteps  | 419453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.64e-06 |
|    n_updates        | 104838   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 5996     |
|    fps              | 696      |
|    time_elapsed     | 602      |
|    total_timesteps  | 419761   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-07  |
|    n_updates        | 104915   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6000     |
|    fps              | 696      |
|    time_elapsed     | 603      |
|    total_timesteps  | 420014   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.27e-05 |
|    n_updates        | 104978   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6004     |
|    fps              | 696      |
|    time_elapsed     | 603      |
|    total_timesteps  | 420205   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-05 |
|    n_updates        | 105026   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6008     |
|    fps              | 695      |
|    time_elapsed     | 604      |
|    total_timesteps  | 420470   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.74e-07 |
|    n_updates        | 105092   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6012     |
|    fps              | 695      |
|    time_elapsed     | 604      |
|    total_timesteps  | 420870   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.44e-07 |
|    n_updates        | 105192   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6016     |
|    fps              | 695      |
|    time_elapsed     | 605      |
|    total_timesteps  | 421194   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.39e-08 |
|    n_updates        | 105273   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6020     |
|    fps              | 695      |
|    time_elapsed     | 605      |
|    total_timesteps  | 421460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.19e-08 |
|    n_updates        | 105339   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6024     |
|    fps              | 695      |
|    time_elapsed     | 606      |
|    total_timesteps  | 421698   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.26e-08 |
|    n_updates        | 105399   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6028     |
|    fps              | 695      |
|    time_elapsed     | 606      |
|    total_timesteps  | 421872   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.27e-08 |
|    n_updates        | 105442   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6032     |
|    fps              | 695      |
|    time_elapsed     | 606      |
|    total_timesteps  | 422201   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-07 |
|    n_updates        | 105525   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6036     |
|    fps              | 695      |
|    time_elapsed     | 607      |
|    total_timesteps  | 422476   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.41e-08 |
|    n_updates        | 105593   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6040     |
|    fps              | 695      |
|    time_elapsed     | 607      |
|    total_timesteps  | 422748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.08e-08 |
|    n_updates        | 105661   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6044     |
|    fps              | 695      |
|    time_elapsed     | 608      |
|    total_timesteps  | 423102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.74e-08 |
|    n_updates        | 105750   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6048     |
|    fps              | 695      |
|    time_elapsed     | 608      |
|    total_timesteps  | 423367   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.32e-08 |
|    n_updates        | 105816   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6052     |
|    fps              | 695      |
|    time_elapsed     | 609      |
|    total_timesteps  | 423673   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.24e-07 |
|    n_updates        | 105893   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6056     |
|    fps              | 695      |
|    time_elapsed     | 609      |
|    total_timesteps  | 423957   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.07e-07 |
|    n_updates        | 105964   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6060     |
|    fps              | 695      |
|    time_elapsed     | 609      |
|    total_timesteps  | 424305   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.03e-07 |
|    n_updates        | 106051   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6064     |
|    fps              | 695      |
|    time_elapsed     | 610      |
|    total_timesteps  | 424535   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.28e-07 |
|    n_updates        | 106108   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6068     |
|    fps              | 695      |
|    time_elapsed     | 610      |
|    total_timesteps  | 424791   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.8e-07  |
|    n_updates        | 106172   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6072     |
|    fps              | 695      |
|    time_elapsed     | 610      |
|    total_timesteps  | 425036   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.66e-06 |
|    n_updates        | 106233   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6076     |
|    fps              | 695      |
|    time_elapsed     | 611      |
|    total_timesteps  | 425436   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-06 |
|    n_updates        | 106333   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6080     |
|    fps              | 695      |
|    time_elapsed     | 612      |
|    total_timesteps  | 425745   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.38e-07 |
|    n_updates        | 106411   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6084     |
|    fps              | 695      |
|    time_elapsed     | 612      |
|    total_timesteps  | 426102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.75e-07 |
|    n_updates        | 106500   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6088     |
|    fps              | 695      |
|    time_elapsed     | 613      |
|    total_timesteps  | 426502   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-07  |
|    n_updates        | 106600   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6092     |
|    fps              | 695      |
|    time_elapsed     | 613      |
|    total_timesteps  | 426800   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.47e-07 |
|    n_updates        | 106674   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6096     |
|    fps              | 695      |
|    time_elapsed     | 614      |
|    total_timesteps  | 427134   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.66e-07 |
|    n_updates        | 106758   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6100     |
|    fps              | 695      |
|    time_elapsed     | 614      |
|    total_timesteps  | 427424   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-06  |
|    n_updates        | 106830   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6104     |
|    fps              | 695      |
|    time_elapsed     | 615      |
|    total_timesteps  | 427824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.2e-07  |
|    n_updates        | 106930   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6108     |
|    fps              | 695      |
|    time_elapsed     | 615      |
|    total_timesteps  | 428167   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.41e-07 |
|    n_updates        | 107016   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6112     |
|    fps              | 695      |
|    time_elapsed     | 616      |
|    total_timesteps  | 428558   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.72e-07 |
|    n_updates        | 107114   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6116     |
|    fps              | 695      |
|    time_elapsed     | 616      |
|    total_timesteps  | 428836   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.01e-07 |
|    n_updates        | 107183   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6120     |
|    fps              | 695      |
|    time_elapsed     | 617      |
|    total_timesteps  | 429141   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.63e-07 |
|    n_updates        | 107260   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6124     |
|    fps              | 695      |
|    time_elapsed     | 617      |
|    total_timesteps  | 429541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-06 |
|    n_updates        | 107360   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6128     |
|    fps              | 694      |
|    time_elapsed     | 618      |
|    total_timesteps  | 429929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-06 |
|    n_updates        | 107457   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6132     |
|    fps              | 694      |
|    time_elapsed     | 619      |
|    total_timesteps  | 430255   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.38e-06 |
|    n_updates        | 107538   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6136     |
|    fps              | 694      |
|    time_elapsed     | 620      |
|    total_timesteps  | 430645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.96e-07 |
|    n_updates        | 107636   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6140     |
|    fps              | 694      |
|    time_elapsed     | 620      |
|    total_timesteps  | 431007   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.46e-08 |
|    n_updates        | 107726   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6144     |
|    fps              | 694      |
|    time_elapsed     | 620      |
|    total_timesteps  | 431218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.55e-07 |
|    n_updates        | 107779   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6148     |
|    fps              | 694      |
|    time_elapsed     | 621      |
|    total_timesteps  | 431444   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.09e-07 |
|    n_updates        | 107835   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6152     |
|    fps              | 694      |
|    time_elapsed     | 621      |
|    total_timesteps  | 431730   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-07 |
|    n_updates        | 107907   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6156     |
|    fps              | 694      |
|    time_elapsed     | 622      |
|    total_timesteps  | 432037   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.21e-08 |
|    n_updates        | 107984   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6160     |
|    fps              | 694      |
|    time_elapsed     | 622      |
|    total_timesteps  | 432359   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.58e-08 |
|    n_updates        | 108064   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6164     |
|    fps              | 694      |
|    time_elapsed     | 623      |
|    total_timesteps  | 432586   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.48e-08 |
|    n_updates        | 108121   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6168     |
|    fps              | 694      |
|    time_elapsed     | 623      |
|    total_timesteps  | 432856   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.11e-08 |
|    n_updates        | 108188   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6172     |
|    fps              | 694      |
|    time_elapsed     | 624      |
|    total_timesteps  | 433112   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.4e-08  |
|    n_updates        | 108252   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6176     |
|    fps              | 693      |
|    time_elapsed     | 624      |
|    total_timesteps  | 433411   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.3e-08  |
|    n_updates        | 108327   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6180     |
|    fps              | 693      |
|    time_elapsed     | 625      |
|    total_timesteps  | 433784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.78e-08 |
|    n_updates        | 108420   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6184     |
|    fps              | 693      |
|    time_elapsed     | 625      |
|    total_timesteps  | 434070   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.93e-08 |
|    n_updates        | 108492   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6188     |
|    fps              | 693      |
|    time_elapsed     | 626      |
|    total_timesteps  | 434274   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.27e-07 |
|    n_updates        | 108543   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6192     |
|    fps              | 693      |
|    time_elapsed     | 626      |
|    total_timesteps  | 434589   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.67e-07 |
|    n_updates        | 108622   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6196     |
|    fps              | 693      |
|    time_elapsed     | 626      |
|    total_timesteps  | 434797   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.93e-07 |
|    n_updates        | 108674   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6200     |
|    fps              | 693      |
|    time_elapsed     | 627      |
|    total_timesteps  | 435045   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.28e-07 |
|    n_updates        | 108736   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6204     |
|    fps              | 693      |
|    time_elapsed     | 627      |
|    total_timesteps  | 435252   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 108787   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6208     |
|    fps              | 693      |
|    time_elapsed     | 628      |
|    total_timesteps  | 435560   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.74e-07 |
|    n_updates        | 108864   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6212     |
|    fps              | 693      |
|    time_elapsed     | 628      |
|    total_timesteps  | 435898   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.01e-06 |
|    n_updates        | 108949   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6216     |
|    fps              | 693      |
|    time_elapsed     | 629      |
|    total_timesteps  | 436102   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.74e-06 |
|    n_updates        | 109000   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.1     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6220     |
|    fps              | 693      |
|    time_elapsed     | 629      |
|    total_timesteps  | 436453   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-06 |
|    n_updates        | 109088   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6224     |
|    fps              | 693      |
|    time_elapsed     | 630      |
|    total_timesteps  | 436762   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.11e-06 |
|    n_updates        | 109165   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6228     |
|    fps              | 693      |
|    time_elapsed     | 630      |
|    total_timesteps  | 437079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.64e-07 |
|    n_updates        | 109244   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6232     |
|    fps              | 693      |
|    time_elapsed     | 630      |
|    total_timesteps  | 437137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.38e-07 |
|    n_updates        | 109259   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6236     |
|    fps              | 693      |
|    time_elapsed     | 631      |
|    total_timesteps  | 437392   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.94e-07 |
|    n_updates        | 109322   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6240     |
|    fps              | 693      |
|    time_elapsed     | 631      |
|    total_timesteps  | 437578   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.73e-07 |
|    n_updates        | 109369   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6244     |
|    fps              | 693      |
|    time_elapsed     | 631      |
|    total_timesteps  | 437770   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.49e-07 |
|    n_updates        | 109417   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6248     |
|    fps              | 692      |
|    time_elapsed     | 632      |
|    total_timesteps  | 438080   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.5e-08  |
|    n_updates        | 109494   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6252     |
|    fps              | 692      |
|    time_elapsed     | 632      |
|    total_timesteps  | 438458   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.43e-07 |
|    n_updates        | 109589   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6256     |
|    fps              | 692      |
|    time_elapsed     | 633      |
|    total_timesteps  | 438755   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-07 |
|    n_updates        | 109663   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6260     |
|    fps              | 692      |
|    time_elapsed     | 633      |
|    total_timesteps  | 439004   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.2e-07  |
|    n_updates        | 109725   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6264     |
|    fps              | 692      |
|    time_elapsed     | 634      |
|    total_timesteps  | 439401   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.05e-07 |
|    n_updates        | 109825   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6268     |
|    fps              | 692      |
|    time_elapsed     | 634      |
|    total_timesteps  | 439736   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.63e-07 |
|    n_updates        | 109908   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6272     |
|    fps              | 692      |
|    time_elapsed     | 635      |
|    total_timesteps  | 439925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.05e-07 |
|    n_updates        | 109956   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6276     |
|    fps              | 692      |
|    time_elapsed     | 635      |
|    total_timesteps  | 440091   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.75e-05 |
|    n_updates        | 109997   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 65.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6280     |
|    fps              | 692      |
|    time_elapsed     | 635      |
|    total_timesteps  | 440361   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 110065   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 66.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6284     |
|    fps              | 692      |
|    time_elapsed     | 636      |
|    total_timesteps  | 440682   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.74e-07 |
|    n_updates        | 110145   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6288     |
|    fps              | 692      |
|    time_elapsed     | 636      |
|    total_timesteps  | 440988   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.13e-07 |
|    n_updates        | 110221   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6292     |
|    fps              | 692      |
|    time_elapsed     | 637      |
|    total_timesteps  | 441370   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.28e-08 |
|    n_updates        | 110317   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6296     |
|    fps              | 692      |
|    time_elapsed     | 638      |
|    total_timesteps  | 441770   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.2e-07  |
|    n_updates        | 110417   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6300     |
|    fps              | 692      |
|    time_elapsed     | 638      |
|    total_timesteps  | 442023   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.19e-08 |
|    n_updates        | 110480   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6304     |
|    fps              | 692      |
|    time_elapsed     | 638      |
|    total_timesteps  | 442253   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.05e-08 |
|    n_updates        | 110538   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6308     |
|    fps              | 692      |
|    time_elapsed     | 639      |
|    total_timesteps  | 442555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.48e-07 |
|    n_updates        | 110613   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 69       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6312     |
|    fps              | 692      |
|    time_elapsed     | 639      |
|    total_timesteps  | 442794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.74e-08 |
|    n_updates        | 110673   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 68.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6316     |
|    fps              | 692      |
|    time_elapsed     | 639      |
|    total_timesteps  | 442985   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.94e-07 |
|    n_updates        | 110721   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6320     |
|    fps              | 692      |
|    time_elapsed     | 640      |
|    total_timesteps  | 443216   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.16e-07 |
|    n_updates        | 110778   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6324     |
|    fps              | 692      |
|    time_elapsed     | 640      |
|    total_timesteps  | 443555   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.07e-06 |
|    n_updates        | 110863   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 67.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6328     |
|    fps              | 692      |
|    time_elapsed     | 641      |
|    total_timesteps  | 443867   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.98e-07 |
|    n_updates        | 110941   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6332     |
|    fps              | 692      |
|    time_elapsed     | 641      |
|    total_timesteps  | 444186   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.88e-07 |
|    n_updates        | 111021   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6336     |
|    fps              | 692      |
|    time_elapsed     | 641      |
|    total_timesteps  | 444463   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.27e-07 |
|    n_updates        | 111090   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6340     |
|    fps              | 692      |
|    time_elapsed     | 642      |
|    total_timesteps  | 444863   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.05e-06 |
|    n_updates        | 111190   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6344     |
|    fps              | 692      |
|    time_elapsed     | 643      |
|    total_timesteps  | 445217   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-06 |
|    n_updates        | 111279   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6348     |
|    fps              | 692      |
|    time_elapsed     | 643      |
|    total_timesteps  | 445582   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.48e-07 |
|    n_updates        | 111370   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6352     |
|    fps              | 692      |
|    time_elapsed     | 644      |
|    total_timesteps  | 445928   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.55e-07 |
|    n_updates        | 111456   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6356     |
|    fps              | 692      |
|    time_elapsed     | 644      |
|    total_timesteps  | 446269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.13e-07 |
|    n_updates        | 111542   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6360     |
|    fps              | 692      |
|    time_elapsed     | 644      |
|    total_timesteps  | 446477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.56e-07 |
|    n_updates        | 111594   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6364     |
|    fps              | 692      |
|    time_elapsed     | 645      |
|    total_timesteps  | 446790   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.08e-06 |
|    n_updates        | 111672   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6368     |
|    fps              | 692      |
|    time_elapsed     | 645      |
|    total_timesteps  | 447063   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.09e-06 |
|    n_updates        | 111740   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6372     |
|    fps              | 692      |
|    time_elapsed     | 646      |
|    total_timesteps  | 447432   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.02e-06 |
|    n_updates        | 111832   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6376     |
|    fps              | 692      |
|    time_elapsed     | 646      |
|    total_timesteps  | 447753   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 111913   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6380     |
|    fps              | 692      |
|    time_elapsed     | 647      |
|    total_timesteps  | 448078   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.62e-07 |
|    n_updates        | 111994   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6384     |
|    fps              | 692      |
|    time_elapsed     | 647      |
|    total_timesteps  | 448478   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.57e-07 |
|    n_updates        | 112094   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6388     |
|    fps              | 692      |
|    time_elapsed     | 648      |
|    total_timesteps  | 448830   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.87e-07 |
|    n_updates        | 112182   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6392     |
|    fps              | 692      |
|    time_elapsed     | 648      |
|    total_timesteps  | 449111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.07e-06 |
|    n_updates        | 112252   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6396     |
|    fps              | 692      |
|    time_elapsed     | 649      |
|    total_timesteps  | 449440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-07 |
|    n_updates        | 112334   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6400     |
|    fps              | 692      |
|    time_elapsed     | 649      |
|    total_timesteps  | 449806   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.85e-07 |
|    n_updates        | 112426   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6404     |
|    fps              | 692      |
|    time_elapsed     | 650      |
|    total_timesteps  | 450159   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.37e-06 |
|    n_updates        | 112514   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6408     |
|    fps              | 692      |
|    time_elapsed     | 650      |
|    total_timesteps  | 450405   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.93e-06 |
|    n_updates        | 112576   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6412     |
|    fps              | 692      |
|    time_elapsed     | 650      |
|    total_timesteps  | 450737   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.62e-07 |
|    n_updates        | 112659   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6416     |
|    fps              | 692      |
|    time_elapsed     | 651      |
|    total_timesteps  | 451137   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.69e-07 |
|    n_updates        | 112759   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6420     |
|    fps              | 692      |
|    time_elapsed     | 651      |
|    total_timesteps  | 451477   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.17e-08 |
|    n_updates        | 112844   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6424     |
|    fps              | 692      |
|    time_elapsed     | 652      |
|    total_timesteps  | 451743   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.14e-08 |
|    n_updates        | 112910   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6428     |
|    fps              | 692      |
|    time_elapsed     | 652      |
|    total_timesteps  | 451996   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.01e-08 |
|    n_updates        | 112973   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6432     |
|    fps              | 692      |
|    time_elapsed     | 653      |
|    total_timesteps  | 452317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.45e-08 |
|    n_updates        | 113054   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6436     |
|    fps              | 692      |
|    time_elapsed     | 653      |
|    total_timesteps  | 452474   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.63e-08 |
|    n_updates        | 113093   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6440     |
|    fps              | 692      |
|    time_elapsed     | 653      |
|    total_timesteps  | 452730   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.7e-08  |
|    n_updates        | 113157   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6444     |
|    fps              | 692      |
|    time_elapsed     | 654      |
|    total_timesteps  | 453011   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.78e-08 |
|    n_updates        | 113227   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6448     |
|    fps              | 692      |
|    time_elapsed     | 654      |
|    total_timesteps  | 453358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.09e-08 |
|    n_updates        | 113314   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6452     |
|    fps              | 692      |
|    time_elapsed     | 655      |
|    total_timesteps  | 453684   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.35e-07 |
|    n_updates        | 113395   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6456     |
|    fps              | 692      |
|    time_elapsed     | 655      |
|    total_timesteps  | 453987   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.92e-07 |
|    n_updates        | 113471   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6460     |
|    fps              | 692      |
|    time_elapsed     | 655      |
|    total_timesteps  | 454234   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.73e-07 |
|    n_updates        | 113533   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6464     |
|    fps              | 692      |
|    time_elapsed     | 656      |
|    total_timesteps  | 454460   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.9e-07  |
|    n_updates        | 113589   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6468     |
|    fps              | 692      |
|    time_elapsed     | 656      |
|    total_timesteps  | 454821   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.94e-06 |
|    n_updates        | 113680   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6472     |
|    fps              | 692      |
|    time_elapsed     | 657      |
|    total_timesteps  | 455053   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.75e-07 |
|    n_updates        | 113738   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6476     |
|    fps              | 692      |
|    time_elapsed     | 657      |
|    total_timesteps  | 455391   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.62e-07 |
|    n_updates        | 113822   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6480     |
|    fps              | 692      |
|    time_elapsed     | 657      |
|    total_timesteps  | 455709   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.82e-07 |
|    n_updates        | 113902   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6484     |
|    fps              | 692      |
|    time_elapsed     | 658      |
|    total_timesteps  | 456033   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.63e-06 |
|    n_updates        | 113983   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6488     |
|    fps              | 692      |
|    time_elapsed     | 658      |
|    total_timesteps  | 456286   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-06  |
|    n_updates        | 114046   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 74.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6492     |
|    fps              | 692      |
|    time_elapsed     | 659      |
|    total_timesteps  | 456569   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.1e-07  |
|    n_updates        | 114117   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6496     |
|    fps              | 692      |
|    time_elapsed     | 659      |
|    total_timesteps  | 456824   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.6e-07  |
|    n_updates        | 114180   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6500     |
|    fps              | 692      |
|    time_elapsed     | 659      |
|    total_timesteps  | 457162   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-07  |
|    n_updates        | 114265   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6504     |
|    fps              | 692      |
|    time_elapsed     | 660      |
|    total_timesteps  | 457387   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.13e-07 |
|    n_updates        | 114321   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6508     |
|    fps              | 692      |
|    time_elapsed     | 660      |
|    total_timesteps  | 457649   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.91e-07 |
|    n_updates        | 114387   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 72.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6512     |
|    fps              | 692      |
|    time_elapsed     | 661      |
|    total_timesteps  | 457999   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.16e-07 |
|    n_updates        | 114474   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6516     |
|    fps              | 692      |
|    time_elapsed     | 661      |
|    total_timesteps  | 458291   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.72e-08 |
|    n_updates        | 114547   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 70.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6520     |
|    fps              | 692      |
|    time_elapsed     | 661      |
|    total_timesteps  | 458523   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.86e-07 |
|    n_updates        | 114605   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 71.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6524     |
|    fps              | 692      |
|    time_elapsed     | 662      |
|    total_timesteps  | 458901   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.71e-06 |
|    n_updates        | 114700   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6528     |
|    fps              | 692      |
|    time_elapsed     | 663      |
|    total_timesteps  | 459301   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.76e-07 |
|    n_updates        | 114800   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 73.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6532     |
|    fps              | 692      |
|    time_elapsed     | 663      |
|    total_timesteps  | 459645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.3e-07  |
|    n_updates        | 114886   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6536     |
|    fps              | 692      |
|    time_elapsed     | 664      |
|    total_timesteps  | 459998   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.72e-07 |
|    n_updates        | 114974   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6540     |
|    fps              | 692      |
|    time_elapsed     | 664      |
|    total_timesteps  | 460313   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.97e-06 |
|    n_updates        | 115053   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6544     |
|    fps              | 692      |
|    time_elapsed     | 664      |
|    total_timesteps  | 460532   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.28e-06 |
|    n_updates        | 115107   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 75.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6548     |
|    fps              | 692      |
|    time_elapsed     | 665      |
|    total_timesteps  | 460917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.74e-07 |
|    n_updates        | 115204   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6552     |
|    fps              | 692      |
|    time_elapsed     | 665      |
|    total_timesteps  | 461317   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.45e-07 |
|    n_updates        | 115304   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6556     |
|    fps              | 692      |
|    time_elapsed     | 666      |
|    total_timesteps  | 461717   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.02e-08 |
|    n_updates        | 115404   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6560     |
|    fps              | 692      |
|    time_elapsed     | 666      |
|    total_timesteps  | 462032   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.31e-08 |
|    n_updates        | 115482   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6564     |
|    fps              | 693      |
|    time_elapsed     | 667      |
|    total_timesteps  | 462418   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.7e-07  |
|    n_updates        | 115579   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6568     |
|    fps              | 693      |
|    time_elapsed     | 667      |
|    total_timesteps  | 462775   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.82e-07 |
|    n_updates        | 115668   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6572     |
|    fps              | 693      |
|    time_elapsed     | 668      |
|    total_timesteps  | 463071   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.92e-07 |
|    n_updates        | 115742   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6576     |
|    fps              | 693      |
|    time_elapsed     | 668      |
|    total_timesteps  | 463462   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.23e-07 |
|    n_updates        | 115840   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6580     |
|    fps              | 693      |
|    time_elapsed     | 668      |
|    total_timesteps  | 463747   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.31e-07 |
|    n_updates        | 115911   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6584     |
|    fps              | 693      |
|    time_elapsed     | 669      |
|    total_timesteps  | 464048   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.89e-07 |
|    n_updates        | 115986   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6588     |
|    fps              | 693      |
|    time_elapsed     | 669      |
|    total_timesteps  | 464441   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.38e-07 |
|    n_updates        | 116085   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6592     |
|    fps              | 693      |
|    time_elapsed     | 670      |
|    total_timesteps  | 464729   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.17e-07 |
|    n_updates        | 116157   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6596     |
|    fps              | 693      |
|    time_elapsed     | 670      |
|    total_timesteps  | 464979   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 116219   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6600     |
|    fps              | 693      |
|    time_elapsed     | 670      |
|    total_timesteps  | 465213   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.55e-07 |
|    n_updates        | 116278   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6604     |
|    fps              | 693      |
|    time_elapsed     | 671      |
|    total_timesteps  | 465562   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.75e-07 |
|    n_updates        | 116365   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6608     |
|    fps              | 693      |
|    time_elapsed     | 671      |
|    total_timesteps  | 465885   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.09e-07 |
|    n_updates        | 116446   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6612     |
|    fps              | 693      |
|    time_elapsed     | 672      |
|    total_timesteps  | 466190   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.43e-07 |
|    n_updates        | 116522   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6616     |
|    fps              | 693      |
|    time_elapsed     | 672      |
|    total_timesteps  | 466541   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.91e-07 |
|    n_updates        | 116610   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6620     |
|    fps              | 693      |
|    time_elapsed     | 673      |
|    total_timesteps  | 466836   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.85e-07 |
|    n_updates        | 116683   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6624     |
|    fps              | 693      |
|    time_elapsed     | 673      |
|    total_timesteps  | 467191   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.53e-07 |
|    n_updates        | 116772   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6628     |
|    fps              | 693      |
|    time_elapsed     | 674      |
|    total_timesteps  | 467476   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.29e-07 |
|    n_updates        | 116843   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6632     |
|    fps              | 693      |
|    time_elapsed     | 674      |
|    total_timesteps  | 467876   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.19e-07 |
|    n_updates        | 116943   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6636     |
|    fps              | 693      |
|    time_elapsed     | 675      |
|    total_timesteps  | 468165   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.4e-06  |
|    n_updates        | 117016   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6640     |
|    fps              | 693      |
|    time_elapsed     | 675      |
|    total_timesteps  | 468476   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.64e-07 |
|    n_updates        | 117093   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6644     |
|    fps              | 693      |
|    time_elapsed     | 675      |
|    total_timesteps  | 468818   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 117179   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6648     |
|    fps              | 693      |
|    time_elapsed     | 676      |
|    total_timesteps  | 469218   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.37e-06 |
|    n_updates        | 117279   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6652     |
|    fps              | 693      |
|    time_elapsed     | 676      |
|    total_timesteps  | 469539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 117359   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6656     |
|    fps              | 693      |
|    time_elapsed     | 676      |
|    total_timesteps  | 469678   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.3e-07  |
|    n_updates        | 117394   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6660     |
|    fps              | 693      |
|    time_elapsed     | 677      |
|    total_timesteps  | 470055   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.13e-06 |
|    n_updates        | 117488   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6664     |
|    fps              | 693      |
|    time_elapsed     | 677      |
|    total_timesteps  | 470440   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.39e-07 |
|    n_updates        | 117584   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6668     |
|    fps              | 693      |
|    time_elapsed     | 678      |
|    total_timesteps  | 470817   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.31e-07 |
|    n_updates        | 117679   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6672     |
|    fps              | 693      |
|    time_elapsed     | 678      |
|    total_timesteps  | 471155   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.14e-08 |
|    n_updates        | 117763   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6676     |
|    fps              | 694      |
|    time_elapsed     | 679      |
|    total_timesteps  | 471528   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.67e-07 |
|    n_updates        | 117856   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6680     |
|    fps              | 694      |
|    time_elapsed     | 679      |
|    total_timesteps  | 471928   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.51e-07 |
|    n_updates        | 117956   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6684     |
|    fps              | 694      |
|    time_elapsed     | 680      |
|    total_timesteps  | 472326   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.17e-07 |
|    n_updates        | 118056   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6688     |
|    fps              | 694      |
|    time_elapsed     | 680      |
|    total_timesteps  | 472630   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.49e-07 |
|    n_updates        | 118132   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6692     |
|    fps              | 694      |
|    time_elapsed     | 681      |
|    total_timesteps  | 472925   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2e-07    |
|    n_updates        | 118206   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6696     |
|    fps              | 694      |
|    time_elapsed     | 681      |
|    total_timesteps  | 473242   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.58e-07 |
|    n_updates        | 118285   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6700     |
|    fps              | 694      |
|    time_elapsed     | 682      |
|    total_timesteps  | 473522   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.52e-07 |
|    n_updates        | 118355   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6704     |
|    fps              | 694      |
|    time_elapsed     | 682      |
|    total_timesteps  | 473914   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.61e-06 |
|    n_updates        | 118453   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6708     |
|    fps              | 694      |
|    time_elapsed     | 683      |
|    total_timesteps  | 474279   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.04e-06 |
|    n_updates        | 118544   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6712     |
|    fps              | 694      |
|    time_elapsed     | 683      |
|    total_timesteps  | 474611   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.17e-07 |
|    n_updates        | 118627   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6716     |
|    fps              | 694      |
|    time_elapsed     | 683      |
|    total_timesteps  | 474794   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.64e-07 |
|    n_updates        | 118673   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6720     |
|    fps              | 694      |
|    time_elapsed     | 684      |
|    total_timesteps  | 475084   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.53e-06 |
|    n_updates        | 118745   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6724     |
|    fps              | 694      |
|    time_elapsed     | 684      |
|    total_timesteps  | 475259   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.04e-07 |
|    n_updates        | 118789   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6728     |
|    fps              | 694      |
|    time_elapsed     | 684      |
|    total_timesteps  | 475645   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.86e-07 |
|    n_updates        | 118886   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6732     |
|    fps              | 694      |
|    time_elapsed     | 685      |
|    total_timesteps  | 475917   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.5e-07  |
|    n_updates        | 118954   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6736     |
|    fps              | 694      |
|    time_elapsed     | 685      |
|    total_timesteps  | 476208   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.61e-07 |
|    n_updates        | 119026   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6740     |
|    fps              | 694      |
|    time_elapsed     | 686      |
|    total_timesteps  | 476493   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.23e-06 |
|    n_updates        | 119098   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6744     |
|    fps              | 694      |
|    time_elapsed     | 686      |
|    total_timesteps  | 476893   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.4e-06  |
|    n_updates        | 119198   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6748     |
|    fps              | 694      |
|    time_elapsed     | 687      |
|    total_timesteps  | 477207   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.4e-07  |
|    n_updates        | 119276   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6752     |
|    fps              | 694      |
|    time_elapsed     | 687      |
|    total_timesteps  | 477546   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2e-07    |
|    n_updates        | 119361   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6756     |
|    fps              | 694      |
|    time_elapsed     | 687      |
|    total_timesteps  | 477883   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-06  |
|    n_updates        | 119445   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6760     |
|    fps              | 694      |
|    time_elapsed     | 688      |
|    total_timesteps  | 478123   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.11e-07 |
|    n_updates        | 119505   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6764     |
|    fps              | 694      |
|    time_elapsed     | 688      |
|    total_timesteps  | 478416   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.5e-07  |
|    n_updates        | 119578   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6768     |
|    fps              | 694      |
|    time_elapsed     | 689      |
|    total_timesteps  | 478784   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.95e-07 |
|    n_updates        | 119670   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6772     |
|    fps              | 694      |
|    time_elapsed     | 689      |
|    total_timesteps  | 479184   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.16e-06 |
|    n_updates        | 119770   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6776     |
|    fps              | 694      |
|    time_elapsed     | 690      |
|    total_timesteps  | 479539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.84e-07 |
|    n_updates        | 119859   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6780     |
|    fps              | 694      |
|    time_elapsed     | 690      |
|    total_timesteps  | 479715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.29e-07 |
|    n_updates        | 119903   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6784     |
|    fps              | 694      |
|    time_elapsed     | 690      |
|    total_timesteps  | 480058   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.05e-05 |
|    n_updates        | 119989   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6788     |
|    fps              | 694      |
|    time_elapsed     | 691      |
|    total_timesteps  | 480458   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.41e-07 |
|    n_updates        | 120089   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6792     |
|    fps              | 694      |
|    time_elapsed     | 692      |
|    total_timesteps  | 480834   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.81e-07 |
|    n_updates        | 120183   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6796     |
|    fps              | 694      |
|    time_elapsed     | 692      |
|    total_timesteps  | 481196   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.14e-08 |
|    n_updates        | 120273   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6800     |
|    fps              | 694      |
|    time_elapsed     | 692      |
|    total_timesteps  | 481469   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.82e-08 |
|    n_updates        | 120342   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6804     |
|    fps              | 694      |
|    time_elapsed     | 693      |
|    total_timesteps  | 481869   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.29e-08 |
|    n_updates        | 120442   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6808     |
|    fps              | 694      |
|    time_elapsed     | 694      |
|    total_timesteps  | 482229   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.07e-08 |
|    n_updates        | 120532   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6812     |
|    fps              | 694      |
|    time_elapsed     | 694      |
|    total_timesteps  | 482537   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.6e-08  |
|    n_updates        | 120609   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6816     |
|    fps              | 694      |
|    time_elapsed     | 695      |
|    total_timesteps  | 482915   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.75e-08 |
|    n_updates        | 120703   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6820     |
|    fps              | 694      |
|    time_elapsed     | 695      |
|    total_timesteps  | 483226   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.02e-07 |
|    n_updates        | 120781   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6824     |
|    fps              | 694      |
|    time_elapsed     | 696      |
|    total_timesteps  | 483597   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.03e-07 |
|    n_updates        | 120874   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6828     |
|    fps              | 694      |
|    time_elapsed     | 697      |
|    total_timesteps  | 483931   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.47e-07 |
|    n_updates        | 120957   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6832     |
|    fps              | 694      |
|    time_elapsed     | 697      |
|    total_timesteps  | 484331   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.54e-07 |
|    n_updates        | 121057   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.4     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6836     |
|    fps              | 693      |
|    time_elapsed     | 698      |
|    total_timesteps  | 484650   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.12e-07 |
|    n_updates        | 121137   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6840     |
|    fps              | 693      |
|    time_elapsed     | 698      |
|    total_timesteps  | 484969   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.79e-06 |
|    n_updates        | 121217   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6844     |
|    fps              | 693      |
|    time_elapsed     | 699      |
|    total_timesteps  | 485294   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.33e-07 |
|    n_updates        | 121298   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6848     |
|    fps              | 693      |
|    time_elapsed     | 700      |
|    total_timesteps  | 485631   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.31e-07 |
|    n_updates        | 121382   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6852     |
|    fps              | 693      |
|    time_elapsed     | 700      |
|    total_timesteps  | 485845   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.36e-07 |
|    n_updates        | 121436   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6856     |
|    fps              | 693      |
|    time_elapsed     | 700      |
|    total_timesteps  | 486118   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.75e-07 |
|    n_updates        | 121504   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6860     |
|    fps              | 693      |
|    time_elapsed     | 701      |
|    total_timesteps  | 486392   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.5e-07  |
|    n_updates        | 121572   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6864     |
|    fps              | 693      |
|    time_elapsed     | 701      |
|    total_timesteps  | 486679   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.62e-07 |
|    n_updates        | 121644   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6868     |
|    fps              | 693      |
|    time_elapsed     | 702      |
|    total_timesteps  | 487079   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.99e-07 |
|    n_updates        | 121744   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6872     |
|    fps              | 693      |
|    time_elapsed     | 702      |
|    total_timesteps  | 487439   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.15e-06 |
|    n_updates        | 121834   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6876     |
|    fps              | 693      |
|    time_elapsed     | 703      |
|    total_timesteps  | 487749   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.13e-06 |
|    n_updates        | 121912   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 84.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6880     |
|    fps              | 693      |
|    time_elapsed     | 703      |
|    total_timesteps  | 488127   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.64e-07 |
|    n_updates        | 122006   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 83.8     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6884     |
|    fps              | 693      |
|    time_elapsed     | 704      |
|    total_timesteps  | 488435   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.5e-06  |
|    n_updates        | 122083   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6888     |
|    fps              | 693      |
|    time_elapsed     | 704      |
|    total_timesteps  | 488723   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.41e-07 |
|    n_updates        | 122155   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6892     |
|    fps              | 693      |
|    time_elapsed     | 705      |
|    total_timesteps  | 489038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.8e-07  |
|    n_updates        | 122234   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.6     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6896     |
|    fps              | 693      |
|    time_elapsed     | 706      |
|    total_timesteps  | 489358   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.1e-07  |
|    n_updates        | 122314   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6900     |
|    fps              | 692      |
|    time_elapsed     | 706      |
|    total_timesteps  | 489671   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.77e-07 |
|    n_updates        | 122392   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6904     |
|    fps              | 692      |
|    time_elapsed     | 707      |
|    total_timesteps  | 489996   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.54e-07 |
|    n_updates        | 122473   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6908     |
|    fps              | 692      |
|    time_elapsed     | 708      |
|    total_timesteps  | 490328   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.7e-06  |
|    n_updates        | 122556   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6912     |
|    fps              | 692      |
|    time_elapsed     | 708      |
|    total_timesteps  | 490728   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.63e-07 |
|    n_updates        | 122656   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.1     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6916     |
|    fps              | 692      |
|    time_elapsed     | 709      |
|    total_timesteps  | 491128   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.84e-08 |
|    n_updates        | 122756   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6920     |
|    fps              | 691      |
|    time_elapsed     | 710      |
|    total_timesteps  | 491442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.77e-08 |
|    n_updates        | 122835   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.3     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6924     |
|    fps              | 691      |
|    time_elapsed     | 710      |
|    total_timesteps  | 491723   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.57e-08 |
|    n_updates        | 122905   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80       |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6928     |
|    fps              | 691      |
|    time_elapsed     | 711      |
|    total_timesteps  | 491929   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.89e-08 |
|    n_updates        | 122957   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6932     |
|    fps              | 691      |
|    time_elapsed     | 711      |
|    total_timesteps  | 492248   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.44e-07 |
|    n_updates        | 123036   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.9     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6936     |
|    fps              | 691      |
|    time_elapsed     | 712      |
|    total_timesteps  | 492539   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.06e-07 |
|    n_updates        | 123109   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.2     |
|    ep_rew_mean      | 0        |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6940     |
|    fps              | 691      |
|    time_elapsed     | 712      |
|    total_timesteps  | 492791   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.03e-07 |
|    n_updates        | 123172   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6944     |
|    fps              | 691      |
|    time_elapsed     | 712      |
|    total_timesteps  | 493038   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.5e-06  |
|    n_updates        | 123234   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6948     |
|    fps              | 691      |
|    time_elapsed     | 713      |
|    total_timesteps  | 493348   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.94e-08 |
|    n_updates        | 123311   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6952     |
|    fps              | 691      |
|    time_elapsed     | 714      |
|    total_timesteps  | 493748   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.22e-07 |
|    n_updates        | 123411   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6956     |
|    fps              | 691      |
|    time_elapsed     | 714      |
|    total_timesteps  | 494148   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.68e-07 |
|    n_updates        | 123511   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 81.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6960     |
|    fps              | 691      |
|    time_elapsed     | 715      |
|    total_timesteps  | 494548   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.69e-07 |
|    n_updates        | 123611   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6964     |
|    fps              | 691      |
|    time_elapsed     | 716      |
|    total_timesteps  | 494948   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.29e-06 |
|    n_updates        | 123711   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6968     |
|    fps              | 691      |
|    time_elapsed     | 716      |
|    total_timesteps  | 495297   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.55e-06 |
|    n_updates        | 123799   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.6     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6972     |
|    fps              | 691      |
|    time_elapsed     | 717      |
|    total_timesteps  | 495697   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.05e-06 |
|    n_updates        | 123899   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.5     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6976     |
|    fps              | 691      |
|    time_elapsed     | 717      |
|    total_timesteps  | 495995   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.84e-07 |
|    n_updates        | 123973   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6980     |
|    fps              | 691      |
|    time_elapsed     | 718      |
|    total_timesteps  | 496353   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.93e-07 |
|    n_updates        | 124063   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6984     |
|    fps              | 691      |
|    time_elapsed     | 718      |
|    total_timesteps  | 496665   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.31e-08 |
|    n_updates        | 124141   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.3     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6988     |
|    fps              | 691      |
|    time_elapsed     | 718      |
|    total_timesteps  | 496950   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.77e-07 |
|    n_updates        | 124212   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 82.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6992     |
|    fps              | 691      |
|    time_elapsed     | 719      |
|    total_timesteps  | 497276   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.09e-08 |
|    n_updates        | 124293   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.8     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 6996     |
|    fps              | 691      |
|    time_elapsed     | 719      |
|    total_timesteps  | 497442   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.95e-08 |
|    n_updates        | 124335   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7000     |
|    fps              | 691      |
|    time_elapsed     | 720      |
|    total_timesteps  | 497715   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.3e-07  |
|    n_updates        | 124403   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 80.2     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7004     |
|    fps              | 691      |
|    time_elapsed     | 720      |
|    total_timesteps  | 498019   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.13e-07 |
|    n_updates        | 124479   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 79.4     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7008     |
|    fps              | 691      |
|    time_elapsed     | 720      |
|    total_timesteps  | 498269   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.46e-07 |
|    n_updates        | 124542   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7012     |
|    fps              | 691      |
|    time_elapsed     | 721      |
|    total_timesteps  | 498399   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 1.99e-07 |
|    n_updates        | 124574   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76       |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7016     |
|    fps              | 691      |
|    time_elapsed     | 721      |
|    total_timesteps  | 498732   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 9.12e-07 |
|    n_updates        | 124657   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 76.7     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7020     |
|    fps              | 690      |
|    time_elapsed     | 722      |
|    total_timesteps  | 499111   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.16e-06 |
|    n_updates        | 124752   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 77.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7024     |
|    fps              | 690      |
|    time_elapsed     | 722      |
|    total_timesteps  | 499511   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.69e-07 |
|    n_updates        | 124852   |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 78.9     |
|    ep_rew_mean      | 0.01     |
|    exploration_rate | 0.05     |
| time/               |          |
|    episodes         | 7028     |
|    fps              | 690      |
|    time_elapsed     | 723      |
|    total_timesteps  | 499822   |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.43e-07 |
|    n_updates        | 124930   |
----------------------------------
 100%  500,000/500,000  [ 0:12:03 < 0:00:00 , 603 it/s ]

Mean reward: 0.0, Std reward: 0.0
Output written to: model_output.txt
```

